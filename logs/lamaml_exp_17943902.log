============================================
Job ID: 17943902
Job Name: lamaml_exp
Node: a100-4011
Partition: a100_short
Start time: Sat Jan 31 17:51:33 EST 2026
Config: cmaml_seq_2013_2024
Seed: 13
Paths: gpfs
============================================
Running: python /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/scripts/run_experiment.py --config cmaml_seq_2013_2024 --paths gpfs --seed 13
============================================
[rank: 0] Global seed set to 13
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /gpfs/data/oermannlab/NYUTron/model_zoos/nyutron_small/checkpoint-736000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: lakej98 (lakej98-nyu-langone-health) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260131_175144-gn2kv2wf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cmaml-sequential-2013-2024-2013-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/gn2kv2wf
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2013.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2013.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Resume enabled but no completed checkpoints found, starting fresh
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78904044628143â€¦ â”‚ 0.79146397113800â€¦ â”‚ 0.8016881346702â€¦ â”‚
â”‚     test_loss     â”‚ 0.27255037426948â€¦ â”‚ 0.31324902176856â€¦ â”‚ 0.2844404280185â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.79130470752716â€¦ â”‚ 0.77398610115051â€¦ â”‚ 0.7711886167526â€¦ â”‚
â”‚     test_loss     â”‚ 0.285354882478714 â”‚ 0.32532200217247â€¦ â”‚ 0.3017894625663â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.73478215932846â€¦ â”‚ 0.74304467439651â€¦ â”‚ 0.7296320796012â€¦ â”‚
â”‚     test_loss     â”‚ 0.34246128797531â€¦ â”‚ 0.31136676669120â€¦ â”‚ 0.3503020703792â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.72116601467132â€¦ â”‚ 0.69906306266784â€¦ â”‚ 0.6796565055847â€¦ â”‚
â”‚     test_loss     â”‚ 0.32772931456565â€¦ â”‚ 0.34345716238021â€¦ â”‚ 0.3457411527633â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–‡â–…â–„â–‚â–
wandb:              meta_loss_step â–…â–â–â–…â–†â–â–†â–„â–„â–†â–‡â–‚â–‡â–‚â–…â–ˆâ–…â–â–ˆâ–‚â–â–„â–†â–â–„â–‚â–ƒâ–„â–â–‚â–…â–â–â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–
wandb:                    test_auc â–‡â–‡â–ˆâ–‡â–†â–†â–„â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_0 â–â–†â–ˆâ–ˆâ–‡â–†
wandb:    val_auc/dataloader_idx_1 â–â–‡â–ˆâ–‡â–†â–„
wandb:   val_auc/dataloader_idx_10 â–â–…â–ˆâ–ˆâ–ˆâ–‡
wandb:   val_auc/dataloader_idx_11 â–â–…â–ˆâ–ˆâ–ˆâ–‡
wandb:    val_auc/dataloader_idx_2 â–â–†â–ˆâ–‡â–†â–„
wandb:    val_auc/dataloader_idx_3 â–â–†â–ˆâ–ˆâ–‡â–†
wandb:    val_auc/dataloader_idx_4 â–â–†â–ˆâ–ˆâ–‡â–‡
wandb:    val_auc/dataloader_idx_5 â–â–†â–ˆâ–ˆâ–‡â–‡
wandb:    val_auc/dataloader_idx_6 â–â–†â–ˆâ–‡â–‡â–†
wandb:    val_auc/dataloader_idx_7 â–â–†â–ˆâ–‡â–†â–†
wandb:    val_auc/dataloader_idx_8 â–â–…â–ˆâ–ˆâ–‡â–‡
wandb:    val_auc/dataloader_idx_9 â–â–…â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_0 â–‚â–â–â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_1 â–‚â–â–‚â–ƒâ–„â–ˆ
wandb:  val_loss/dataloader_idx_10 â–‚â–‚â–â–â–ƒâ–ˆ
wandb:  val_loss/dataloader_idx_11 â–‚â–‚â–â–â–ƒâ–ˆ
wandb:   val_loss/dataloader_idx_2 â–‚â–â–‚â–ƒâ–…â–ˆ
wandb:   val_loss/dataloader_idx_3 â–‚â–â–â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_4 â–‚â–â–‚â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_5 â–‚â–â–‚â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_6 â–‚â–â–‚â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_7 â–â–â–‚â–ƒâ–…â–ˆ
wandb:   val_loss/dataloader_idx_8 â–‚â–â–â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_9 â–‚â–‚â–â–‚â–ƒâ–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 6
wandb:             meta_loss_epoch 0.09837
wandb:              meta_loss_step 0.01233
wandb:                    test_auc 0.67966
wandb:   test_auc/dataloader_idx_0 0.78904
wandb:   test_auc/dataloader_idx_1 0.79146
wandb:  test_auc/dataloader_idx_10 0.69906
wandb:  test_auc/dataloader_idx_11 0.67966
wandb:   test_auc/dataloader_idx_2 0.80169
wandb:   test_auc/dataloader_idx_3 0.7913
wandb:   test_auc/dataloader_idx_4 0.77399
wandb:   test_auc/dataloader_idx_5 0.77119
wandb:   test_auc/dataloader_idx_6 0.73478
wandb:   test_auc/dataloader_idx_7 0.74304
wandb:   test_auc/dataloader_idx_8 0.72963
wandb:   test_auc/dataloader_idx_9 0.72117
wandb:  test_loss/dataloader_idx_0 0.27255
wandb:  test_loss/dataloader_idx_1 0.31325
wandb: test_loss/dataloader_idx_10 0.34346
wandb: test_loss/dataloader_idx_11 0.34574
wandb:  test_loss/dataloader_idx_2 0.28444
wandb:  test_loss/dataloader_idx_3 0.28535
wandb:  test_loss/dataloader_idx_4 0.32532
wandb:  test_loss/dataloader_idx_5 0.30179
wandb:  test_loss/dataloader_idx_6 0.34246
wandb:  test_loss/dataloader_idx_7 0.31137
wandb:  test_loss/dataloader_idx_8 0.3503
wandb:  test_loss/dataloader_idx_9 0.32773
wandb:                   test_year 2024
wandb:         trainer/global_step 37938
wandb:    val_auc/dataloader_idx_0 0.77742
wandb:    val_auc/dataloader_idx_1 0.77525
wandb:   val_auc/dataloader_idx_10 0.70013
wandb:   val_auc/dataloader_idx_11 0.69163
wandb:    val_auc/dataloader_idx_2 0.7638
wandb:    val_auc/dataloader_idx_3 0.78442
wandb:    val_auc/dataloader_idx_4 0.76282
wandb:    val_auc/dataloader_idx_5 0.74862
wandb:    val_auc/dataloader_idx_6 0.74928
wandb:    val_auc/dataloader_idx_7 0.71056
wandb:    val_auc/dataloader_idx_8 0.72228
wandb:    val_auc/dataloader_idx_9 0.71011
wandb:   val_loss/dataloader_idx_0 0.35342
wandb:   val_loss/dataloader_idx_1 0.37546
wandb:  val_loss/dataloader_idx_10 0.38461
wandb:  val_loss/dataloader_idx_11 0.39016
wandb:   val_loss/dataloader_idx_2 0.34465
wandb:   val_loss/dataloader_idx_3 0.35142
wandb:   val_loss/dataloader_idx_4 0.37865
wandb:   val_loss/dataloader_idx_5 0.39119
wandb:   val_loss/dataloader_idx_6 0.37945
wandb:   val_loss/dataloader_idx_7 0.40335
wandb:   val_loss/dataloader_idx_8 0.41339
wandb:   val_loss/dataloader_idx_9 0.37453
wandb: 
wandb: ğŸš€ View run cmaml-sequential-2013-2024-2013-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/gn2kv2wf
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260131_175144-gn2kv2wf/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260131_235813-wgvif5r1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cmaml-sequential-2013-2024-2014-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/wgvif5r1
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2014.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2014.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.79248183965682â€¦ â”‚ 0.79099357128143â€¦ â”‚ 0.8086053133010â€¦ â”‚
â”‚     test_loss     â”‚ 0.27789250016212â€¦ â”‚ 0.323220819234848 â”‚ 0.2882017493247â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.79584246873855â€¦ â”‚ 0.78684115409851â€¦ â”‚ 0.7803018093109â€¦ â”‚
â”‚     test_loss     â”‚ 0.29280337691307â€¦ â”‚ 0.32806989550590â€¦ â”‚ 0.30588299036026 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.73911058902740â€¦ â”‚  0.7520712018013  â”‚ 0.7402517199516â€¦ â”‚
â”‚     test_loss     â”‚ 0.35278746485710â€¦ â”‚ 0.31922215223312â€¦ â”‚ 0.3587582707405â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.72798371315002â€¦ â”‚ 0.70412576198577â€¦ â”‚ 0.6895556449890â€¦ â”‚
â”‚     test_loss     â”‚ 0.33927223086357â€¦ â”‚ 0.35612562298774â€¦ â”‚ 0.3581147789955â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–…â–ƒâ–â–ˆ
wandb:              meta_loss_step â–â–‚â–†â–â–ƒâ–„â–„â–‚â–â–â–„â–ƒâ–â–ƒâ–‚â–‚â–‚â–â–ƒâ–â–â–â–â–‚â–ƒâ–â–â–‚â–â–‚â–†â–‚â–‚â–†â–†â–†â–†â–†â–‚â–ˆ
wandb:                    test_auc â–‡â–‡â–ˆâ–‡â–‡â–†â–„â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–ˆâ–‡â–
wandb:    val_auc/dataloader_idx_1 â–ˆâ–‡â–‡â–
wandb:   val_auc/dataloader_idx_10 â–ˆâ–ˆâ–ˆâ–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–ˆâ–ˆâ–
wandb:    val_auc/dataloader_idx_2 â–ˆâ–†â–…â–
wandb:    val_auc/dataloader_idx_3 â–ˆâ–ˆâ–‡â–
wandb:    val_auc/dataloader_idx_4 â–ˆâ–ˆâ–ˆâ–
wandb:    val_auc/dataloader_idx_5 â–ˆâ–ˆâ–‡â–
wandb:    val_auc/dataloader_idx_6 â–ˆâ–‡â–‡â–
wandb:    val_auc/dataloader_idx_7 â–ˆâ–ˆâ–‡â–
wandb:    val_auc/dataloader_idx_8 â–ˆâ–‡â–‡â–
wandb:    val_auc/dataloader_idx_9 â–ˆâ–ˆâ–ˆâ–
wandb:   val_loss/dataloader_idx_0 â–â–‚â–ˆâ–†
wandb:   val_loss/dataloader_idx_1 â–â–ƒâ–ˆâ–†
wandb:  val_loss/dataloader_idx_10 â–â–‚â–ˆâ–‚
wandb:  val_loss/dataloader_idx_11 â–â–‚â–ˆâ–
wandb:   val_loss/dataloader_idx_2 â–â–ƒâ–ˆâ–…
wandb:   val_loss/dataloader_idx_3 â–â–ƒâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_4 â–â–‚â–ˆâ–†
wandb:   val_loss/dataloader_idx_5 â–â–‚â–ˆâ–„
wandb:   val_loss/dataloader_idx_6 â–â–‚â–ˆâ–„
wandb:   val_loss/dataloader_idx_7 â–â–‚â–ˆâ–
wandb:   val_loss/dataloader_idx_8 â–â–‚â–ˆâ–ƒ
wandb:   val_loss/dataloader_idx_9 â–â–‚â–ˆâ–‚
wandb: 
wandb: Run summary:
wandb:                       epoch 4
wandb:             meta_loss_epoch 0.29091
wandb:              meta_loss_step 0.41882
wandb:                    test_auc 0.68956
wandb:   test_auc/dataloader_idx_0 0.79248
wandb:   test_auc/dataloader_idx_1 0.79099
wandb:  test_auc/dataloader_idx_10 0.70413
wandb:  test_auc/dataloader_idx_11 0.68956
wandb:   test_auc/dataloader_idx_2 0.80861
wandb:   test_auc/dataloader_idx_3 0.79584
wandb:   test_auc/dataloader_idx_4 0.78684
wandb:   test_auc/dataloader_idx_5 0.7803
wandb:   test_auc/dataloader_idx_6 0.73911
wandb:   test_auc/dataloader_idx_7 0.75207
wandb:   test_auc/dataloader_idx_8 0.74025
wandb:   test_auc/dataloader_idx_9 0.72798
wandb:  test_loss/dataloader_idx_0 0.27789
wandb:  test_loss/dataloader_idx_1 0.32322
wandb: test_loss/dataloader_idx_10 0.35613
wandb: test_loss/dataloader_idx_11 0.35811
wandb:  test_loss/dataloader_idx_2 0.2882
wandb:  test_loss/dataloader_idx_3 0.2928
wandb:  test_loss/dataloader_idx_4 0.32807
wandb:  test_loss/dataloader_idx_5 0.30588
wandb:  test_loss/dataloader_idx_6 0.35279
wandb:  test_loss/dataloader_idx_7 0.31922
wandb:  test_loss/dataloader_idx_8 0.35876
wandb:  test_loss/dataloader_idx_9 0.33927
wandb:                   test_year 2024
wandb:         trainer/global_step 27616
wandb:    val_auc/dataloader_idx_0 0.71738
wandb:    val_auc/dataloader_idx_1 0.73386
wandb:   val_auc/dataloader_idx_10 0.61298
wandb:   val_auc/dataloader_idx_11 0.60494
wandb:    val_auc/dataloader_idx_2 0.74533
wandb:    val_auc/dataloader_idx_3 0.74834
wandb:    val_auc/dataloader_idx_4 0.72103
wandb:    val_auc/dataloader_idx_5 0.7282
wandb:    val_auc/dataloader_idx_6 0.70821
wandb:    val_auc/dataloader_idx_7 0.68727
wandb:    val_auc/dataloader_idx_8 0.68514
wandb:    val_auc/dataloader_idx_9 0.64827
wandb:   val_loss/dataloader_idx_0 0.33142
wandb:   val_loss/dataloader_idx_1 0.34915
wandb:  val_loss/dataloader_idx_10 0.35587
wandb:  val_loss/dataloader_idx_11 0.35525
wandb:   val_loss/dataloader_idx_2 0.31829
wandb:   val_loss/dataloader_idx_3 0.33922
wandb:   val_loss/dataloader_idx_4 0.35803
wandb:   val_loss/dataloader_idx_5 0.35187
wandb:   val_loss/dataloader_idx_6 0.34588
wandb:   val_loss/dataloader_idx_7 0.34596
wandb:   val_loss/dataloader_idx_8 0.37348
wandb:   val_loss/dataloader_idx_9 0.35078
wandb: 
wandb: ğŸš€ View run cmaml-sequential-2013-2024-2014-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/wgvif5r1
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260131_235813-wgvif5r1/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260201_042727-emqhcser
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cmaml-sequential-2013-2024-2015-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/emqhcser
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2015.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2015.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78698533773422â€¦ â”‚ 0.78767597675323â€¦ â”‚ 0.8077685832977â€¦ â”‚
â”‚     test_loss     â”‚ 0.28964784741401â€¦ â”‚ 0.33394843339920â€¦ â”‚ 0.2954950928688â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.79596078395843â€¦ â”‚ 0.79274070262908â€¦ â”‚ 0.7794858813285â€¦ â”‚
â”‚     test_loss     â”‚ 0.301260381937027 â”‚ 0.33599868416786â€¦ â”‚ 0.3175147473812â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.73468977212905â€¦ â”‚ 0.74977004528045â€¦ â”‚ 0.7421922683715â€¦ â”‚
â”‚     test_loss     â”‚ 0.36762335896492â€¦ â”‚ 0.33165583014488â€¦ â”‚ 0.3654367327690â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.72510266304016â€¦ â”‚ 0.70339637994766â€¦ â”‚ 0.6938955783843â€¦ â”‚
â”‚     test_loss     â”‚ 0.34702885150909â€¦ â”‚ 0.36404845118522â€¦ â”‚ 0.3630688786506â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–â–â–‡â–ˆ
wandb:              meta_loss_step â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–ˆâ–â–â–â–ƒâ–ƒâ–â–†â–‚â–â–ƒâ–ƒâ–â–„â–„â–
wandb:                    test_auc â–‡â–‡â–ˆâ–‡â–‡â–†â–„â–„â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–ˆâ–‚â–
wandb:    val_auc/dataloader_idx_1 â–ˆâ–ˆâ–‚â–
wandb:   val_auc/dataloader_idx_10 â–ˆâ–ˆâ–â–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–ˆâ–â–
wandb:    val_auc/dataloader_idx_2 â–ˆâ–‡â–‚â–
wandb:    val_auc/dataloader_idx_3 â–ˆâ–ˆâ–â–
wandb:    val_auc/dataloader_idx_4 â–ˆâ–ˆâ–‚â–
wandb:    val_auc/dataloader_idx_5 â–ˆâ–ˆâ–â–
wandb:    val_auc/dataloader_idx_6 â–ˆâ–ˆâ–‚â–
wandb:    val_auc/dataloader_idx_7 â–ˆâ–ˆâ–‚â–
wandb:    val_auc/dataloader_idx_8 â–ˆâ–ˆâ–â–
wandb:    val_auc/dataloader_idx_9 â–ˆâ–ˆâ–â–
wandb:   val_loss/dataloader_idx_0 â–â–â–ˆâ–‡
wandb:   val_loss/dataloader_idx_1 â–â–â–ˆâ–‡
wandb:  val_loss/dataloader_idx_10 â–â–â–ˆâ–‡
wandb:  val_loss/dataloader_idx_11 â–â–â–ˆâ–‡
wandb:   val_loss/dataloader_idx_2 â–â–â–ˆâ–‡
wandb:   val_loss/dataloader_idx_3 â–â–â–ˆâ–‡
wandb:   val_loss/dataloader_idx_4 â–â–â–ˆâ–‡
wandb:   val_loss/dataloader_idx_5 â–â–â–ˆâ–‡
wandb:   val_loss/dataloader_idx_6 â–â–â–ˆâ–‡
wandb:   val_loss/dataloader_idx_7 â–â–â–ˆâ–‡
wandb:   val_loss/dataloader_idx_8 â–â–â–ˆâ–‡
wandb:   val_loss/dataloader_idx_9 â–â–â–ˆâ–‡
wandb: 
wandb: Run summary:
wandb:                       epoch 4
wandb:             meta_loss_epoch 3.10183
wandb:              meta_loss_step 5.25558
wandb:                    test_auc 0.6939
wandb:   test_auc/dataloader_idx_0 0.78699
wandb:   test_auc/dataloader_idx_1 0.78768
wandb:  test_auc/dataloader_idx_10 0.7034
wandb:  test_auc/dataloader_idx_11 0.6939
wandb:   test_auc/dataloader_idx_2 0.80777
wandb:   test_auc/dataloader_idx_3 0.79596
wandb:   test_auc/dataloader_idx_4 0.79274
wandb:   test_auc/dataloader_idx_5 0.77949
wandb:   test_auc/dataloader_idx_6 0.73469
wandb:   test_auc/dataloader_idx_7 0.74977
wandb:   test_auc/dataloader_idx_8 0.74219
wandb:   test_auc/dataloader_idx_9 0.7251
wandb:  test_loss/dataloader_idx_0 0.28965
wandb:  test_loss/dataloader_idx_1 0.33395
wandb: test_loss/dataloader_idx_10 0.36405
wandb: test_loss/dataloader_idx_11 0.36307
wandb:  test_loss/dataloader_idx_2 0.2955
wandb:  test_loss/dataloader_idx_3 0.30126
wandb:  test_loss/dataloader_idx_4 0.336
wandb:  test_loss/dataloader_idx_5 0.31751
wandb:  test_loss/dataloader_idx_6 0.36762
wandb:  test_loss/dataloader_idx_7 0.33166
wandb:  test_loss/dataloader_idx_8 0.36544
wandb:  test_loss/dataloader_idx_9 0.34703
wandb:                   test_year 2024
wandb:         trainer/global_step 29240
wandb:    val_auc/dataloader_idx_0 0.50005
wandb:    val_auc/dataloader_idx_1 0.50862
wandb:   val_auc/dataloader_idx_10 0.50148
wandb:   val_auc/dataloader_idx_11 0.49994
wandb:    val_auc/dataloader_idx_2 0.49843
wandb:    val_auc/dataloader_idx_3 0.50267
wandb:    val_auc/dataloader_idx_4 0.50528
wandb:    val_auc/dataloader_idx_5 0.50591
wandb:    val_auc/dataloader_idx_6 0.50041
wandb:    val_auc/dataloader_idx_7 0.50195
wandb:    val_auc/dataloader_idx_8 0.50249
wandb:    val_auc/dataloader_idx_9 0.50081
wandb:   val_loss/dataloader_idx_0 2.38607
wandb:   val_loss/dataloader_idx_1 2.55712
wandb:  val_loss/dataloader_idx_10 2.61605
wandb:  val_loss/dataloader_idx_11 2.60974
wandb:   val_loss/dataloader_idx_2 2.26124
wandb:   val_loss/dataloader_idx_3 2.46304
wandb:   val_loss/dataloader_idx_4 2.64359
wandb:   val_loss/dataloader_idx_5 2.58444
wandb:   val_loss/dataloader_idx_6 2.52615
wandb:   val_loss/dataloader_idx_7 2.52597
wandb:   val_loss/dataloader_idx_8 2.78869
wandb:   val_loss/dataloader_idx_9 2.56796
wandb: 
wandb: ğŸš€ View run cmaml-sequential-2013-2024-2015-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/emqhcser
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260201_042727-emqhcser/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260201_090728-f8chcipa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cmaml-sequential-2013-2024-2016-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/f8chcipa
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2016.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2016.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78669244050979â€¦ â”‚ 0.78265917301177â€¦ â”‚ 0.8058297634124â€¦ â”‚
â”‚     test_loss     â”‚ 0.30976739525794â€¦ â”‚ 0.36416226625442â€¦ â”‚ 0.3182314038276â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.79148310422897â€¦ â”‚ 0.78748738765716â€¦ â”‚ 0.7727348208427â€¦ â”‚
â”‚     test_loss     â”‚ 0.32407611608505â€¦ â”‚ 0.36413884162902â€¦ â”‚ 0.3403644263744â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.73388957977294â€¦ â”‚ 0.74217057228088â€¦ â”‚ 0.7401452064514â€¦ â”‚
â”‚     test_loss     â”‚ 0.39261385798454â€¦ â”‚ 0.35509070754051â€¦ â”‚ 0.3914592862129â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.72077751159667â€¦ â”‚ 0.69620645046234â€¦ â”‚ 0.6887613534927â€¦ â”‚
â”‚     test_loss     â”‚ 0.37076079845428â€¦ â”‚ 0.38755360245704â€¦ â”‚ 0.3842557370662â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆ
wandb:             meta_loss_epoch â–ˆâ–…â–‚â–
wandb:              meta_loss_step â–ƒâ–‚â–â–â–‚â–„â–„â–â–‚â–‚â–ˆâ–‚â–ˆâ–ƒâ–†â–â–ƒâ–‚â–ƒâ–†â–‚â–â–â–â–â–‚â–…â–ƒâ–‚â–‚â–ƒâ–â–â–‚â–â–â–â–â–â–‚
wandb:                    test_auc â–‡â–‡â–ˆâ–‡â–‡â–†â–„â–„â–„â–ƒâ–â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–„â–ƒâ–
wandb:    val_auc/dataloader_idx_1 â–ˆâ–â–â–ƒ
wandb:   val_auc/dataloader_idx_10 â–ˆâ–„â–â–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–„â–â–
wandb:    val_auc/dataloader_idx_2 â–ˆâ–â–‚â–ƒ
wandb:    val_auc/dataloader_idx_3 â–ˆâ–‚â–‚â–
wandb:    val_auc/dataloader_idx_4 â–ˆâ–‚â–â–
wandb:    val_auc/dataloader_idx_5 â–ˆâ–„â–‚â–
wandb:    val_auc/dataloader_idx_6 â–ˆâ–ƒâ–‚â–
wandb:    val_auc/dataloader_idx_7 â–ˆâ–â–â–
wandb:    val_auc/dataloader_idx_8 â–ˆâ–‚â–â–‚
wandb:    val_auc/dataloader_idx_9 â–…â–â–…â–ˆ
wandb:   val_loss/dataloader_idx_0 â–â–ƒâ–†â–ˆ
wandb:   val_loss/dataloader_idx_1 â–â–„â–†â–ˆ
wandb:  val_loss/dataloader_idx_10 â–â–ƒâ–†â–ˆ
wandb:  val_loss/dataloader_idx_11 â–â–ƒâ–†â–ˆ
wandb:   val_loss/dataloader_idx_2 â–â–„â–†â–ˆ
wandb:   val_loss/dataloader_idx_3 â–â–ƒâ–†â–ˆ
wandb:   val_loss/dataloader_idx_4 â–â–ƒâ–†â–ˆ
wandb:   val_loss/dataloader_idx_5 â–â–ƒâ–†â–ˆ
wandb:   val_loss/dataloader_idx_6 â–â–ƒâ–†â–ˆ
wandb:   val_loss/dataloader_idx_7 â–â–„â–†â–ˆ
wandb:   val_loss/dataloader_idx_8 â–â–„â–†â–ˆ
wandb:   val_loss/dataloader_idx_9 â–â–„â–†â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 4
wandb:             meta_loss_epoch 0.04193
wandb:              meta_loss_step 0.03189
wandb:                    test_auc 0.68876
wandb:   test_auc/dataloader_idx_0 0.78669
wandb:   test_auc/dataloader_idx_1 0.78266
wandb:  test_auc/dataloader_idx_10 0.69621
wandb:  test_auc/dataloader_idx_11 0.68876
wandb:   test_auc/dataloader_idx_2 0.80583
wandb:   test_auc/dataloader_idx_3 0.79148
wandb:   test_auc/dataloader_idx_4 0.78749
wandb:   test_auc/dataloader_idx_5 0.77273
wandb:   test_auc/dataloader_idx_6 0.73389
wandb:   test_auc/dataloader_idx_7 0.74217
wandb:   test_auc/dataloader_idx_8 0.74015
wandb:   test_auc/dataloader_idx_9 0.72078
wandb:  test_loss/dataloader_idx_0 0.30977
wandb:  test_loss/dataloader_idx_1 0.36416
wandb: test_loss/dataloader_idx_10 0.38755
wandb: test_loss/dataloader_idx_11 0.38426
wandb:  test_loss/dataloader_idx_2 0.31823
wandb:  test_loss/dataloader_idx_3 0.32408
wandb:  test_loss/dataloader_idx_4 0.36414
wandb:  test_loss/dataloader_idx_5 0.34036
wandb:  test_loss/dataloader_idx_6 0.39261
wandb:  test_loss/dataloader_idx_7 0.35509
wandb:  test_loss/dataloader_idx_8 0.39146
wandb:  test_loss/dataloader_idx_9 0.37076
wandb:                   test_year 2024
wandb:         trainer/global_step 33636
wandb:    val_auc/dataloader_idx_0 0.77239
wandb:    val_auc/dataloader_idx_1 0.77443
wandb:   val_auc/dataloader_idx_10 0.70296
wandb:   val_auc/dataloader_idx_11 0.69563
wandb:    val_auc/dataloader_idx_2 0.76997
wandb:    val_auc/dataloader_idx_3 0.78682
wandb:    val_auc/dataloader_idx_4 0.76395
wandb:    val_auc/dataloader_idx_5 0.74381
wandb:    val_auc/dataloader_idx_6 0.74526
wandb:    val_auc/dataloader_idx_7 0.71608
wandb:    val_auc/dataloader_idx_8 0.73117
wandb:    val_auc/dataloader_idx_9 0.71736
wandb:   val_loss/dataloader_idx_0 0.49189
wandb:   val_loss/dataloader_idx_1 0.51626
wandb:  val_loss/dataloader_idx_10 0.50721
wandb:  val_loss/dataloader_idx_11 0.5195
wandb:   val_loss/dataloader_idx_2 0.46418
wandb:   val_loss/dataloader_idx_3 0.48382
wandb:   val_loss/dataloader_idx_4 0.51842
wandb:   val_loss/dataloader_idx_5 0.53059
wandb:   val_loss/dataloader_idx_6 0.51607
wandb:   val_loss/dataloader_idx_7 0.53842
wandb:   val_loss/dataloader_idx_8 0.55174
wandb:   val_loss/dataloader_idx_9 0.50361
wandb: 
wandb: ğŸš€ View run cmaml-sequential-2013-2024-2016-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/f8chcipa
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260201_090728-f8chcipa/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260201_141520-c0pve3xd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cmaml-sequential-2013-2024-2017-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/c0pve3xd
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2017.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2017.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.77555930614471â€¦ â”‚ 0.78242635726928â€¦ â”‚ 0.7994446754455â€¦ â”‚
â”‚     test_loss     â”‚ 0.48871436715126â€¦ â”‚ 0.58625346422195â€¦ â”‚ 0.5213241577148â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.790866494178772 â”‚ 0.77522218227386â€¦ â”‚ 0.7708508372306â€¦ â”‚
â”‚     test_loss     â”‚ 0.50646567344665â€¦ â”‚ 0.585262656211853 â”‚ 0.5275212526321â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.73202794790267â€¦ â”‚ 0.73031473159790â€¦ â”‚ 0.7248833179473â€¦ â”‚
â”‚     test_loss     â”‚ 0.60410994291305â€¦ â”‚ 0.54154407978057â€¦ â”‚ 0.5751666426658â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.70586746931076â€¦ â”‚ 0.67953294515609â€¦ â”‚ 0.6735258698463â€¦ â”‚
â”‚     test_loss     â”‚ 0.50138324499130â€¦ â”‚ 0.518974244594574 â”‚ 0.5099025368690â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–‚â–‚â–â–â–ˆâ–ˆâ–‡
wandb:              meta_loss_step â–â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–ˆâ–…â–‚â–ˆâ–‚â–ˆâ–‚â–‡â–‚â–‚â–â–‚â–â–†â–†â–†â–‚â–…â–…â–
wandb:                    test_auc â–‡â–‡â–ˆâ–ˆâ–‡â–†â–„â–„â–„â–ƒâ–â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–‡â–…â–…â–â–‚â–†
wandb:    val_auc/dataloader_idx_1 â–†â–…â–ƒâ–„â–ƒâ–â–ˆ
wandb:   val_auc/dataloader_idx_10 â–ˆâ–‡â–‡â–‡â–â–‚â–„
wandb:   val_auc/dataloader_idx_11 â–ˆâ–ˆâ–‡â–‡â–â–‚â–„
wandb:    val_auc/dataloader_idx_2 â–„â–ƒâ–â–ƒâ–„â–ƒâ–ˆ
wandb:    val_auc/dataloader_idx_3 â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–†
wandb:    val_auc/dataloader_idx_4 â–ˆâ–‡â–‡â–ˆâ–‚â–â–†
wandb:    val_auc/dataloader_idx_5 â–„â–‚â–â–‚â–„â–ƒâ–ˆ
wandb:    val_auc/dataloader_idx_6 â–„â–‚â–â–ƒâ–ƒâ–ƒâ–ˆ
wandb:    val_auc/dataloader_idx_7 â–ˆâ–…â–„â–„â–‚â–â–†
wandb:    val_auc/dataloader_idx_8 â–ˆâ–‡â–†â–‡â–â–‚â–„
wandb:    val_auc/dataloader_idx_9 â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ƒ
wandb:   val_loss/dataloader_idx_0 â–„â–†â–‡â–ˆâ–â–â–
wandb:   val_loss/dataloader_idx_1 â–„â–†â–‡â–ˆâ–â–â–
wandb:  val_loss/dataloader_idx_10 â–„â–‡â–ˆâ–ˆâ–â–‚â–‚
wandb:  val_loss/dataloader_idx_11 â–…â–‡â–ˆâ–ˆâ–â–‚â–‚
wandb:   val_loss/dataloader_idx_2 â–„â–†â–‡â–ˆâ–‚â–â–
wandb:   val_loss/dataloader_idx_3 â–ƒâ–†â–‡â–ˆâ–â–â–
wandb:   val_loss/dataloader_idx_4 â–ƒâ–…â–‡â–ˆâ–â–â–
wandb:   val_loss/dataloader_idx_5 â–„â–†â–‡â–ˆâ–â–â–
wandb:   val_loss/dataloader_idx_6 â–„â–†â–‡â–ˆâ–â–â–
wandb:   val_loss/dataloader_idx_7 â–„â–†â–‡â–ˆâ–â–â–
wandb:   val_loss/dataloader_idx_8 â–„â–†â–‡â–ˆâ–â–â–
wandb:   val_loss/dataloader_idx_9 â–…â–‡â–ˆâ–ˆâ–â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:                       epoch 7
wandb:             meta_loss_epoch 0.25783
wandb:              meta_loss_step 0.52851
wandb:                    test_auc 0.67353
wandb:   test_auc/dataloader_idx_0 0.77556
wandb:   test_auc/dataloader_idx_1 0.78243
wandb:  test_auc/dataloader_idx_10 0.67953
wandb:  test_auc/dataloader_idx_11 0.67353
wandb:   test_auc/dataloader_idx_2 0.79944
wandb:   test_auc/dataloader_idx_3 0.79087
wandb:   test_auc/dataloader_idx_4 0.77522
wandb:   test_auc/dataloader_idx_5 0.77085
wandb:   test_auc/dataloader_idx_6 0.73203
wandb:   test_auc/dataloader_idx_7 0.73031
wandb:   test_auc/dataloader_idx_8 0.72488
wandb:   test_auc/dataloader_idx_9 0.70587
wandb:  test_loss/dataloader_idx_0 0.48871
wandb:  test_loss/dataloader_idx_1 0.58625
wandb: test_loss/dataloader_idx_10 0.51897
wandb: test_loss/dataloader_idx_11 0.5099
wandb:  test_loss/dataloader_idx_2 0.52132
wandb:  test_loss/dataloader_idx_3 0.50647
wandb:  test_loss/dataloader_idx_4 0.58526
wandb:  test_loss/dataloader_idx_5 0.52752
wandb:  test_loss/dataloader_idx_6 0.60411
wandb:  test_loss/dataloader_idx_7 0.54154
wandb:  test_loss/dataloader_idx_8 0.57517
wandb:  test_loss/dataloader_idx_9 0.50138
wandb:                   test_year 2024
wandb:         trainer/global_step 81480
wandb:    val_auc/dataloader_idx_0 0.77606
wandb:    val_auc/dataloader_idx_1 0.78253
wandb:   val_auc/dataloader_idx_10 0.64863
wandb:   val_auc/dataloader_idx_11 0.64708
wandb:    val_auc/dataloader_idx_2 0.78221
wandb:    val_auc/dataloader_idx_3 0.78416
wandb:    val_auc/dataloader_idx_4 0.76687
wandb:    val_auc/dataloader_idx_5 0.7631
wandb:    val_auc/dataloader_idx_6 0.7636
wandb:    val_auc/dataloader_idx_7 0.71867
wandb:    val_auc/dataloader_idx_8 0.70855
wandb:    val_auc/dataloader_idx_9 0.66185
wandb:   val_loss/dataloader_idx_0 0.30045
wandb:   val_loss/dataloader_idx_1 0.30402
wandb:  val_loss/dataloader_idx_10 0.36781
wandb:  val_loss/dataloader_idx_11 0.37438
wandb:   val_loss/dataloader_idx_2 0.27699
wandb:   val_loss/dataloader_idx_3 0.29832
wandb:   val_loss/dataloader_idx_4 0.32148
wandb:   val_loss/dataloader_idx_5 0.32023
wandb:   val_loss/dataloader_idx_6 0.31163
wandb:   val_loss/dataloader_idx_7 0.3288
wandb:   val_loss/dataloader_idx_8 0.3547
wandb:   val_loss/dataloader_idx_9 0.36655
wandb: 
wandb: ğŸš€ View run cmaml-sequential-2013-2024-2017-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/c0pve3xd
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260201_141520-c0pve3xd/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260202_013702-4cskkqcp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cmaml-sequential-2013-2024-2018-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/4cskkqcp
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2018.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13/best-checkpoint-2018.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.77638626098632â€¦ â”‚ 0.78652524948120â€¦ â”‚ 0.7951277494430â€¦ â”‚
â”‚     test_loss     â”‚ 0.45602503418922â€¦ â”‚ 0.53548657894134â€¦ â”‚ 0.4819503426551â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78891426324844â€¦ â”‚ 0.76532137393951â€¦ â”‚ 0.7612269520759â€¦ â”‚
â”‚     test_loss     â”‚ 0.45994359254837â€¦ â”‚ 0.52124238014221â€¦ â”‚ 0.4633161425590â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.72972828149795â€¦ â”‚ 0.72699016332626â€¦ â”‚ 0.7302839756011â€¦ â”‚
â”‚     test_loss     â”‚ 0.52124100923538â€¦ â”‚ 0.47149658203125  â”‚ 0.5010315775871â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.70005244016647â€¦ â”‚ 0.677759051322937 â”‚ 0.6742774248123â€¦ â”‚
â”‚     test_loss     â”‚ 0.44585663080215â€¦ â”‚ 0.46266171336174â€¦ â”‚ 0.4544606804847â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–…â–â–
wandb:              meta_loss_step â–â–â–â–‚â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–‚â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–
wandb:                    test_auc â–‡â–ˆâ–ˆâ–ˆâ–†â–†â–„â–„â–„â–‚â–â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–‡â–†â–
wandb:    val_auc/dataloader_idx_1 â–ˆâ–ˆâ–†â–
wandb:   val_auc/dataloader_idx_10 â–ˆâ–†â–‚â–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–‡â–ƒâ–
wandb:    val_auc/dataloader_idx_2 â–ˆâ–†â–â–
wandb:    val_auc/dataloader_idx_3 â–ˆâ–…â–ƒâ–
wandb:    val_auc/dataloader_idx_4 â–ˆâ–…â–„â–
wandb:    val_auc/dataloader_idx_5 â–ˆâ–„â–‚â–
wandb:    val_auc/dataloader_idx_6 â–ˆâ–ƒâ–„â–
wandb:    val_auc/dataloader_idx_7 â–ˆâ–„â–â–
wandb:    val_auc/dataloader_idx_8 â–ˆâ–…â–‚â–
wandb:    val_auc/dataloader_idx_9 â–ˆâ–ˆâ–â–…
wandb:   val_loss/dataloader_idx_0 â–â–„â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_1 â–â–„â–ˆâ–ˆ
wandb:  val_loss/dataloader_idx_10 â–â–ƒâ–†â–ˆ
wandb:  val_loss/dataloader_idx_11 â–â–ƒâ–†â–ˆ
wandb:   val_loss/dataloader_idx_2 â–â–„â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_3 â–â–„â–‡â–ˆ
wandb:   val_loss/dataloader_idx_4 â–â–ƒâ–‡â–ˆ
wandb:   val_loss/dataloader_idx_5 â–â–ƒâ–‡â–ˆ
wandb:   val_loss/dataloader_idx_6 â–â–ƒâ–‡â–ˆ
wandb:   val_loss/dataloader_idx_7 â–â–„â–‡â–ˆ
wandb:   val_loss/dataloader_idx_8 â–â–ƒâ–†â–ˆ
wandb:   val_loss/dataloader_idx_9 â–â–ƒâ–†â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 4
wandb:             meta_loss_epoch 0.01991
wandb:              meta_loss_step 0.00167
wandb:                    test_auc 0.67428
wandb:   test_auc/dataloader_idx_0 0.77639
wandb:   test_auc/dataloader_idx_1 0.78653
wandb:  test_auc/dataloader_idx_10 0.67776
wandb:  test_auc/dataloader_idx_11 0.67428
wandb:   test_auc/dataloader_idx_2 0.79513
wandb:   test_auc/dataloader_idx_3 0.78891
wandb:   test_auc/dataloader_idx_4 0.76532
wandb:   test_auc/dataloader_idx_5 0.76123
wandb:   test_auc/dataloader_idx_6 0.72973
wandb:   test_auc/dataloader_idx_7 0.72699
wandb:   test_auc/dataloader_idx_8 0.73028
wandb:   test_auc/dataloader_idx_9 0.70005
wandb:  test_loss/dataloader_idx_0 0.45603
wandb:  test_loss/dataloader_idx_1 0.53549
wandb: test_loss/dataloader_idx_10 0.46266
wandb: test_loss/dataloader_idx_11 0.45446
wandb:  test_loss/dataloader_idx_2 0.48195
wandb:  test_loss/dataloader_idx_3 0.45994
wandb:  test_loss/dataloader_idx_4 0.52124
wandb:  test_loss/dataloader_idx_5 0.46332
wandb:  test_loss/dataloader_idx_6 0.52124
wandb:  test_loss/dataloader_idx_7 0.4715
wandb:  test_loss/dataloader_idx_8 0.50103
wandb:  test_loss/dataloader_idx_9 0.44586
wandb:                   test_year 2024
wandb:         trainer/global_step 46612
wandb:    val_auc/dataloader_idx_0 0.7634
wandb:    val_auc/dataloader_idx_1 0.76202
wandb:   val_auc/dataloader_idx_10 0.68149
wandb:   val_auc/dataloader_idx_11 0.67422
wandb:    val_auc/dataloader_idx_2 0.76209
wandb:    val_auc/dataloader_idx_3 0.78124
wandb:    val_auc/dataloader_idx_4 0.75729
wandb:    val_auc/dataloader_idx_5 0.73306
wandb:    val_auc/dataloader_idx_6 0.74006
wandb:    val_auc/dataloader_idx_7 0.70467
wandb:    val_auc/dataloader_idx_8 0.71364
wandb:    val_auc/dataloader_idx_9 0.70992
wandb:   val_loss/dataloader_idx_0 0.61559
wandb:   val_loss/dataloader_idx_1 0.6355
wandb:  val_loss/dataloader_idx_10 0.59536
wandb:  val_loss/dataloader_idx_11 0.59723
wandb:   val_loss/dataloader_idx_2 0.58124
wandb:   val_loss/dataloader_idx_3 0.60563
wandb:   val_loss/dataloader_idx_4 0.65034
wandb:   val_loss/dataloader_idx_5 0.65167
wandb:   val_loss/dataloader_idx_6 0.6168
wandb:   val_loss/dataloader_idx_7 0.63968
wandb:   val_loss/dataloader_idx_8 0.65726
wandb:   val_loss/dataloader_idx_9 0.57407
wandb: 
wandb: ğŸš€ View run cmaml-sequential-2013-2024-2018-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/4cskkqcp
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260202_013702-4cskkqcp/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260202_082112-ebqt7j54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cmaml-sequential-2013-2024-2019-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/ebqt7j54
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/cmaml-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
