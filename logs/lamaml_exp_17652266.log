============================================
Job ID: 17652266
Job Name: lamaml_exp
Node: a100-4007
Partition: a100_short
Start time: Sat Jan 24 12:44:47 EST 2026
Config: traditional_seq_2013_2024
Seed: 11
Paths: gpfs
============================================
Running: python /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/scripts/run_experiment.py --config traditional_seq_2013_2024 --paths gpfs --seed 11
============================================
[rank: 0] Global seed set to 11
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /gpfs/data/oermannlab/NYUTron/model_zoos/nyutron_small/checkpoint-736000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: lakej98 (lakej98-nyu-langone-health) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260124_124558-c30xypgy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2013-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/c30xypgy
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2013-v1.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2013-v1.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83018791675567â€¦ â”‚ 0.84001922607421â€¦ â”‚ 0.8454387187957â€¦ â”‚
â”‚     test_loss     â”‚ 0.32677042484283â€¦ â”‚ 0.32839217782020â€¦ â”‚ 0.3332020044326â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83793419599533â€¦ â”‚ 0.82701557874679â€¦ â”‚ 0.8264544010162â€¦ â”‚
â”‚     test_loss     â”‚ 0.31714907288551â€¦ â”‚ 0.32125574350357â€¦ â”‚ 0.3133003115653â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.786837100982666 â”‚ 0.79405945539474â€¦ â”‚ 0.7836053371429â€¦ â”‚
â”‚     test_loss     â”‚ 0.34210872650146â€¦ â”‚ 0.32512980699539â€¦ â”‚ 0.3525124788284â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.75883519649505â€¦ â”‚ 0.743678092956543 â”‚ 0.7132083177566â€¦ â”‚
â”‚     test_loss     â”‚ 0.36049231886863â€¦ â”‚ 0.377494215965271 â”‚ 0.3899788856506â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–…â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–†â–…â–„â–„â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–
wandb:             train_loss_step â–‚â–…â–â–†â–‡â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‚â–ˆâ–ƒâ–ƒâ–‚â–â–„â–„â–‚â–‚â–„â–â–‚â–‚â–â–â–‚â–â–ƒâ–ƒâ–â–‚â–ƒâ–…â–‚â–†
wandb:         trainer/global_step â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–â–ƒâ–„â–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:    val_auc/dataloader_idx_1 â–â–ƒâ–„â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   val_auc/dataloader_idx_10 â–â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:   val_auc/dataloader_idx_11 â–â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†
wandb:    val_auc/dataloader_idx_2 â–â–ƒâ–„â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:    val_auc/dataloader_idx_3 â–â–„â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_4 â–â–ƒâ–„â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_5 â–â–„â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:    val_auc/dataloader_idx_6 â–â–„â–„â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–ƒâ–„â–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_8 â–â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:    val_auc/dataloader_idx_9 â–â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:   val_loss/dataloader_idx_0 â–ˆâ–…â–†â–†â–‚â–ˆâ–â–‚â–„â–â–„â–†â–ƒâ–†
wandb:   val_loss/dataloader_idx_1 â–ˆâ–…â–†â–†â–‚â–ˆâ–â–‚â–„â–â–„â–†â–„â–‡
wandb:  val_loss/dataloader_idx_10 â–ƒâ–‚â–…â–†â–‚â–ˆâ–â–‚â–„â–â–‚â–…â–‚â–…
wandb:  val_loss/dataloader_idx_11 â–‚â–‚â–…â–†â–‚â–ˆâ–â–‚â–„â–â–ƒâ–…â–ƒâ–…
wandb:   val_loss/dataloader_idx_2 â–ˆâ–…â–†â–†â–‚â–ˆâ–â–‚â–„â–â–„â–†â–ƒâ–‡
wandb:   val_loss/dataloader_idx_3 â–ˆâ–…â–†â–†â–‚â–ˆâ–â–â–„â–â–ƒâ–†â–ƒâ–†
wandb:   val_loss/dataloader_idx_4 â–ˆâ–…â–†â–†â–‚â–ˆâ–â–â–„â–â–ƒâ–…â–ƒâ–†
wandb:   val_loss/dataloader_idx_5 â–ˆâ–…â–†â–†â–‚â–ˆâ–â–‚â–„â–â–ƒâ–†â–ƒâ–‡
wandb:   val_loss/dataloader_idx_6 â–ˆâ–…â–…â–†â–‚â–ˆâ–â–‚â–„â–â–ƒâ–†â–ƒâ–†
wandb:   val_loss/dataloader_idx_7 â–‡â–…â–†â–†â–‚â–ˆâ–â–‚â–„â–â–ƒâ–…â–‚â–†
wandb:   val_loss/dataloader_idx_8 â–…â–„â–…â–†â–‚â–ˆâ–â–‚â–„â–â–ƒâ–…â–ƒâ–†
wandb:   val_loss/dataloader_idx_9 â–ƒâ–ƒâ–…â–†â–‚â–ˆâ–â–‚â–„â–â–ƒâ–…â–‚â–…
wandb: 
wandb: Run summary:
wandb:                       epoch 14
wandb:                    test_auc 0.71321
wandb:   test_auc/dataloader_idx_0 0.83019
wandb:   test_auc/dataloader_idx_1 0.84002
wandb:  test_auc/dataloader_idx_10 0.74368
wandb:  test_auc/dataloader_idx_11 0.71321
wandb:   test_auc/dataloader_idx_2 0.84544
wandb:   test_auc/dataloader_idx_3 0.83793
wandb:   test_auc/dataloader_idx_4 0.82702
wandb:   test_auc/dataloader_idx_5 0.82645
wandb:   test_auc/dataloader_idx_6 0.78684
wandb:   test_auc/dataloader_idx_7 0.79406
wandb:   test_auc/dataloader_idx_8 0.78361
wandb:   test_auc/dataloader_idx_9 0.75884
wandb:  test_loss/dataloader_idx_0 0.32677
wandb:  test_loss/dataloader_idx_1 0.32839
wandb: test_loss/dataloader_idx_10 0.37749
wandb: test_loss/dataloader_idx_11 0.38998
wandb:  test_loss/dataloader_idx_2 0.3332
wandb:  test_loss/dataloader_idx_3 0.31715
wandb:  test_loss/dataloader_idx_4 0.32126
wandb:  test_loss/dataloader_idx_5 0.3133
wandb:  test_loss/dataloader_idx_6 0.34211
wandb:  test_loss/dataloader_idx_7 0.32513
wandb:  test_loss/dataloader_idx_8 0.35251
wandb:  test_loss/dataloader_idx_9 0.36049
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.38508
wandb:             train_loss_step 0.54738
wandb:         trainer/global_step 88522
wandb:    val_auc/dataloader_idx_0 0.83286
wandb:    val_auc/dataloader_idx_1 0.83946
wandb:   val_auc/dataloader_idx_10 0.73815
wandb:   val_auc/dataloader_idx_11 0.72122
wandb:    val_auc/dataloader_idx_2 0.83635
wandb:    val_auc/dataloader_idx_3 0.84747
wandb:    val_auc/dataloader_idx_4 0.82979
wandb:    val_auc/dataloader_idx_5 0.80845
wandb:    val_auc/dataloader_idx_6 0.80916
wandb:    val_auc/dataloader_idx_7 0.78624
wandb:    val_auc/dataloader_idx_8 0.77626
wandb:    val_auc/dataloader_idx_9 0.75427
wandb:   val_loss/dataloader_idx_0 0.35293
wandb:   val_loss/dataloader_idx_1 0.36486
wandb:  val_loss/dataloader_idx_10 0.41106
wandb:  val_loss/dataloader_idx_11 0.42182
wandb:   val_loss/dataloader_idx_2 0.36322
wandb:   val_loss/dataloader_idx_3 0.3459
wandb:   val_loss/dataloader_idx_4 0.35548
wandb:   val_loss/dataloader_idx_5 0.3613
wandb:   val_loss/dataloader_idx_6 0.35754
wandb:   val_loss/dataloader_idx_7 0.36632
wandb:   val_loss/dataloader_idx_8 0.38856
wandb:   val_loss/dataloader_idx_9 0.39051
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2013-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/c30xypgy
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260124_124558-c30xypgy/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260124_190338-5m0s4din
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2014-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/5m0s4din
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2014.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2014.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82828974723815â€¦ â”‚ 0.84200322628021â€¦ â”‚ 0.8510475158691â€¦ â”‚
â”‚     test_loss     â”‚ 0.32116612792015â€¦ â”‚ 0.31856757402420â€¦ â”‚ 0.3214726448059â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.84442514181137â€¦ â”‚ 0.82888400554656â€¦ â”‚ 0.8305673599243â€¦ â”‚
â”‚     test_loss     â”‚ 0.30371874570846â€¦ â”‚ 0.31137561798095â€¦ â”‚ 0.3089558184146â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.790842592716217 â”‚ 0.79973125457763â€¦ â”‚ 0.7839469909667â€¦ â”‚
â”‚     test_loss     â”‚ 0.336234450340271 â”‚ 0.32082614302635â€¦ â”‚ 0.3492417633533â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.75950515270233â€¦ â”‚ 0.74275147914886â€¦ â”‚ 0.7110508680343â€¦ â”‚
â”‚     test_loss     â”‚ 0.34931784868240â€¦ â”‚ 0.36181527376174â€¦ â”‚ 0.3730067610740â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–…â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–†â–„â–ƒâ–‚â–
wandb:             train_loss_step â–†â–‚â–‚â–ƒâ–‚â–‚â–„â–â–ƒâ–‚â–â–â–ƒâ–â–â–‚â–â–‚â–â–ƒâ–â–â–â–‚â–‚â–â–‚â–‚â–„â–ƒâ–â–â–‚â–â–â–‚â–â–â–â–ˆ
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_0 â–â–‚â–…â–‡â–…â–ˆ
wandb:    val_auc/dataloader_idx_1 â–ƒâ–â–ˆâ–…â–„â–‡
wandb:   val_auc/dataloader_idx_10 â–ˆâ–‡â–„â–ƒâ–‚â–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–ˆâ–‚â–„â–â–ƒ
wandb:    val_auc/dataloader_idx_2 â–â–‚â–ˆâ–†â–…â–‡
wandb:    val_auc/dataloader_idx_3 â–‚â–†â–â–‡â–ˆâ–‡
wandb:    val_auc/dataloader_idx_4 â–â–„â–„â–…â–†â–ˆ
wandb:    val_auc/dataloader_idx_5 â–â–â–‚â–„â–ˆâ–†
wandb:    val_auc/dataloader_idx_6 â–â–ƒâ–ƒâ–‚â–ˆâ–„
wandb:    val_auc/dataloader_idx_7 â–â–‚â–ƒâ–…â–†â–ˆ
wandb:    val_auc/dataloader_idx_8 â–ˆâ–‡â–â–„â–‚â–ƒ
wandb:    val_auc/dataloader_idx_9 â–ˆâ–†â–â–„â–‚â–‚
wandb:   val_loss/dataloader_idx_0 â–ˆâ–â–ˆâ–„â–‡â–†
wandb:   val_loss/dataloader_idx_1 â–ˆâ–â–‡â–…â–ˆâ–‡
wandb:  val_loss/dataloader_idx_10 â–ˆâ–â–‡â–…â–‡â–ˆ
wandb:  val_loss/dataloader_idx_11 â–ˆâ–â–‡â–…â–†â–ˆ
wandb:   val_loss/dataloader_idx_2 â–ˆâ–â–ˆâ–…â–‡â–‡
wandb:   val_loss/dataloader_idx_3 â–ˆâ–â–ˆâ–„â–†â–†
wandb:   val_loss/dataloader_idx_4 â–ˆâ–â–‡â–„â–†â–†
wandb:   val_loss/dataloader_idx_5 â–ˆâ–â–ˆâ–„â–†â–‡
wandb:   val_loss/dataloader_idx_6 â–ˆâ–â–ˆâ–„â–†â–‡
wandb:   val_loss/dataloader_idx_7 â–‡â–â–ˆâ–„â–†â–‡
wandb:   val_loss/dataloader_idx_8 â–‡â–â–ˆâ–…â–‡â–ˆ
wandb:   val_loss/dataloader_idx_9 â–ˆâ–â–†â–…â–‡â–‡
wandb: 
wandb: Run summary:
wandb:                       epoch 6
wandb:                    test_auc 0.71105
wandb:   test_auc/dataloader_idx_0 0.82829
wandb:   test_auc/dataloader_idx_1 0.842
wandb:  test_auc/dataloader_idx_10 0.74275
wandb:  test_auc/dataloader_idx_11 0.71105
wandb:   test_auc/dataloader_idx_2 0.85105
wandb:   test_auc/dataloader_idx_3 0.84443
wandb:   test_auc/dataloader_idx_4 0.82888
wandb:   test_auc/dataloader_idx_5 0.83057
wandb:   test_auc/dataloader_idx_6 0.79084
wandb:   test_auc/dataloader_idx_7 0.79973
wandb:   test_auc/dataloader_idx_8 0.78395
wandb:   test_auc/dataloader_idx_9 0.75951
wandb:  test_loss/dataloader_idx_0 0.32117
wandb:  test_loss/dataloader_idx_1 0.31857
wandb: test_loss/dataloader_idx_10 0.36182
wandb: test_loss/dataloader_idx_11 0.37301
wandb:  test_loss/dataloader_idx_2 0.32147
wandb:  test_loss/dataloader_idx_3 0.30372
wandb:  test_loss/dataloader_idx_4 0.31138
wandb:  test_loss/dataloader_idx_5 0.30896
wandb:  test_loss/dataloader_idx_6 0.33623
wandb:  test_loss/dataloader_idx_7 0.32083
wandb:  test_loss/dataloader_idx_8 0.34924
wandb:  test_loss/dataloader_idx_9 0.34932
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.4144
wandb:             train_loss_step 0.61935
wandb:         trainer/global_step 41424
wandb:    val_auc/dataloader_idx_0 0.84028
wandb:    val_auc/dataloader_idx_1 0.84699
wandb:   val_auc/dataloader_idx_10 0.73993
wandb:   val_auc/dataloader_idx_11 0.72353
wandb:    val_auc/dataloader_idx_2 0.84589
wandb:    val_auc/dataloader_idx_3 0.85546
wandb:    val_auc/dataloader_idx_4 0.83957
wandb:    val_auc/dataloader_idx_5 0.8178
wandb:    val_auc/dataloader_idx_6 0.81461
wandb:    val_auc/dataloader_idx_7 0.79305
wandb:    val_auc/dataloader_idx_8 0.78284
wandb:    val_auc/dataloader_idx_9 0.75915
wandb:   val_loss/dataloader_idx_0 0.29703
wandb:   val_loss/dataloader_idx_1 0.30777
wandb:  val_loss/dataloader_idx_10 0.36829
wandb:  val_loss/dataloader_idx_11 0.37594
wandb:   val_loss/dataloader_idx_2 0.30023
wandb:   val_loss/dataloader_idx_3 0.289
wandb:   val_loss/dataloader_idx_4 0.30304
wandb:   val_loss/dataloader_idx_5 0.31492
wandb:   val_loss/dataloader_idx_6 0.31574
wandb:   val_loss/dataloader_idx_7 0.3249
wandb:   val_loss/dataloader_idx_8 0.34855
wandb:   val_loss/dataloader_idx_9 0.35132
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2014-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/5m0s4din
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260124_190338-5m0s4din/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260124_220111-iysrz020
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2015-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/iysrz020
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2015.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2015.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82886636257171â€¦ â”‚ 0.84812879562377â€¦ â”‚ 0.8634088039398â€¦ â”‚
â”‚     test_loss     â”‚ 0.30397439002990â€¦ â”‚ 0.29942521452903â€¦ â”‚ 0.2966339886188â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.852135181427002 â”‚ 0.83840131759643â€¦ â”‚ 0.8376567363739â€¦ â”‚
â”‚     test_loss     â”‚ 0.278496652841568 â”‚ 0.29508954286575â€¦ â”‚ 0.2858358919620â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.79887473583221â€¦ â”‚ 0.80668056011199â€¦ â”‚ 0.7860447168350â€¦ â”‚
â”‚     test_loss     â”‚ 0.31512251496315  â”‚ 0.29844087362289â€¦ â”‚ 0.3274447321891â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.75156420469284â€¦ â”‚ 0.74228978157043â€¦ â”‚ 0.7137667536735â€¦ â”‚
â”‚     test_loss     â”‚ 0.32731136679649â€¦ â”‚ 0.33935451507568â€¦ â”‚ 0.3504121899604â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–‡â–‡â–‡â–…â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–‡â–†â–…â–„â–„â–‚â–‚â–
wandb:             train_loss_step â–ƒâ–â–‚â–â–â–†â–â–â–‚â–‚â–†â–â–‚â–‚â–â–‚â–ƒâ–„â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–â–‚â–ˆâ–â–ƒâ–ƒâ–‚â–‚â–â–…â–â–‚â–â–ƒâ–â–
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–ˆâ–‡â–‡â–‡â–„â–ƒâ–‚â–
wandb:    val_auc/dataloader_idx_1 â–…â–â–ˆâ–ƒâ–‡â–„â–ƒâ–„â–
wandb:   val_auc/dataloader_idx_10 â–‡â–ˆâ–ˆâ–†â–‡â–‡â–ƒâ–ƒâ–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–ˆâ–ˆâ–…â–‡â–‡â–â–„â–‚
wandb:    val_auc/dataloader_idx_2 â–â–ƒâ–†â–…â–ˆâ–ˆâ–‡â–„â–ƒ
wandb:    val_auc/dataloader_idx_3 â–…â–†â–‡â–ˆâ–†â–†â–„â–„â–
wandb:    val_auc/dataloader_idx_4 â–â–ƒâ–‡â–†â–‡â–ˆâ–ˆâ–†â–„
wandb:    val_auc/dataloader_idx_5 â–‡â–‡â–ˆâ–‡â–‡â–‡â–…â–…â–
wandb:    val_auc/dataloader_idx_6 â–†â–ˆâ–ˆâ–†â–ˆâ–…â–‡â–„â–
wandb:    val_auc/dataloader_idx_7 â–â–ƒâ–…â–†â–ˆâ–…â–„â–…â–„
wandb:    val_auc/dataloader_idx_8 â–ˆâ–‡â–ˆâ–…â–‡â–…â–â–ƒâ–
wandb:    val_auc/dataloader_idx_9 â–ˆâ–‡â–ˆâ–†â–†â–…â–‚â–‚â–
wandb:   val_loss/dataloader_idx_0 â–†â–‡â–„â–â–ƒâ–‚â–ˆâ–â–‚
wandb:   val_loss/dataloader_idx_1 â–‡â–ˆâ–…â–â–ƒâ–‚â–ˆâ–â–‚
wandb:  val_loss/dataloader_idx_10 â–ˆâ–‡â–…â–â–ƒâ–‚â–ƒâ–â–
wandb:  val_loss/dataloader_idx_11 â–ˆâ–‡â–†â–â–ƒâ–‚â–„â–â–
wandb:   val_loss/dataloader_idx_2 â–‡â–ˆâ–…â–‚â–„â–‚â–‡â–â–‚
wandb:   val_loss/dataloader_idx_3 â–‡â–ˆâ–…â–â–„â–‚â–‡â–‚â–‚
wandb:   val_loss/dataloader_idx_4 â–‡â–ˆâ–…â–â–ƒâ–‚â–†â–â–‚
wandb:   val_loss/dataloader_idx_5 â–‡â–ˆâ–…â–â–ƒâ–‚â–‡â–‚â–ƒ
wandb:   val_loss/dataloader_idx_6 â–‡â–ˆâ–…â–â–ƒâ–‚â–†â–â–‚
wandb:   val_loss/dataloader_idx_7 â–‡â–ˆâ–…â–â–ƒâ–‚â–†â–â–‚
wandb:   val_loss/dataloader_idx_8 â–ˆâ–ˆâ–†â–â–‚â–‚â–…â–â–‚
wandb:   val_loss/dataloader_idx_9 â–ˆâ–‡â–…â–â–‚â–‚â–ƒâ–â–
wandb: 
wandb: Run summary:
wandb:                       epoch 9
wandb:                    test_auc 0.71377
wandb:   test_auc/dataloader_idx_0 0.82887
wandb:   test_auc/dataloader_idx_1 0.84813
wandb:  test_auc/dataloader_idx_10 0.74229
wandb:  test_auc/dataloader_idx_11 0.71377
wandb:   test_auc/dataloader_idx_2 0.86341
wandb:   test_auc/dataloader_idx_3 0.85214
wandb:   test_auc/dataloader_idx_4 0.8384
wandb:   test_auc/dataloader_idx_5 0.83766
wandb:   test_auc/dataloader_idx_6 0.79887
wandb:   test_auc/dataloader_idx_7 0.80668
wandb:   test_auc/dataloader_idx_8 0.78604
wandb:   test_auc/dataloader_idx_9 0.75156
wandb:  test_loss/dataloader_idx_0 0.30397
wandb:  test_loss/dataloader_idx_1 0.29943
wandb: test_loss/dataloader_idx_10 0.33935
wandb: test_loss/dataloader_idx_11 0.35041
wandb:  test_loss/dataloader_idx_2 0.29663
wandb:  test_loss/dataloader_idx_3 0.2785
wandb:  test_loss/dataloader_idx_4 0.29509
wandb:  test_loss/dataloader_idx_5 0.28584
wandb:  test_loss/dataloader_idx_6 0.31512
wandb:  test_loss/dataloader_idx_7 0.29844
wandb:  test_loss/dataloader_idx_8 0.32744
wandb:  test_loss/dataloader_idx_9 0.32731
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.35986
wandb:             train_loss_step 0.28333
wandb:         trainer/global_step 65790
wandb:    val_auc/dataloader_idx_0 0.82815
wandb:    val_auc/dataloader_idx_1 0.84507
wandb:   val_auc/dataloader_idx_10 0.73732
wandb:   val_auc/dataloader_idx_11 0.72209
wandb:    val_auc/dataloader_idx_2 0.8503
wandb:    val_auc/dataloader_idx_3 0.85384
wandb:    val_auc/dataloader_idx_4 0.84306
wandb:    val_auc/dataloader_idx_5 0.81297
wandb:    val_auc/dataloader_idx_6 0.81199
wandb:    val_auc/dataloader_idx_7 0.79467
wandb:    val_auc/dataloader_idx_8 0.7776
wandb:    val_auc/dataloader_idx_9 0.7479
wandb:   val_loss/dataloader_idx_0 0.29439
wandb:   val_loss/dataloader_idx_1 0.29664
wandb:  val_loss/dataloader_idx_10 0.33055
wandb:  val_loss/dataloader_idx_11 0.33798
wandb:   val_loss/dataloader_idx_2 0.27806
wandb:   val_loss/dataloader_idx_3 0.27497
wandb:   val_loss/dataloader_idx_4 0.28463
wandb:   val_loss/dataloader_idx_5 0.30205
wandb:   val_loss/dataloader_idx_6 0.29688
wandb:   val_loss/dataloader_idx_7 0.30464
wandb:   val_loss/dataloader_idx_8 0.32417
wandb:   val_loss/dataloader_idx_9 0.31893
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2015-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/iysrz020
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260124_220111-iysrz020/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260125_022628-6mf0hnf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2016-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/6mf0hnf4
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2016.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2016.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82931149005889â€¦ â”‚ 0.84022158384323â€¦ â”‚ 0.8574063181877â€¦ â”‚
â”‚     test_loss     â”‚ 0.32778024673461â€¦ â”‚ 0.32307001948356â€¦ â”‚ 0.3218824565410â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.856165885925293 â”‚ 0.84789168834686â€¦ â”‚ 0.8486134409904â€¦ â”‚
â”‚     test_loss     â”‚ 0.30644309520721â€¦ â”‚ 0.33124443888664â€¦ â”‚ 0.3361267745494â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80358362197875â€¦ â”‚ 0.81727564334869â€¦ â”‚ 0.7915452718734â€¦ â”‚
â”‚     test_loss     â”‚ 0.36786556243896â€¦ â”‚ 0.35139015316963â€¦ â”‚ 0.3770292401313â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.75434935092926â€¦ â”‚ 0.74550664424896â€¦ â”‚ 0.7137989401817â€¦ â”‚
â”‚     test_loss     â”‚ 0.37191793322563â€¦ â”‚ 0.39250653982162â€¦ â”‚ 0.3997088372707â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–…â–†â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–‚â–
wandb:             train_loss_step â–‚â–â–â–â–„â–â–ƒâ–â–ƒâ–‚â–‚â–â–‚â–â–â–‚â–â–ƒâ–ƒâ–ƒâ–ˆâ–‚â–â–â–‚â–‚â–‡â–‚â–â–‚â–â–â–â–‚â–â–ƒâ–â–‡â–‚â–‚
wandb:         trainer/global_step â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_0 â–‡â–ˆâ–‡â–ˆâ–†â–…â–…â–…â–â–‚
wandb:    val_auc/dataloader_idx_1 â–‡â–ˆâ–ˆâ–‡â–‡â–…â–†â–†â–…â–
wandb:   val_auc/dataloader_idx_10 â–ˆâ–‡â–‡â–‡â–…â–…â–†â–…â–„â–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–‡â–‡â–‡â–†â–…â–†â–…â–ƒâ–
wandb:    val_auc/dataloader_idx_2 â–‡â–ˆâ–ˆâ–†â–‡â–…â–…â–…â–‚â–
wandb:    val_auc/dataloader_idx_3 â–„â–…â–‡â–‡â–†â–†â–ˆâ–ˆâ–ƒâ–
wandb:    val_auc/dataloader_idx_4 â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–„â–
wandb:    val_auc/dataloader_idx_5 â–‡â–ˆâ–‡â–ˆâ–ˆâ–†â–‡â–†â–„â–
wandb:    val_auc/dataloader_idx_6 â–†â–†â–‡â–ˆâ–ˆâ–†â–†â–‡â–„â–
wandb:    val_auc/dataloader_idx_7 â–…â–‡â–‡â–ˆâ–ˆâ–‡â–†â–†â–„â–
wandb:    val_auc/dataloader_idx_8 â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–ˆâ–†â–…â–
wandb:    val_auc/dataloader_idx_9 â–ˆâ–ˆâ–ˆâ–‡â–†â–…â–‡â–…â–„â–
wandb:   val_loss/dataloader_idx_0 â–â–„â–ƒâ–â–ƒâ–ƒâ–ƒâ–‡â–‡â–ˆ
wandb:   val_loss/dataloader_idx_1 â–â–ƒâ–‚â–â–‚â–ƒâ–ƒâ–‡â–†â–ˆ
wandb:  val_loss/dataloader_idx_10 â–â–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–†â–ˆâ–‡
wandb:  val_loss/dataloader_idx_11 â–â–ƒâ–ƒâ–â–‚â–ƒâ–„â–†â–ˆâ–‡
wandb:   val_loss/dataloader_idx_2 â–â–„â–ƒâ–â–‚â–ƒâ–ƒâ–‡â–‡â–ˆ
wandb:   val_loss/dataloader_idx_3 â–â–„â–ƒâ–â–ƒâ–ƒâ–ƒâ–†â–‡â–ˆ
wandb:   val_loss/dataloader_idx_4 â–â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–†â–†â–ˆ
wandb:   val_loss/dataloader_idx_5 â–â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–†â–†â–ˆ
wandb:   val_loss/dataloader_idx_6 â–â–ƒâ–ƒâ–â–ƒâ–„â–„â–‡â–‡â–ˆ
wandb:   val_loss/dataloader_idx_7 â–â–ƒâ–ƒâ–â–ƒâ–„â–„â–‡â–‡â–ˆ
wandb:   val_loss/dataloader_idx_8 â–â–ƒâ–ƒâ–â–‚â–„â–„â–‡â–‡â–ˆ
wandb:   val_loss/dataloader_idx_9 â–â–ƒâ–ƒâ–â–‚â–ƒâ–„â–†â–ˆâ–‡
wandb: 
wandb: Run summary:
wandb:                       epoch 10
wandb:                    test_auc 0.7138
wandb:   test_auc/dataloader_idx_0 0.82931
wandb:   test_auc/dataloader_idx_1 0.84022
wandb:  test_auc/dataloader_idx_10 0.74551
wandb:  test_auc/dataloader_idx_11 0.7138
wandb:   test_auc/dataloader_idx_2 0.85741
wandb:   test_auc/dataloader_idx_3 0.85617
wandb:   test_auc/dataloader_idx_4 0.84789
wandb:   test_auc/dataloader_idx_5 0.84861
wandb:   test_auc/dataloader_idx_6 0.80358
wandb:   test_auc/dataloader_idx_7 0.81728
wandb:   test_auc/dataloader_idx_8 0.79155
wandb:   test_auc/dataloader_idx_9 0.75435
wandb:  test_loss/dataloader_idx_0 0.32778
wandb:  test_loss/dataloader_idx_1 0.32307
wandb: test_loss/dataloader_idx_10 0.39251
wandb: test_loss/dataloader_idx_11 0.39971
wandb:  test_loss/dataloader_idx_2 0.32188
wandb:  test_loss/dataloader_idx_3 0.30644
wandb:  test_loss/dataloader_idx_4 0.33124
wandb:  test_loss/dataloader_idx_5 0.33613
wandb:  test_loss/dataloader_idx_6 0.36787
wandb:  test_loss/dataloader_idx_7 0.35139
wandb:  test_loss/dataloader_idx_8 0.37703
wandb:  test_loss/dataloader_idx_9 0.37192
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.33598
wandb:             train_loss_step 0.15421
wandb:         trainer/global_step 84090
wandb:    val_auc/dataloader_idx_0 0.82901
wandb:    val_auc/dataloader_idx_1 0.83146
wandb:   val_auc/dataloader_idx_10 0.70867
wandb:   val_auc/dataloader_idx_11 0.70225
wandb:    val_auc/dataloader_idx_2 0.84437
wandb:    val_auc/dataloader_idx_3 0.86182
wandb:    val_auc/dataloader_idx_4 0.84562
wandb:    val_auc/dataloader_idx_5 0.81703
wandb:    val_auc/dataloader_idx_6 0.81742
wandb:    val_auc/dataloader_idx_7 0.79609
wandb:    val_auc/dataloader_idx_8 0.77396
wandb:    val_auc/dataloader_idx_9 0.73256
wandb:   val_loss/dataloader_idx_0 0.37517
wandb:   val_loss/dataloader_idx_1 0.39164
wandb:  val_loss/dataloader_idx_10 0.444
wandb:  val_loss/dataloader_idx_11 0.44652
wandb:   val_loss/dataloader_idx_2 0.37224
wandb:   val_loss/dataloader_idx_3 0.3751
wandb:   val_loss/dataloader_idx_4 0.41286
wandb:   val_loss/dataloader_idx_5 0.43231
wandb:   val_loss/dataloader_idx_6 0.44114
wandb:   val_loss/dataloader_idx_7 0.44493
wandb:   val_loss/dataloader_idx_8 0.4471
wandb:   val_loss/dataloader_idx_9 0.41229
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2016-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/6mf0hnf4
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260125_022628-6mf0hnf4/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260125_073429-1mc7evce
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2017-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/1mc7evce
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2017.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2017.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.84003919363021â€¦ â”‚ 0.84798157215118â€¦ â”‚ 0.8666059970855â€¦ â”‚
â”‚     test_loss     â”‚ 0.28952395915985â€¦ â”‚ 0.29061502218246â€¦ â”‚ 0.2798771560192â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.85919564962387â€¦ â”‚ 0.84986406564712â€¦ â”‚ 0.8580517172813â€¦ â”‚
â”‚     test_loss     â”‚ 0.27441540360450â€¦ â”‚ 0.28915619850158â€¦ â”‚ 0.2797089517116â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81199061870574â€¦ â”‚ 0.81815433502197â€¦ â”‚ 0.8012585639953â€¦ â”‚
â”‚     test_loss     â”‚ 0.30859050154685â€¦ â”‚ 0.29089519381523â€¦ â”‚ 0.3227223753929â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.75846564769744â€¦ â”‚ 0.74521064758300â€¦ â”‚ 0.7222779989242â€¦ â”‚
â”‚     test_loss     â”‚ 0.33266425132751â€¦ â”‚ 0.35150396823883â€¦ â”‚ 0.3524526655673â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–…â–†â–…â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–†â–…â–„â–ƒâ–‚â–
wandb:             train_loss_step â–…â–‚â–‚â–‚â–â–‚â–†â–â–‚â–â–â–ƒâ–„â–ˆâ–‚â–‚â–‚â–ƒâ–…â–‚â–‚â–‚â–ƒâ–ƒâ–…â–‚â–‚â–„â–„â–‚â–‚â–â–„â–â–‚â–‚â–â–â–‚â–„
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–ˆâ–…â–ƒâ–‚â–‚â–
wandb:    val_auc/dataloader_idx_1 â–†â–ˆâ–ˆâ–‚â–„â–â–‚
wandb:   val_auc/dataloader_idx_10 â–ˆâ–ˆâ–‡â–†â–ƒâ–ƒâ–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–ˆâ–†â–†â–‚â–ƒâ–
wandb:    val_auc/dataloader_idx_2 â–ˆâ–ˆâ–‡â–…â–ƒâ–‚â–
wandb:    val_auc/dataloader_idx_3 â–ƒâ–ˆâ–„â–ˆâ–â–„â–‚
wandb:    val_auc/dataloader_idx_4 â–„â–†â–…â–ˆâ–†â–â–
wandb:    val_auc/dataloader_idx_5 â–‡â–„â–„â–ˆâ–†â–â–ƒ
wandb:    val_auc/dataloader_idx_6 â–‡â–ˆâ–‡â–‡â–…â–‚â–
wandb:    val_auc/dataloader_idx_7 â–â–‚â–„â–ˆâ–„â–‡â–ƒ
wandb:    val_auc/dataloader_idx_8 â–ˆâ–‡â–†â–…â–ƒâ–â–
wandb:    val_auc/dataloader_idx_9 â–‡â–ˆâ–†â–†â–â–‚â–
wandb:   val_loss/dataloader_idx_0 â–ˆâ–â–ƒâ–â–†â–ƒâ–„
wandb:   val_loss/dataloader_idx_1 â–ˆâ–‚â–ƒâ–â–…â–ƒâ–ƒ
wandb:  val_loss/dataloader_idx_10 â–ˆâ–‚â–ƒâ–â–ƒâ–‚â–
wandb:  val_loss/dataloader_idx_11 â–ˆâ–‚â–ƒâ–â–ƒâ–‚â–
wandb:   val_loss/dataloader_idx_2 â–ˆâ–‚â–ƒâ–â–…â–ƒâ–ƒ
wandb:   val_loss/dataloader_idx_3 â–ˆâ–‚â–ƒâ–â–„â–ƒâ–ƒ
wandb:   val_loss/dataloader_idx_4 â–ˆâ–‚â–ƒâ–â–„â–ƒâ–ƒ
wandb:   val_loss/dataloader_idx_5 â–ˆâ–‚â–ƒâ–â–„â–ƒâ–ƒ
wandb:   val_loss/dataloader_idx_6 â–ˆâ–‚â–ƒâ–â–„â–ƒâ–ƒ
wandb:   val_loss/dataloader_idx_7 â–ˆâ–‚â–ƒâ–â–„â–‚â–‚
wandb:   val_loss/dataloader_idx_8 â–ˆâ–‚â–ƒâ–â–ƒâ–‚â–‚
wandb:   val_loss/dataloader_idx_9 â–ˆâ–‚â–ƒâ–â–ƒâ–‚â–
wandb: 
wandb: Run summary:
wandb:                       epoch 7
wandb:                    test_auc 0.72228
wandb:   test_auc/dataloader_idx_0 0.84004
wandb:   test_auc/dataloader_idx_1 0.84798
wandb:  test_auc/dataloader_idx_10 0.74521
wandb:  test_auc/dataloader_idx_11 0.72228
wandb:   test_auc/dataloader_idx_2 0.86661
wandb:   test_auc/dataloader_idx_3 0.8592
wandb:   test_auc/dataloader_idx_4 0.84986
wandb:   test_auc/dataloader_idx_5 0.85805
wandb:   test_auc/dataloader_idx_6 0.81199
wandb:   test_auc/dataloader_idx_7 0.81815
wandb:   test_auc/dataloader_idx_8 0.80126
wandb:   test_auc/dataloader_idx_9 0.75847
wandb:  test_loss/dataloader_idx_0 0.28952
wandb:  test_loss/dataloader_idx_1 0.29062
wandb: test_loss/dataloader_idx_10 0.3515
wandb: test_loss/dataloader_idx_11 0.35245
wandb:  test_loss/dataloader_idx_2 0.27988
wandb:  test_loss/dataloader_idx_3 0.27442
wandb:  test_loss/dataloader_idx_4 0.28916
wandb:  test_loss/dataloader_idx_5 0.27971
wandb:  test_loss/dataloader_idx_6 0.30859
wandb:  test_loss/dataloader_idx_7 0.2909
wandb:  test_loss/dataloader_idx_8 0.32272
wandb:  test_loss/dataloader_idx_9 0.33266
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.37659
wandb:             train_loss_step 1.23296
wandb:         trainer/global_step 81480
wandb:    val_auc/dataloader_idx_0 0.83033
wandb:    val_auc/dataloader_idx_1 0.84653
wandb:   val_auc/dataloader_idx_10 0.7318
wandb:   val_auc/dataloader_idx_11 0.71961
wandb:    val_auc/dataloader_idx_2 0.85138
wandb:    val_auc/dataloader_idx_3 0.87348
wandb:    val_auc/dataloader_idx_4 0.85638
wandb:    val_auc/dataloader_idx_5 0.83135
wandb:    val_auc/dataloader_idx_6 0.82532
wandb:    val_auc/dataloader_idx_7 0.80841
wandb:    val_auc/dataloader_idx_8 0.78961
wandb:    val_auc/dataloader_idx_9 0.7511
wandb:   val_loss/dataloader_idx_0 0.31138
wandb:   val_loss/dataloader_idx_1 0.30588
wandb:  val_loss/dataloader_idx_10 0.35248
wandb:  val_loss/dataloader_idx_11 0.35537
wandb:   val_loss/dataloader_idx_2 0.29189
wandb:   val_loss/dataloader_idx_3 0.28867
wandb:   val_loss/dataloader_idx_4 0.31116
wandb:   val_loss/dataloader_idx_5 0.31484
wandb:   val_loss/dataloader_idx_6 0.31154
wandb:   val_loss/dataloader_idx_7 0.31167
wandb:   val_loss/dataloader_idx_8 0.33412
wandb:   val_loss/dataloader_idx_9 0.3339
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2017-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/1mc7evce
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260125_073429-1mc7evce/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260125_115408-3ik85xrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2018-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/3ik85xrc
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2018.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2018.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83364433050155â€¦ â”‚ 0.84736639261245â€¦ â”‚ 0.8633315563201â€¦ â”‚
â”‚     test_loss     â”‚ 0.33176353573799â€¦ â”‚ 0.32873433828353â€¦ â”‚ 0.3287944793701â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.86184740066528â€¦ â”‚ 0.84902167320251â€¦ â”‚ 0.8578163385391â€¦ â”‚
â”‚     test_loss     â”‚ 0.32036280632019â€¦ â”‚ 0.33932828903198â€¦ â”‚ 0.3386580348014â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81525629758834â€¦ â”‚ 0.82208573818206â€¦ â”‚ 0.8035846948623â€¦ â”‚
â”‚     test_loss     â”‚ 0.36286988854408â€¦ â”‚ 0.34650993347167â€¦ â”‚ 0.3680952191352â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.76072925329208â€¦ â”‚ 0.75262457132339â€¦ â”‚ 0.7268364429473â€¦ â”‚
â”‚     test_loss     â”‚ 0.37502276897430â€¦ â”‚ 0.39527830481529â€¦ â”‚ 0.3990338146686â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–†â–…â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–†â–ƒâ–
wandb:             train_loss_step â–‚â–‚â–‚â–‚â–„â–„â–ƒâ–â–‚â–â–ƒâ–â–‚â–‚â–†â–‚â–â–‚â–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–ˆâ–„â–ƒâ–â–‡â–‚â–â–„â–„â–‚â–‚â–‚â–â–„â–ƒâ–‚
wandb:         trainer/global_step â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–†â–ˆâ–ƒâ–
wandb:    val_auc/dataloader_idx_1 â–‚â–ˆâ–â–„
wandb:   val_auc/dataloader_idx_10 â–‡â–ˆâ–ƒâ–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–ˆâ–ƒâ–
wandb:    val_auc/dataloader_idx_2 â–„â–ˆâ–â–‚
wandb:    val_auc/dataloader_idx_3 â–â–‡â–…â–ˆ
wandb:    val_auc/dataloader_idx_4 â–â–†â–ˆâ–†
wandb:    val_auc/dataloader_idx_5 â–ˆâ–â–‚â–ƒ
wandb:    val_auc/dataloader_idx_6 â–â–ˆâ–…â–…
wandb:    val_auc/dataloader_idx_7 â–â–‡â–†â–ˆ
wandb:    val_auc/dataloader_idx_8 â–„â–ˆâ–â–
wandb:    val_auc/dataloader_idx_9 â–‡â–ˆâ–„â–
wandb:   val_loss/dataloader_idx_0 â–ˆâ–…â–â–†
wandb:   val_loss/dataloader_idx_1 â–ˆâ–…â–â–†
wandb:  val_loss/dataloader_idx_10 â–ˆâ–†â–â–†
wandb:  val_loss/dataloader_idx_11 â–ˆâ–†â–â–†
wandb:   val_loss/dataloader_idx_2 â–ˆâ–…â–â–†
wandb:   val_loss/dataloader_idx_3 â–ˆâ–„â–â–…
wandb:   val_loss/dataloader_idx_4 â–ˆâ–„â–â–…
wandb:   val_loss/dataloader_idx_5 â–ˆâ–„â–â–†
wandb:   val_loss/dataloader_idx_6 â–ˆâ–„â–â–†
wandb:   val_loss/dataloader_idx_7 â–ˆâ–…â–â–†
wandb:   val_loss/dataloader_idx_8 â–ˆâ–…â–â–…
wandb:   val_loss/dataloader_idx_9 â–ˆâ–…â–â–†
wandb: 
wandb: Run summary:
wandb:                       epoch 4
wandb:                    test_auc 0.72684
wandb:   test_auc/dataloader_idx_0 0.83364
wandb:   test_auc/dataloader_idx_1 0.84737
wandb:  test_auc/dataloader_idx_10 0.75262
wandb:  test_auc/dataloader_idx_11 0.72684
wandb:   test_auc/dataloader_idx_2 0.86333
wandb:   test_auc/dataloader_idx_3 0.86185
wandb:   test_auc/dataloader_idx_4 0.84902
wandb:   test_auc/dataloader_idx_5 0.85782
wandb:   test_auc/dataloader_idx_6 0.81526
wandb:   test_auc/dataloader_idx_7 0.82209
wandb:   test_auc/dataloader_idx_8 0.80358
wandb:   test_auc/dataloader_idx_9 0.76073
wandb:  test_loss/dataloader_idx_0 0.33176
wandb:  test_loss/dataloader_idx_1 0.32873
wandb: test_loss/dataloader_idx_10 0.39528
wandb: test_loss/dataloader_idx_11 0.39903
wandb:  test_loss/dataloader_idx_2 0.32879
wandb:  test_loss/dataloader_idx_3 0.32036
wandb:  test_loss/dataloader_idx_4 0.33933
wandb:  test_loss/dataloader_idx_5 0.33866
wandb:  test_loss/dataloader_idx_6 0.36287
wandb:  test_loss/dataloader_idx_7 0.34651
wandb:  test_loss/dataloader_idx_8 0.3681
wandb:  test_loss/dataloader_idx_9 0.37502
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.40407
wandb:             train_loss_step 0.52841
wandb:         trainer/global_step 46612
wandb:    val_auc/dataloader_idx_0 0.83116
wandb:    val_auc/dataloader_idx_1 0.85107
wandb:   val_auc/dataloader_idx_10 0.73998
wandb:   val_auc/dataloader_idx_11 0.72999
wandb:    val_auc/dataloader_idx_2 0.85585
wandb:    val_auc/dataloader_idx_3 0.87529
wandb:    val_auc/dataloader_idx_4 0.86103
wandb:    val_auc/dataloader_idx_5 0.83571
wandb:    val_auc/dataloader_idx_6 0.83657
wandb:    val_auc/dataloader_idx_7 0.81552
wandb:    val_auc/dataloader_idx_8 0.79952
wandb:    val_auc/dataloader_idx_9 0.75918
wandb:   val_loss/dataloader_idx_0 0.31482
wandb:   val_loss/dataloader_idx_1 0.3149
wandb:  val_loss/dataloader_idx_10 0.37615
wandb:  val_loss/dataloader_idx_11 0.37798
wandb:   val_loss/dataloader_idx_2 0.29617
wandb:   val_loss/dataloader_idx_3 0.29478
wandb:   val_loss/dataloader_idx_4 0.31583
wandb:   val_loss/dataloader_idx_5 0.32682
wandb:   val_loss/dataloader_idx_6 0.3274
wandb:   val_loss/dataloader_idx_7 0.33448
wandb:   val_loss/dataloader_idx_8 0.34761
wandb:   val_loss/dataloader_idx_9 0.35429
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2018-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/3ik85xrc
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260125_115408-3ik85xrc/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260125_143512-niiwrdrk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2019-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/niiwrdrk
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2019.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2019.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83380925655364â€¦ â”‚ 0.84912884235382â€¦ â”‚ 0.8646747469902â€¦ â”‚
â”‚     test_loss     â”‚ 0.28631305694580â€¦ â”‚ 0.28886809945106â€¦ â”‚ 0.2805102765560â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.86347764730453â€¦ â”‚ 0.84932070970535â€¦ â”‚ 0.8610911369323â€¦ â”‚
â”‚     test_loss     â”‚ 0.27395913004875â€¦ â”‚ 0.29082766175270â€¦ â”‚ 0.2841347455978â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81976240873336â€¦ â”‚ 0.82576739788055â€¦ â”‚ 0.8033103942871â€¦ â”‚
â”‚     test_loss     â”‚ 0.311314195394516 â”‚ 0.29684165120124â€¦ â”‚ 0.3226186633110â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.76083755493164â€¦ â”‚ 0.75569206476211â€¦ â”‚ 0.7243167757987â€¦ â”‚
â”‚     test_loss     â”‚ 0.33238506317138â€¦ â”‚ 0.34688484668731â€¦ â”‚ 0.3525138795375â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb: uploading history steps 1375-1387, summary, console lines 29-58
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–†â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–†â–…â–ƒâ–
wandb:             train_loss_step â–‚â–„â–‚â–â–ƒâ–‚â–„â–‚â–‚â–‚â–â–â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–â–‚â–â–‚â–â–‡â–‚â–â–„â–‚â–ƒâ–â–ƒâ–â–‚â–ˆâ–ˆâ–‚â–ƒâ–ƒ
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–ˆâ–†â–…â–
wandb:    val_auc/dataloader_idx_1 â–…â–ˆâ–„â–‚â–
wandb:   val_auc/dataloader_idx_10 â–…â–‡â–„â–ˆâ–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–‡â–ˆâ–…â–
wandb:    val_auc/dataloader_idx_2 â–ˆâ–†â–„â–„â–
wandb:    val_auc/dataloader_idx_3 â–ˆâ–†â–ƒâ–ƒâ–
wandb:    val_auc/dataloader_idx_4 â–ˆâ–ˆâ–†â–†â–
wandb:    val_auc/dataloader_idx_5 â–‡â–ˆâ–…â–ƒâ–
wandb:    val_auc/dataloader_idx_6 â–‡â–ˆâ–„â–‡â–
wandb:    val_auc/dataloader_idx_7 â–â–‡â–†â–ˆâ–
wandb:    val_auc/dataloader_idx_8 â–ˆâ–…â–†â–â–‚
wandb:    val_auc/dataloader_idx_9 â–ˆâ–‡â–…â–†â–
wandb:   val_loss/dataloader_idx_0 â–ˆâ–â–ƒâ–„â–‡
wandb:   val_loss/dataloader_idx_1 â–ˆâ–â–„â–ƒâ–†
wandb:  val_loss/dataloader_idx_10 â–ˆâ–â–†â–ƒâ–‡
wandb:  val_loss/dataloader_idx_11 â–ˆâ–â–†â–„â–ˆ
wandb:   val_loss/dataloader_idx_2 â–ˆâ–â–„â–„â–ˆ
wandb:   val_loss/dataloader_idx_3 â–‡â–â–„â–„â–ˆ
wandb:   val_loss/dataloader_idx_4 â–†â–â–„â–ƒâ–ˆ
wandb:   val_loss/dataloader_idx_5 â–†â–â–„â–ƒâ–ˆ
wandb:   val_loss/dataloader_idx_6 â–†â–â–„â–ƒâ–ˆ
wandb:   val_loss/dataloader_idx_7 â–†â–â–„â–ƒâ–ˆ
wandb:   val_loss/dataloader_idx_8 â–ˆâ–â–…â–„â–ˆ
wandb:   val_loss/dataloader_idx_9 â–ˆâ–â–†â–ƒâ–‡
wandb: 
wandb: Run summary:
wandb:                       epoch 5
wandb:                    test_auc 0.72432
wandb:   test_auc/dataloader_idx_0 0.83381
wandb:   test_auc/dataloader_idx_1 0.84913
wandb:  test_auc/dataloader_idx_10 0.75569
wandb:  test_auc/dataloader_idx_11 0.72432
wandb:   test_auc/dataloader_idx_2 0.86467
wandb:   test_auc/dataloader_idx_3 0.86348
wandb:   test_auc/dataloader_idx_4 0.84932
wandb:   test_auc/dataloader_idx_5 0.86109
wandb:   test_auc/dataloader_idx_6 0.81976
wandb:   test_auc/dataloader_idx_7 0.82577
wandb:   test_auc/dataloader_idx_8 0.80331
wandb:   test_auc/dataloader_idx_9 0.76084
wandb:  test_loss/dataloader_idx_0 0.28631
wandb:  test_loss/dataloader_idx_1 0.28887
wandb: test_loss/dataloader_idx_10 0.34688
wandb: test_loss/dataloader_idx_11 0.35251
wandb:  test_loss/dataloader_idx_2 0.28051
wandb:  test_loss/dataloader_idx_3 0.27396
wandb:  test_loss/dataloader_idx_4 0.29083
wandb:  test_loss/dataloader_idx_5 0.28413
wandb:  test_loss/dataloader_idx_6 0.31131
wandb:  test_loss/dataloader_idx_7 0.29684
wandb:  test_loss/dataloader_idx_8 0.32262
wandb:  test_loss/dataloader_idx_9 0.33239
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.41631
wandb:             train_loss_step 0.28069
wandb:         trainer/global_step 68250
wandb:    val_auc/dataloader_idx_0 0.831
wandb:    val_auc/dataloader_idx_1 0.8493
wandb:   val_auc/dataloader_idx_10 0.74565
wandb:   val_auc/dataloader_idx_11 0.73479
wandb:    val_auc/dataloader_idx_2 0.85233
wandb:    val_auc/dataloader_idx_3 0.86709
wandb:    val_auc/dataloader_idx_4 0.85388
wandb:    val_auc/dataloader_idx_5 0.8309
wandb:    val_auc/dataloader_idx_6 0.83724
wandb:    val_auc/dataloader_idx_7 0.81306
wandb:    val_auc/dataloader_idx_8 0.79979
wandb:    val_auc/dataloader_idx_9 0.76152
wandb:   val_loss/dataloader_idx_0 0.30485
wandb:   val_loss/dataloader_idx_1 0.3054
wandb:  val_loss/dataloader_idx_10 0.39108
wandb:  val_loss/dataloader_idx_11 0.39238
wandb:   val_loss/dataloader_idx_2 0.29739
wandb:   val_loss/dataloader_idx_3 0.3049
wandb:   val_loss/dataloader_idx_4 0.33404
wandb:   val_loss/dataloader_idx_5 0.34644
wandb:   val_loss/dataloader_idx_6 0.34613
wandb:   val_loss/dataloader_idx_7 0.35873
wandb:   val_loss/dataloader_idx_8 0.36062
wandb:   val_loss/dataloader_idx_9 0.36222
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2019-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/niiwrdrk
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260125_143512-niiwrdrk/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260125_180327-twf4956n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2020-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/twf4956n
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2020.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2020.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.830958366394043 â”‚ 0.84211760759353â€¦ â”‚ 0.8629369735717â€¦ â”‚
â”‚     test_loss     â”‚ 0.29119980335235â€¦ â”‚ 0.29731774330139â€¦ â”‚ 0.2854399681091â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.85941278934478â€¦ â”‚ 0.84820538759231â€¦ â”‚ 0.8575572967529â€¦ â”‚
â”‚     test_loss     â”‚ 0.283873975276947 â”‚ 0.30049538612365â€¦ â”‚ 0.2984659075736â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82024639844894â€¦ â”‚ 0.82468438148498â€¦ â”‚ 0.8045157194137â€¦ â”‚
â”‚     test_loss     â”‚ 0.32689779996871â€¦ â”‚ 0.31754294037818â€¦ â”‚ 0.3452192842960â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.76834481954574â€¦ â”‚ 0.75752067565917â€¦ â”‚ 0.7337003946304â€¦ â”‚
â”‚     test_loss     â”‚ 0.36157113313674â€¦ â”‚ 0.375566303730011 â”‚ 0.3793078660964â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–†â–…â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–‡â–†â–„â–ƒâ–‚â–
wandb:             train_loss_step â–‚â–ƒâ–„â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–†â–‚â–†â–‚â–â–‚â–ƒâ–â–â–‚â–ƒâ–ƒâ–ƒâ–ˆâ–â–‚â–„â–‚â–„â–‚â–…â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb:         trainer/global_step â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–‡â–ˆâ–‡â–„â–…â–…â–
wandb:    val_auc/dataloader_idx_1 â–ˆâ–‡â–ˆâ–…â–…â–„â–
wandb:   val_auc/dataloader_idx_10 â–„â–ˆâ–†â–‡â–†â–â–…
wandb:   val_auc/dataloader_idx_11 â–…â–‡â–ˆâ–ˆâ–‡â–â–‡
wandb:    val_auc/dataloader_idx_2 â–ˆâ–†â–†â–ƒâ–…â–„â–
wandb:    val_auc/dataloader_idx_3 â–ˆâ–ˆâ–ˆâ–„â–…â–‡â–
wandb:    val_auc/dataloader_idx_4 â–‡â–ˆâ–†â–…â–…â–„â–
wandb:    val_auc/dataloader_idx_5 â–ˆâ–‡â–ˆâ–…â–†â–‡â–
wandb:    val_auc/dataloader_idx_6 â–†â–ˆâ–‡â–…â–„â–…â–
wandb:    val_auc/dataloader_idx_7 â–†â–‡â–ˆâ–ˆâ–‡â–‡â–
wandb:    val_auc/dataloader_idx_8 â–†â–ˆâ–‡â–…â–„â–â–
wandb:    val_auc/dataloader_idx_9 â–†â–ˆâ–†â–†â–†â–â–†
wandb:   val_loss/dataloader_idx_0 â–‚â–â–„â–‚â–‚â–ˆâ–‚
wandb:   val_loss/dataloader_idx_1 â–‚â–â–ƒâ–â–‚â–ˆâ–
wandb:  val_loss/dataloader_idx_10 â–ƒâ–â–ƒâ–â–‚â–ˆâ–‚
wandb:  val_loss/dataloader_idx_11 â–ƒâ–â–‚â–‚â–‚â–ˆâ–‚
wandb:   val_loss/dataloader_idx_2 â–‚â–â–ƒâ–‚â–‚â–ˆâ–‚
wandb:   val_loss/dataloader_idx_3 â–‚â–â–ƒâ–‚â–‚â–ˆâ–‚
wandb:   val_loss/dataloader_idx_4 â–‚â–â–ƒâ–‚â–‚â–ˆâ–‚
wandb:   val_loss/dataloader_idx_5 â–‚â–â–ƒâ–‚â–ƒâ–ˆâ–ƒ
wandb:   val_loss/dataloader_idx_6 â–‚â–â–ƒâ–‚â–ƒâ–ˆâ–ƒ
wandb:   val_loss/dataloader_idx_7 â–‚â–â–ƒâ–‚â–ƒâ–ˆâ–ƒ
wandb:   val_loss/dataloader_idx_8 â–‚â–â–ƒâ–‚â–‚â–ˆâ–‚
wandb:   val_loss/dataloader_idx_9 â–‚â–â–ƒâ–‚â–‚â–ˆâ–‚
wandb: 
wandb: Run summary:
wandb:                       epoch 7
wandb:                    test_auc 0.7337
wandb:   test_auc/dataloader_idx_0 0.83096
wandb:   test_auc/dataloader_idx_1 0.84212
wandb:  test_auc/dataloader_idx_10 0.75752
wandb:  test_auc/dataloader_idx_11 0.7337
wandb:   test_auc/dataloader_idx_2 0.86294
wandb:   test_auc/dataloader_idx_3 0.85941
wandb:   test_auc/dataloader_idx_4 0.84821
wandb:   test_auc/dataloader_idx_5 0.85756
wandb:   test_auc/dataloader_idx_6 0.82025
wandb:   test_auc/dataloader_idx_7 0.82468
wandb:   test_auc/dataloader_idx_8 0.80452
wandb:   test_auc/dataloader_idx_9 0.76834
wandb:  test_loss/dataloader_idx_0 0.2912
wandb:  test_loss/dataloader_idx_1 0.29732
wandb: test_loss/dataloader_idx_10 0.37557
wandb: test_loss/dataloader_idx_11 0.37931
wandb:  test_loss/dataloader_idx_2 0.28544
wandb:  test_loss/dataloader_idx_3 0.28387
wandb:  test_loss/dataloader_idx_4 0.3005
wandb:  test_loss/dataloader_idx_5 0.29847
wandb:  test_loss/dataloader_idx_6 0.3269
wandb:  test_loss/dataloader_idx_7 0.31754
wandb:  test_loss/dataloader_idx_8 0.34522
wandb:  test_loss/dataloader_idx_9 0.36157
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.41701
wandb:             train_loss_step 0.34311
wandb:         trainer/global_step 119777
wandb:    val_auc/dataloader_idx_0 0.82283
wandb:    val_auc/dataloader_idx_1 0.84076
wandb:   val_auc/dataloader_idx_10 0.75335
wandb:   val_auc/dataloader_idx_11 0.74336
wandb:    val_auc/dataloader_idx_2 0.84546
wandb:    val_auc/dataloader_idx_3 0.86307
wandb:    val_auc/dataloader_idx_4 0.85631
wandb:    val_auc/dataloader_idx_5 0.82743
wandb:    val_auc/dataloader_idx_6 0.83687
wandb:    val_auc/dataloader_idx_7 0.81444
wandb:    val_auc/dataloader_idx_8 0.80432
wandb:    val_auc/dataloader_idx_9 0.77154
wandb:   val_loss/dataloader_idx_0 0.28648
wandb:   val_loss/dataloader_idx_1 0.2886
wandb:  val_loss/dataloader_idx_10 0.37362
wandb:  val_loss/dataloader_idx_11 0.37814
wandb:   val_loss/dataloader_idx_2 0.27972
wandb:   val_loss/dataloader_idx_3 0.28068
wandb:   val_loss/dataloader_idx_4 0.30488
wandb:   val_loss/dataloader_idx_5 0.32152
wandb:   val_loss/dataloader_idx_6 0.31864
wandb:   val_loss/dataloader_idx_7 0.34046
wandb:   val_loss/dataloader_idx_8 0.3528
wandb:   val_loss/dataloader_idx_9 0.35531
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2020-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/twf4956n
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260125_180327-twf4956n/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260125_232248-2rbwdzgg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2021-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/2rbwdzgg
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2021.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2021.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.830161452293396 â”‚ 0.84608399868011â€¦ â”‚ 0.8664422035217â€¦ â”‚
â”‚     test_loss     â”‚ 0.30849751830101â€¦ â”‚ 0.30566152930259â€¦ â”‚ 0.2988908290863â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.858937680721283 â”‚ 0.84925460815429â€¦ â”‚ 0.8561453819274â€¦ â”‚
â”‚     test_loss     â”‚ 0.29407200217247â€¦ â”‚ 0.31128829717636â€¦ â”‚ 0.3080632984638â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81717193126678â€¦ â”‚ 0.82235598564147â€¦ â”‚ 0.8162248134613â€¦ â”‚
â”‚     test_loss     â”‚ 0.33769279718399â€¦ â”‚ 0.32268738746643â€¦ â”‚ 0.3428213596343â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.77161556482315â€¦ â”‚ 0.756072461605072 â”‚ 0.7354518771171â€¦ â”‚
â”‚     test_loss     â”‚ 0.37864282727241â€¦ â”‚ 0.41063264012336â€¦ â”‚ 0.4130457937717â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–‡â–…â–†â–…â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–‡â–…â–„â–ƒâ–‚â–
wandb:             train_loss_step â–‚â–„â–„â–‚â–‚â–â–„â–ƒâ–‚â–„â–‚â–‚â–ƒâ–ƒâ–…â–â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–ƒâ–ƒâ–‚â–„â–â–â–ˆâ–â–â–‚â–â–‚â–ˆâ–„
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–†â–ˆâ–„â–ˆâ–‡â–â–ƒ
wandb:    val_auc/dataloader_idx_1 â–ˆâ–†â–„â–…â–ƒâ–â–ƒ
wandb:   val_auc/dataloader_idx_10 â–†â–†â–â–†â–ˆâ–â–†
wandb:   val_auc/dataloader_idx_11 â–…â–ˆâ–‚â–‚â–ˆâ–â–†
wandb:    val_auc/dataloader_idx_2 â–â–‚â–ƒâ–ƒâ–„â–„â–ˆ
wandb:    val_auc/dataloader_idx_3 â–ˆâ–ˆâ–‡â–‡â–…â–â–
wandb:    val_auc/dataloader_idx_4 â–ˆâ–ˆâ–‡â–…â–„â–‚â–
wandb:    val_auc/dataloader_idx_5 â–ˆâ–‡â–†â–†â–…â–ƒâ–
wandb:    val_auc/dataloader_idx_6 â–ˆâ–ˆâ–†â–†â–…â–â–‚
wandb:    val_auc/dataloader_idx_7 â–ˆâ–‡â–†â–‡â–…â–â–„
wandb:    val_auc/dataloader_idx_8 â–†â–…â–†â–ˆâ–‡â–…â–
wandb:    val_auc/dataloader_idx_9 â–†â–ˆâ–‚â–ˆâ–ˆâ–â–‡
wandb:   val_loss/dataloader_idx_0 â–„â–â–„â–„â–„â–â–ˆ
wandb:   val_loss/dataloader_idx_1 â–„â–‚â–„â–…â–…â–â–ˆ
wandb:  val_loss/dataloader_idx_10 â–ƒâ–â–…â–…â–†â–ƒâ–ˆ
wandb:  val_loss/dataloader_idx_11 â–ƒâ–â–„â–„â–†â–‚â–ˆ
wandb:   val_loss/dataloader_idx_2 â–„â–‚â–„â–…â–…â–â–ˆ
wandb:   val_loss/dataloader_idx_3 â–„â–â–„â–„â–…â–â–ˆ
wandb:   val_loss/dataloader_idx_4 â–ƒâ–‚â–„â–…â–„â–â–ˆ
wandb:   val_loss/dataloader_idx_5 â–ƒâ–â–„â–„â–„â–â–ˆ
wandb:   val_loss/dataloader_idx_6 â–ƒâ–â–„â–„â–„â–â–ˆ
wandb:   val_loss/dataloader_idx_7 â–ƒâ–‚â–„â–„â–„â–â–ˆ
wandb:   val_loss/dataloader_idx_8 â–ƒâ–‚â–ƒâ–„â–„â–â–ˆ
wandb:   val_loss/dataloader_idx_9 â–ƒâ–â–ƒâ–ƒâ–…â–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 7
wandb:                    test_auc 0.73545
wandb:   test_auc/dataloader_idx_0 0.83016
wandb:   test_auc/dataloader_idx_1 0.84608
wandb:  test_auc/dataloader_idx_10 0.75607
wandb:  test_auc/dataloader_idx_11 0.73545
wandb:   test_auc/dataloader_idx_2 0.86644
wandb:   test_auc/dataloader_idx_3 0.85894
wandb:   test_auc/dataloader_idx_4 0.84925
wandb:   test_auc/dataloader_idx_5 0.85615
wandb:   test_auc/dataloader_idx_6 0.81717
wandb:   test_auc/dataloader_idx_7 0.82236
wandb:   test_auc/dataloader_idx_8 0.81622
wandb:   test_auc/dataloader_idx_9 0.77162
wandb:  test_loss/dataloader_idx_0 0.3085
wandb:  test_loss/dataloader_idx_1 0.30566
wandb: test_loss/dataloader_idx_10 0.41063
wandb: test_loss/dataloader_idx_11 0.41305
wandb:  test_loss/dataloader_idx_2 0.29889
wandb:  test_loss/dataloader_idx_3 0.29407
wandb:  test_loss/dataloader_idx_4 0.31129
wandb:  test_loss/dataloader_idx_5 0.30806
wandb:  test_loss/dataloader_idx_6 0.33769
wandb:  test_loss/dataloader_idx_7 0.32269
wandb:  test_loss/dataloader_idx_8 0.34282
wandb:  test_loss/dataloader_idx_9 0.37864
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.42794
wandb:             train_loss_step 0.32928
wandb:         trainer/global_step 52339
wandb:    val_auc/dataloader_idx_0 0.83248
wandb:    val_auc/dataloader_idx_1 0.84561
wandb:   val_auc/dataloader_idx_10 0.75619
wandb:   val_auc/dataloader_idx_11 0.74544
wandb:    val_auc/dataloader_idx_2 0.8586
wandb:    val_auc/dataloader_idx_3 0.85926
wandb:    val_auc/dataloader_idx_4 0.85433
wandb:    val_auc/dataloader_idx_5 0.8223
wandb:    val_auc/dataloader_idx_6 0.83584
wandb:    val_auc/dataloader_idx_7 0.81802
wandb:    val_auc/dataloader_idx_8 0.81263
wandb:    val_auc/dataloader_idx_9 0.77853
wandb:   val_loss/dataloader_idx_0 0.30981
wandb:   val_loss/dataloader_idx_1 0.31877
wandb:  val_loss/dataloader_idx_10 0.44023
wandb:  val_loss/dataloader_idx_11 0.44753
wandb:   val_loss/dataloader_idx_2 0.30532
wandb:   val_loss/dataloader_idx_3 0.31555
wandb:   val_loss/dataloader_idx_4 0.33319
wandb:   val_loss/dataloader_idx_5 0.34927
wandb:   val_loss/dataloader_idx_6 0.34567
wandb:   val_loss/dataloader_idx_7 0.35716
wandb:   val_loss/dataloader_idx_8 0.37885
wandb:   val_loss/dataloader_idx_9 0.41418
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2021-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/2rbwdzgg
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260125_232248-2rbwdzgg/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260126_031516-9dug9pa2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2022-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/9dug9pa2
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2022.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2022.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83320724964141â€¦ â”‚ 0.848196804523468 â”‚ 0.8597207069396â€¦ â”‚
â”‚     test_loss     â”‚ 0.27384415268898â€¦ â”‚ 0.28059941530227â€¦ â”‚ 0.2755645811557â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.86126160621643â€¦ â”‚ 0.84828978776931â€¦ â”‚ 0.8586678504943â€¦ â”‚
â”‚     test_loss     â”‚ 0.26945966482162â€¦ â”‚ 0.28864353895187â€¦ â”‚ 0.2827127873897â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82380735874176â€¦ â”‚ 0.82692122459411â€¦ â”‚ 0.8137536048889â€¦ â”‚
â”‚     test_loss     â”‚ 0.31181573867797â€¦ â”‚ 0.30572551488876â€¦ â”‚ 0.3351297080516â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78448581695556â€¦ â”‚ 0.78027069568634â€¦ â”‚ 0.7528051137924â€¦ â”‚
â”‚     test_loss     â”‚ 0.36349266767501â€¦ â”‚ 0.37122040987014â€¦ â”‚ 0.3861691951751â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–†â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–†â–†â–„â–ƒâ–ƒâ–
wandb:             train_loss_step â–ƒâ–‚â–‚â–‚â–â–ƒâ–„â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‡â–„â–„â–„â–ƒâ–‚â–„â–„â–„â–ƒâ–†â–„â–â–ƒâ–ˆâ–‡â–…â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–ƒ
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–‚â–…â–ˆâ–â–…â–„â–ƒ
wandb:    val_auc/dataloader_idx_1 â–„â–…â–†â–‡â–ˆâ–‚â–
wandb:   val_auc/dataloader_idx_10 â–‡â–…â–ˆâ–†â–â–„â–ƒ
wandb:   val_auc/dataloader_idx_11 â–â–â–†â–ˆâ–†â–ƒâ–‚
wandb:    val_auc/dataloader_idx_2 â–ˆâ–‡â–„â–†â–‚â–†â–
wandb:    val_auc/dataloader_idx_3 â–‡â–ˆâ–ˆâ–ƒâ–ƒâ–‚â–
wandb:    val_auc/dataloader_idx_4 â–‡â–ˆâ–‡â–ˆâ–†â–„â–
wandb:    val_auc/dataloader_idx_5 â–†â–ˆâ–‡â–…â–†â–†â–
wandb:    val_auc/dataloader_idx_6 â–â–†â–ˆâ–†â–„â–‡â–ƒ
wandb:    val_auc/dataloader_idx_7 â–‡â–‡â–ˆâ–†â–†â–ƒâ–
wandb:    val_auc/dataloader_idx_8 â–ˆâ–ˆâ–ƒâ–†â–…â–ƒâ–
wandb:    val_auc/dataloader_idx_9 â–â–…â–‡â–ˆâ–„â–„â–„
wandb:   val_loss/dataloader_idx_0 â–†â–„â–‡â–„â–‚â–ˆâ–
wandb:   val_loss/dataloader_idx_1 â–†â–„â–‡â–„â–â–ˆâ–
wandb:  val_loss/dataloader_idx_10 â–ˆâ–…â–…â–„â–â–ˆâ–ƒ
wandb:  val_loss/dataloader_idx_11 â–ˆâ–…â–†â–„â–â–ˆâ–„
wandb:   val_loss/dataloader_idx_2 â–‡â–…â–‡â–„â–‚â–ˆâ–
wandb:   val_loss/dataloader_idx_3 â–†â–„â–‡â–„â–â–ˆâ–
wandb:   val_loss/dataloader_idx_4 â–‡â–„â–‡â–„â–â–ˆâ–
wandb:   val_loss/dataloader_idx_5 â–‡â–„â–†â–„â–â–ˆâ–
wandb:   val_loss/dataloader_idx_6 â–†â–„â–†â–„â–â–ˆâ–
wandb:   val_loss/dataloader_idx_7 â–…â–ƒâ–†â–„â–â–ˆâ–
wandb:   val_loss/dataloader_idx_8 â–†â–„â–†â–„â–â–ˆâ–‚
wandb:   val_loss/dataloader_idx_9 â–†â–…â–…â–„â–â–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:                       epoch 7
wandb:                    test_auc 0.75281
wandb:   test_auc/dataloader_idx_0 0.83321
wandb:   test_auc/dataloader_idx_1 0.8482
wandb:  test_auc/dataloader_idx_10 0.78027
wandb:  test_auc/dataloader_idx_11 0.75281
wandb:   test_auc/dataloader_idx_2 0.85972
wandb:   test_auc/dataloader_idx_3 0.86126
wandb:   test_auc/dataloader_idx_4 0.84829
wandb:   test_auc/dataloader_idx_5 0.85867
wandb:   test_auc/dataloader_idx_6 0.82381
wandb:   test_auc/dataloader_idx_7 0.82692
wandb:   test_auc/dataloader_idx_8 0.81375
wandb:   test_auc/dataloader_idx_9 0.78449
wandb:  test_loss/dataloader_idx_0 0.27384
wandb:  test_loss/dataloader_idx_1 0.2806
wandb: test_loss/dataloader_idx_10 0.37122
wandb: test_loss/dataloader_idx_11 0.38617
wandb:  test_loss/dataloader_idx_2 0.27556
wandb:  test_loss/dataloader_idx_3 0.26946
wandb:  test_loss/dataloader_idx_4 0.28864
wandb:  test_loss/dataloader_idx_5 0.28271
wandb:  test_loss/dataloader_idx_6 0.31182
wandb:  test_loss/dataloader_idx_7 0.30573
wandb:  test_loss/dataloader_idx_8 0.33513
wandb:  test_loss/dataloader_idx_9 0.36349
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.45948
wandb:             train_loss_step 0.49074
wandb:         trainer/global_step 113785
wandb:    val_auc/dataloader_idx_0 0.83745
wandb:    val_auc/dataloader_idx_1 0.84824
wandb:   val_auc/dataloader_idx_10 0.76968
wandb:   val_auc/dataloader_idx_11 0.7598
wandb:    val_auc/dataloader_idx_2 0.85275
wandb:    val_auc/dataloader_idx_3 0.86679
wandb:    val_auc/dataloader_idx_4 0.85644
wandb:    val_auc/dataloader_idx_5 0.83096
wandb:    val_auc/dataloader_idx_6 0.84229
wandb:    val_auc/dataloader_idx_7 0.81527
wandb:    val_auc/dataloader_idx_8 0.81735
wandb:    val_auc/dataloader_idx_9 0.79353
wandb:   val_loss/dataloader_idx_0 0.26192
wandb:   val_loss/dataloader_idx_1 0.26758
wandb:  val_loss/dataloader_idx_10 0.3638
wandb:  val_loss/dataloader_idx_11 0.37538
wandb:   val_loss/dataloader_idx_2 0.25521
wandb:   val_loss/dataloader_idx_3 0.25947
wandb:   val_loss/dataloader_idx_4 0.27312
wandb:   val_loss/dataloader_idx_5 0.28522
wandb:   val_loss/dataloader_idx_6 0.27997
wandb:   val_loss/dataloader_idx_7 0.29885
wandb:   val_loss/dataloader_idx_8 0.32353
wandb:   val_loss/dataloader_idx_9 0.35069
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2022-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/9dug9pa2
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260126_031516-9dug9pa2/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260126_084726-ta7tut7k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2023-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/ta7tut7k
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2023.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2023.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82535231113433â€¦ â”‚ 0.843280017375946 â”‚ 0.8562472462654â€¦ â”‚
â”‚     test_loss     â”‚ 0.28049081563949â€¦ â”‚ 0.28512015938758â€¦ â”‚ 0.2761798501014â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.853210985660553 â”‚ 0.84317433834075â€¦ â”‚ 0.8542956709861â€¦ â”‚
â”‚     test_loss     â”‚ 0.27303287386894â€¦ â”‚ 0.29215064644813â€¦ â”‚ 0.2789386510848â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82317793369293â€¦ â”‚ 0.81999075412750â€¦ â”‚ 0.8089401721954â€¦ â”‚
â”‚     test_loss     â”‚ 0.30448061227798â€¦ â”‚ 0.29781514406204â€¦ â”‚ 0.3198227584362â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78340524435043â€¦ â”‚ 0.78779697418212â€¦ â”‚ 0.7602848410606â€¦ â”‚
â”‚     test_loss     â”‚ 0.33844017982482â€¦ â”‚ 0.35866788029670â€¦ â”‚ 0.3728624284267â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–…â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–
wandb:             train_loss_step â–„â–ƒâ–ƒâ–…â–†â–‚â–‚â–‚â–â–ƒâ–ˆâ–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–ƒâ–‚â–â–â–‚â–‚â–â–‚â–‚â–„â–„â–ƒâ–ƒâ–â–†â–‚â–‚â–‚â–‚â–‚â–
wandb:         trainer/global_step â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–‡â–†â–‡â–ˆâ–†â–†â–…â–„â–â–‚
wandb:    val_auc/dataloader_idx_1 â–ˆâ–‡â–ˆâ–ˆâ–†â–‡â–ƒâ–„â–â–‚
wandb:   val_auc/dataloader_idx_10 â–â–‚â–…â–†â–…â–‡â–ˆâ–‡â–â–„
wandb:   val_auc/dataloader_idx_11 â–ˆâ–‡â–‡â–‡â–‡â–†â–…â–†â–‚â–
wandb:    val_auc/dataloader_idx_2 â–‡â–†â–ˆâ–ˆâ–†â–†â–„â–„â–‚â–
wandb:    val_auc/dataloader_idx_3 â–‡â–‡â–‡â–ˆâ–…â–…â–„â–„â–â–
wandb:    val_auc/dataloader_idx_4 â–ˆâ–ˆâ–ˆâ–†â–…â–‡â–…â–†â–‚â–
wandb:    val_auc/dataloader_idx_5 â–‡â–‡â–ˆâ–ˆâ–…â–†â–„â–…â–‚â–
wandb:    val_auc/dataloader_idx_6 â–ˆâ–‡â–‡â–‡â–…â–…â–„â–ƒâ–â–
wandb:    val_auc/dataloader_idx_7 â–‡â–‡â–ˆâ–ˆâ–…â–†â–„â–„â–â–„
wandb:    val_auc/dataloader_idx_8 â–ˆâ–ˆâ–‡â–‡â–ƒâ–†â–ƒâ–…â–â–
wandb:    val_auc/dataloader_idx_9 â–ˆâ–ˆâ–ˆâ–ˆâ–…â–‡â–„â–…â–‚â–
wandb:   val_loss/dataloader_idx_0 â–ƒâ–‚â–ƒâ–‡â–â–ƒâ–‚â–‚â–…â–ˆ
wandb:   val_loss/dataloader_idx_1 â–ƒâ–‚â–ƒâ–‡â–â–ƒâ–‚â–‚â–„â–ˆ
wandb:  val_loss/dataloader_idx_10 â–„â–ƒâ–…â–ˆâ–â–†â–„â–ƒâ–†â–†
wandb:  val_loss/dataloader_idx_11 â–„â–ƒâ–…â–ˆâ–â–†â–„â–ƒâ–‡â–‡
wandb:   val_loss/dataloader_idx_2 â–ƒâ–‚â–ƒâ–‡â–â–ƒâ–‚â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_3 â–ƒâ–‚â–ƒâ–‡â–â–ƒâ–‚â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_4 â–ƒâ–‚â–ƒâ–‡â–â–ƒâ–‚â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_5 â–ƒâ–‚â–ƒâ–†â–â–ƒâ–‚â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_6 â–ƒâ–‚â–ƒâ–†â–â–ƒâ–‚â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_7 â–ƒâ–‚â–ƒâ–†â–â–ƒâ–‚â–‚â–…â–ˆ
wandb:   val_loss/dataloader_idx_8 â–„â–‚â–„â–‡â–â–„â–ƒâ–‚â–†â–ˆ
wandb:   val_loss/dataloader_idx_9 â–…â–ƒâ–…â–ˆâ–â–…â–ƒâ–ƒâ–†â–†
wandb: 
wandb: Run summary:
wandb:                       epoch 10
wandb:                    test_auc 0.76028
wandb:   test_auc/dataloader_idx_0 0.82535
wandb:   test_auc/dataloader_idx_1 0.84328
wandb:  test_auc/dataloader_idx_10 0.7878
wandb:  test_auc/dataloader_idx_11 0.76028
wandb:   test_auc/dataloader_idx_2 0.85625
wandb:   test_auc/dataloader_idx_3 0.85321
wandb:   test_auc/dataloader_idx_4 0.84317
wandb:   test_auc/dataloader_idx_5 0.8543
wandb:   test_auc/dataloader_idx_6 0.82318
wandb:   test_auc/dataloader_idx_7 0.81999
wandb:   test_auc/dataloader_idx_8 0.80894
wandb:   test_auc/dataloader_idx_9 0.78341
wandb:  test_loss/dataloader_idx_0 0.28049
wandb:  test_loss/dataloader_idx_1 0.28512
wandb: test_loss/dataloader_idx_10 0.35867
wandb: test_loss/dataloader_idx_11 0.37286
wandb:  test_loss/dataloader_idx_2 0.27618
wandb:  test_loss/dataloader_idx_3 0.27303
wandb:  test_loss/dataloader_idx_4 0.29215
wandb:  test_loss/dataloader_idx_5 0.27894
wandb:  test_loss/dataloader_idx_6 0.30448
wandb:  test_loss/dataloader_idx_7 0.29782
wandb:  test_loss/dataloader_idx_8 0.31982
wandb:  test_loss/dataloader_idx_9 0.33844
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.44859
wandb:             train_loss_step 0.5102
wandb:         trainer/global_step 182150
wandb:    val_auc/dataloader_idx_0 0.82909
wandb:    val_auc/dataloader_idx_1 0.84316
wandb:   val_auc/dataloader_idx_10 0.78075
wandb:   val_auc/dataloader_idx_11 0.75872
wandb:    val_auc/dataloader_idx_2 0.8457
wandb:    val_auc/dataloader_idx_3 0.85861
wandb:    val_auc/dataloader_idx_4 0.85238
wandb:    val_auc/dataloader_idx_5 0.82609
wandb:    val_auc/dataloader_idx_6 0.82776
wandb:    val_auc/dataloader_idx_7 0.81426
wandb:    val_auc/dataloader_idx_8 0.79628
wandb:    val_auc/dataloader_idx_9 0.77342
wandb:   val_loss/dataloader_idx_0 0.31269
wandb:   val_loss/dataloader_idx_1 0.32445
wandb:  val_loss/dataloader_idx_10 0.3753
wandb:  val_loss/dataloader_idx_11 0.39881
wandb:   val_loss/dataloader_idx_2 0.314
wandb:   val_loss/dataloader_idx_3 0.31956
wandb:   val_loss/dataloader_idx_4 0.33363
wandb:   val_loss/dataloader_idx_5 0.34587
wandb:   val_loss/dataloader_idx_6 0.34833
wandb:   val_loss/dataloader_idx_7 0.36289
wandb:   val_loss/dataloader_idx_8 0.36086
wandb:   val_loss/dataloader_idx_9 0.35683
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2023-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/ta7tut7k
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260126_084726-ta7tut7k/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260126_173043-tpz8cq6c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2024-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/tpz8cq6c
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2024.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-11/best-checkpoint-2024.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82935070991516â€¦ â”‚ 0.84001123905181â€¦ â”‚ 0.8564075827598â€¦ â”‚
â”‚     test_loss     â”‚ 0.28794735670089â€¦ â”‚ 0.29277342557907â€¦ â”‚ 0.2860812544822â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.84977859258651â€¦ â”‚ 0.84095788002014â€¦ â”‚ 0.8529237508773â€¦ â”‚
â”‚     test_loss     â”‚ 0.28111591935157â€¦ â”‚ 0.30021855235099â€¦ â”‚ 0.2907299697399â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81907308101654â€¦ â”‚ 0.81843411922454â€¦ â”‚ 0.8059241771697â€¦ â”‚
â”‚     test_loss     â”‚ 0.31347188353538â€¦ â”‚ 0.30448597669601â€¦ â”‚ 0.3251821696758â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.777347981929779 â”‚ 0.78606200218200â€¦ â”‚ 0.7716042995452â€¦ â”‚
â”‚     test_loss     â”‚ 0.34210559725761â€¦ â”‚ 0.36610674858093â€¦ â”‚ 0.3764213323593â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–‡â–‡â–ˆâ–…â–…â–„â–â–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:             train_loss_step â–‚â–ƒâ–„â–„â–ƒâ–„â–‚â–â–â–„â–‚â–‚â–ƒâ–„â–‚â–‚â–‚â–…â–â–‚â–‚â–â–ƒâ–‚â–…â–‚â–â–†â–‚â–ˆâ–‚â–„â–â–â–‚â–ƒâ–‚â–ƒâ–â–‚
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–†â–†â–‡â–„â–ˆâ–…â–…â–„â–
wandb:    val_auc/dataloader_idx_1 â–ˆâ–†â–‡â–‡â–…â–†â–…â–„â–„â–
wandb:   val_auc/dataloader_idx_10 â–ˆâ–‡â–ˆâ–ˆâ–†â–‡â–†â–„â–ƒâ–
wandb:   val_auc/dataloader_idx_11 â–‚â–â–ƒâ–ƒâ–„â–†â–ˆâ–…â–ƒâ–„
wandb:    val_auc/dataloader_idx_2 â–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–‚â–
wandb:    val_auc/dataloader_idx_3 â–ˆâ–†â–†â–‡â–…â–†â–…â–„â–„â–
wandb:    val_auc/dataloader_idx_4 â–ˆâ–†â–‡â–ˆâ–†â–‡â–†â–…â–…â–
wandb:    val_auc/dataloader_idx_5 â–ˆâ–†â–‡â–ˆâ–†â–‡â–…â–…â–†â–
wandb:    val_auc/dataloader_idx_6 â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–†â–…â–„â–
wandb:    val_auc/dataloader_idx_7 â–ˆâ–†â–‡â–ˆâ–„â–†â–†â–ƒâ–„â–
wandb:    val_auc/dataloader_idx_8 â–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡â–‡â–†â–…â–
wandb:    val_auc/dataloader_idx_9 â–ˆâ–‡â–ˆâ–‡â–…â–…â–…â–„â–ƒâ–
wandb:   val_loss/dataloader_idx_0 â–…â–…â–†â–ˆâ–â–ƒâ–†â–ƒâ–ˆâ–†
wandb:   val_loss/dataloader_idx_1 â–…â–„â–„â–‡â–â–„â–†â–„â–ˆâ–‡
wandb:  val_loss/dataloader_idx_10 â–†â–…â–…â–‡â–â–„â–†â–ƒâ–ˆâ–ˆ
wandb:  val_loss/dataloader_idx_11 â–†â–…â–†â–ˆâ–â–…â–‡â–‚â–ˆâ–‡
wandb:   val_loss/dataloader_idx_2 â–„â–ƒâ–„â–†â–â–„â–†â–„â–ˆâ–†
wandb:   val_loss/dataloader_idx_3 â–„â–ƒâ–„â–†â–â–ƒâ–†â–„â–ˆâ–†
wandb:   val_loss/dataloader_idx_4 â–…â–„â–„â–†â–â–ƒâ–†â–„â–ˆâ–†
wandb:   val_loss/dataloader_idx_5 â–„â–„â–„â–…â–â–ƒâ–†â–„â–ˆâ–‡
wandb:   val_loss/dataloader_idx_6 â–…â–„â–„â–…â–â–‚â–…â–ƒâ–ˆâ–†
wandb:   val_loss/dataloader_idx_7 â–…â–„â–ƒâ–…â–â–â–…â–ƒâ–ˆâ–†
wandb:   val_loss/dataloader_idx_8 â–†â–„â–…â–†â–â–‚â–…â–‚â–ˆâ–‡
wandb:   val_loss/dataloader_idx_9 â–‡â–…â–†â–‡â–â–ƒâ–…â–ƒâ–ˆâ–‡
wandb: 
wandb: Run summary:
wandb:                       epoch 10
wandb:                    test_auc 0.7716
wandb:   test_auc/dataloader_idx_0 0.82935
wandb:   test_auc/dataloader_idx_1 0.84001
wandb:  test_auc/dataloader_idx_10 0.78606
wandb:  test_auc/dataloader_idx_11 0.7716
wandb:   test_auc/dataloader_idx_2 0.85641
wandb:   test_auc/dataloader_idx_3 0.84978
wandb:   test_auc/dataloader_idx_4 0.84096
wandb:   test_auc/dataloader_idx_5 0.85292
wandb:   test_auc/dataloader_idx_6 0.81907
wandb:   test_auc/dataloader_idx_7 0.81843
wandb:   test_auc/dataloader_idx_8 0.80592
wandb:   test_auc/dataloader_idx_9 0.77735
wandb:  test_loss/dataloader_idx_0 0.28795
wandb:  test_loss/dataloader_idx_1 0.29277
wandb: test_loss/dataloader_idx_10 0.36611
wandb: test_loss/dataloader_idx_11 0.37642
wandb:  test_loss/dataloader_idx_2 0.28608
wandb:  test_loss/dataloader_idx_3 0.28112
wandb:  test_loss/dataloader_idx_4 0.30022
wandb:  test_loss/dataloader_idx_5 0.29073
wandb:  test_loss/dataloader_idx_6 0.31347
wandb:  test_loss/dataloader_idx_7 0.30449
wandb:  test_loss/dataloader_idx_8 0.32518
wandb:  test_loss/dataloader_idx_9 0.34211
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.44516
wandb:             train_loss_step 0.86142
wandb:         trainer/global_step 195170
wandb:    val_auc/dataloader_idx_0 0.82745
wandb:    val_auc/dataloader_idx_1 0.82946
wandb:   val_auc/dataloader_idx_10 0.76739
wandb:   val_auc/dataloader_idx_11 0.77472
wandb:    val_auc/dataloader_idx_2 0.83675
wandb:    val_auc/dataloader_idx_3 0.84328
wandb:    val_auc/dataloader_idx_4 0.84617
wandb:    val_auc/dataloader_idx_5 0.82324
wandb:    val_auc/dataloader_idx_6 0.82545
wandb:    val_auc/dataloader_idx_7 0.80863
wandb:    val_auc/dataloader_idx_8 0.78652
wandb:    val_auc/dataloader_idx_9 0.76787
wandb:   val_loss/dataloader_idx_0 0.27902
wandb:   val_loss/dataloader_idx_1 0.28955
wandb:  val_loss/dataloader_idx_10 0.36937
wandb:  val_loss/dataloader_idx_11 0.37553
wandb:   val_loss/dataloader_idx_2 0.27525
wandb:   val_loss/dataloader_idx_3 0.28201
wandb:   val_loss/dataloader_idx_4 0.2938
wandb:   val_loss/dataloader_idx_5 0.30832
wandb:   val_loss/dataloader_idx_6 0.3021
wandb:   val_loss/dataloader_idx_7 0.31397
wandb:   val_loss/dataloader_idx_8 0.33073
wandb:   val_loss/dataloader_idx_9 0.34335
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2024-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/tpz8cq6c
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260126_173043-tpz8cq6c/logs
Saved results to: /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/results/la_maml_clinical_v2/traditional-sequential-2013-2024/traditional-sequential-2013-2024-seed-11.csv
============================================
End time: Tue Jan 27 02:34:10 EST 2026
Job completed successfully
