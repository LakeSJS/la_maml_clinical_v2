============================================
Job ID: 17787455
Job Name: lamaml_exp
Node: a100-4016
Partition: a100_short
Start time: Wed Jan 28 00:44:13 EST 2026
Config: tmaml_seq_2013_2024
Seed: 10
Paths: gpfs
============================================
Running: python /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/scripts/run_experiment.py --config tmaml_seq_2013_2024 --paths gpfs --seed 10
============================================
[rank: 0] Global seed set to 10
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: lakej98 (lakej98-nyu-langone-health) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260128_004502-ljxawciz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2020-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/ljxawciz
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 4. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2020.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2020.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Resuming from year 2019, checkpoint: /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2019.ckpt
Loaded 0 existing results from previous run
Resuming training from year 2020
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80115556716918â€¦ â”‚ 0.822979211807251 â”‚ 0.8460692167282â€¦ â”‚
â”‚     test_loss     â”‚ 0.26472008228302  â”‚ 0.29322242736816â€¦ â”‚ 0.2515550255775â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.834833025932312 â”‚ 0.83016288280487â€¦ â”‚ 0.8269206881523â€¦ â”‚
â”‚     test_loss     â”‚ 0.25922548770904â€¦ â”‚ 0.285976380109787 â”‚ 0.2661620378494â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.79950928688049â€¦ â”‚ 0.81148874759674â€¦ â”‚ 0.8020037412643â€¦ â”‚
â”‚     test_loss     â”‚ 0.30297616124153â€¦ â”‚ 0.27827417850494â€¦ â”‚ 0.3040988147258â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74479842185974â€¦ â”‚ 0.73383247852325â€¦ â”‚ 0.7204870581626â€¦ â”‚
â”‚     test_loss     â”‚ 0.31445315480232â€¦ â”‚ 0.32839369773864â€¦ â”‚ 0.3300829827785â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–…â–…â–„â–ƒâ–ƒâ–‚â–â–‚â–
wandb:              meta_loss_step â–ƒâ–â–„â–ƒâ–â–â–„â–‚â–â–‚â–‚â–‡â–ˆâ–‚â–…â–‚â–‚â–‚â–‚â–‚â–â–‡â–‚â–„â–‚â–‚â–ƒâ–†â–â–ƒâ–â–†â–â–â–â–ƒâ–‚â–â–„â–„
wandb:                    test_auc â–…â–‡â–ˆâ–‡â–‡â–‡â–…â–†â–†â–‚â–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–ˆâ–‡â–…â–…â–…â–„â–â–‡â–‚
wandb:    val_auc/dataloader_idx_1 â–…â–‡â–ˆâ–†â–ƒâ–ƒâ–„â–ƒâ–‚â–
wandb:   val_auc/dataloader_idx_10 â–…â–†â–…â–‚â–ƒâ–„â–„â–â–ˆâ–ƒ
wandb:   val_auc/dataloader_idx_11 â–…â–‡â–…â–‚â–â–…â–†â–‚â–ˆâ–„
wandb:    val_auc/dataloader_idx_2 â–ƒâ–†â–†â–…â–…â–‡â–ˆâ–â–ƒâ–
wandb:    val_auc/dataloader_idx_3 â–ˆâ–†â–…â–…â–„â–†â–„â–„â–…â–
wandb:    val_auc/dataloader_idx_4 â–„â–ƒâ–„â–„â–‚â–…â–†â–â–ˆâ–
wandb:    val_auc/dataloader_idx_5 â–ˆâ–…â–…â–…â–…â–…â–„â–‚â–ƒâ–
wandb:    val_auc/dataloader_idx_6 â–†â–…â–‡â–…â–ƒâ–‡â–†â–â–ˆâ–…
wandb:    val_auc/dataloader_idx_7 â–…â–„â–…â–„â–â–‡â–ˆâ–‚â–„â–‚
wandb:    val_auc/dataloader_idx_8 â–â–†â–†â–†â–„â–†â–…â–ƒâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_9 â–â–„â–…â–ƒâ–„â–…â–…â–â–ˆâ–‡
wandb:   val_loss/dataloader_idx_0 â–ˆâ–ƒâ–ƒâ–„â–†â–‚â–„â–…â–â–ƒ
wandb:   val_loss/dataloader_idx_1 â–ˆâ–‚â–â–ƒâ–‡â–ƒâ–„â–ƒâ–„â–ƒ
wandb:  val_loss/dataloader_idx_10 â–„â–ƒâ–‚â–„â–ƒâ–†â–†â–†â–â–ˆ
wandb:  val_loss/dataloader_idx_11 â–ƒâ–ƒâ–‚â–‚â–‚â–†â–…â–†â–â–ˆ
wandb:   val_loss/dataloader_idx_2 â–ˆâ–ƒâ–‚â–ƒâ–…â–â–‚â–„â–ƒâ–„
wandb:   val_loss/dataloader_idx_3 â–ˆâ–ƒâ–„â–„â–ˆâ–â–…â–„â–ƒâ–†
wandb:   val_loss/dataloader_idx_4 â–ˆâ–„â–„â–„â–…â–‚â–„â–ƒâ–â–ƒ
wandb:   val_loss/dataloader_idx_5 â–ˆâ–â–‚â–‚â–‡â–â–…â–ƒâ–‚â–„
wandb:   val_loss/dataloader_idx_6 â–ˆâ–„â–ƒâ–ƒâ–†â–‚â–ƒâ–ƒâ–â–‚
wandb:   val_loss/dataloader_idx_7 â–‚â–â–‚â–‚â–„â–ƒâ–…â–…â–…â–ˆ
wandb:   val_loss/dataloader_idx_8 â–ˆâ–ƒâ–„â–ƒâ–„â–‚â–ƒâ–ƒâ–â–
wandb:   val_loss/dataloader_idx_9 â–„â–„â–‚â–‚â–â–…â–„â–„â–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 10
wandb:             meta_loss_epoch 0.15563
wandb:              meta_loss_step 0.08404
wandb:                    test_auc 0.72049
wandb:   test_auc/dataloader_idx_0 0.80116
wandb:   test_auc/dataloader_idx_1 0.82298
wandb:  test_auc/dataloader_idx_10 0.73383
wandb:  test_auc/dataloader_idx_11 0.72049
wandb:   test_auc/dataloader_idx_2 0.84607
wandb:   test_auc/dataloader_idx_3 0.83483
wandb:   test_auc/dataloader_idx_4 0.83016
wandb:   test_auc/dataloader_idx_5 0.82692
wandb:   test_auc/dataloader_idx_6 0.79951
wandb:   test_auc/dataloader_idx_7 0.81149
wandb:   test_auc/dataloader_idx_8 0.802
wandb:   test_auc/dataloader_idx_9 0.7448
wandb:  test_loss/dataloader_idx_0 0.26472
wandb:  test_loss/dataloader_idx_1 0.29322
wandb: test_loss/dataloader_idx_10 0.32839
wandb: test_loss/dataloader_idx_11 0.33008
wandb:  test_loss/dataloader_idx_2 0.25156
wandb:  test_loss/dataloader_idx_3 0.25923
wandb:  test_loss/dataloader_idx_4 0.28598
wandb:  test_loss/dataloader_idx_5 0.26616
wandb:  test_loss/dataloader_idx_6 0.30298
wandb:  test_loss/dataloader_idx_7 0.27827
wandb:  test_loss/dataloader_idx_8 0.3041
wandb:  test_loss/dataloader_idx_9 0.31445
wandb:                   test_year 2024
wandb:         trainer/global_step 74770
wandb:    val_auc/dataloader_idx_0 0.81045
wandb:    val_auc/dataloader_idx_1 0.81504
wandb:   val_auc/dataloader_idx_10 0.72955
wandb:   val_auc/dataloader_idx_11 0.71907
wandb:    val_auc/dataloader_idx_2 0.83836
wandb:    val_auc/dataloader_idx_3 0.84167
wandb:    val_auc/dataloader_idx_4 0.83371
wandb:    val_auc/dataloader_idx_5 0.80919
wandb:    val_auc/dataloader_idx_6 0.82352
wandb:    val_auc/dataloader_idx_7 0.8063
wandb:    val_auc/dataloader_idx_8 0.80401
wandb:    val_auc/dataloader_idx_9 0.76474
wandb:   val_loss/dataloader_idx_0 0.27355
wandb:   val_loss/dataloader_idx_1 0.28098
wandb:  val_loss/dataloader_idx_10 0.33466
wandb:  val_loss/dataloader_idx_11 0.33575
wandb:   val_loss/dataloader_idx_2 0.24817
wandb:   val_loss/dataloader_idx_3 0.26035
wandb:   val_loss/dataloader_idx_4 0.27786
wandb:   val_loss/dataloader_idx_5 0.29088
wandb:   val_loss/dataloader_idx_6 0.27197
wandb:   val_loss/dataloader_idx_7 0.29326
wandb:   val_loss/dataloader_idx_8 0.29845
wandb:   val_loss/dataloader_idx_9 0.30745
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2020-seed-10 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/ljxawciz
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260128_004502-ljxawciz/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260128_135606-4dom5gjx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2021-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/4dom5gjx
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2021.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2021.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80497866868972â€¦ â”‚ 0.81950485706329â€¦ â”‚ 0.8413420915603â€¦ â”‚
â”‚     test_loss     â”‚ 0.26954525709152â€¦ â”‚ 0.30875727534294â€¦ â”‚ 0.2642147541046â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.831722617149353 â”‚ 0.83284431695938â€¦ â”‚ 0.8297963142395â€¦ â”‚
â”‚     test_loss     â”‚ 0.27077427506446â€¦ â”‚ 0.29592004418373â€¦ â”‚ 0.2715486586093â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80324745178222â€¦ â”‚ 0.80888450145721â€¦ â”‚ 0.7997848987579â€¦ â”‚
â”‚     test_loss     â”‚ 0.31043520569801â€¦ â”‚ 0.28835847973823â€¦ â”‚ 0.3195882141590â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.76800185441970â€¦ â”‚ 0.75968676805496â€¦ â”‚ 0.7403011322021â€¦ â”‚
â”‚     test_loss     â”‚ 0.30343657732009â€¦ â”‚ 0.31337144970893â€¦ â”‚ 0.3196985423564â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–†â–†â–…â–…â–…â–ƒâ–‚â–‚â–â–
wandb:              meta_loss_step â–‚â–„â–â–â–‚â–ƒâ–â–‚â–†â–„â–‚â–â–ƒâ–â–‚â–‚â–â–ƒâ–„â–â–‚â–„â–â–â–â–â–â–‚â–‚â–…â–‚â–‚â–â–ˆâ–â–â–â–‚â–â–…
wandb:                    test_auc â–…â–†â–ˆâ–‡â–‡â–‡â–…â–†â–…â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–‡â–„â–„â–…â–…â–‚â–ƒâ–ƒâ–â–ƒ
wandb:    val_auc/dataloader_idx_1 â–ˆâ–†â–‡â–„â–…â–†â–ƒâ–ƒâ–â–â–‚
wandb:   val_auc/dataloader_idx_10 â–„â–ˆâ–…â–„â–â–‚â–„â–„â–‚â–â–‚
wandb:   val_auc/dataloader_idx_11 â–â–„â–†â–ˆâ–…â–…â–†â–†â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_2 â–ˆâ–‡â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒ
wandb:    val_auc/dataloader_idx_3 â–…â–†â–…â–ˆâ–‡â–ˆâ–„â–‡â–â–â–‚
wandb:    val_auc/dataloader_idx_4 â–‡â–ˆâ–…â–…â–…â–ƒâ–â–â–‚â–‚â–ƒ
wandb:    val_auc/dataloader_idx_5 â–‡â–ˆâ–„â–ƒâ–‡â–ƒâ–‚â–â–â–â–ƒ
wandb:    val_auc/dataloader_idx_6 â–„â–ˆâ–‚â–†â–ˆâ–†â–ƒâ–â–‚â–â–„
wandb:    val_auc/dataloader_idx_7 â–„â–†â–…â–ˆâ–‡â–†â–„â–ƒâ–„â–„â–
wandb:    val_auc/dataloader_idx_8 â–…â–†â–‚â–…â–ˆâ–‡â–„â–ˆâ–‚â–â–
wandb:    val_auc/dataloader_idx_9 â–â–„â–‚â–â–„â–„â–†â–†â–‡â–‡â–ˆ
wandb:   val_loss/dataloader_idx_0 â–„â–‡â–„â–„â–‚â–ƒâ–ˆâ–‡â–‚â–„â–
wandb:   val_loss/dataloader_idx_1 â–ƒâ–‡â–‚â–„â–â–â–ˆâ–ˆâ–‚â–ƒâ–
wandb:  val_loss/dataloader_idx_10 â–‡â–‡â–…â–†â–…â–ˆâ–ƒâ–„â–‚â–„â–
wandb:  val_loss/dataloader_idx_11 â–ˆâ–‡â–„â–„â–ƒâ–†â–‚â–‚â–‚â–ƒâ–
wandb:   val_loss/dataloader_idx_2 â–â–…â–‚â–‚â–‚â–„â–ˆâ–ˆâ–â–„â–
wandb:   val_loss/dataloader_idx_3 â–„â–†â–ƒâ–‚â–â–‚â–ˆâ–‡â–‚â–„â–‚
wandb:   val_loss/dataloader_idx_4 â–ƒâ–„â–‚â–â–â–„â–ˆâ–†â–â–ƒâ–
wandb:   val_loss/dataloader_idx_5 â–ƒâ–„â–‚â–‚â–â–„â–ˆâ–‡â–‚â–„â–
wandb:   val_loss/dataloader_idx_6 â–ƒâ–…â–ƒâ–‚â–‚â–„â–ˆâ–‡â–‚â–„â–
wandb:   val_loss/dataloader_idx_7 â–‚â–…â–ƒâ–â–‚â–„â–†â–‡â–†â–‡â–ˆ
wandb:   val_loss/dataloader_idx_8 â–‚â–ƒâ–‚â–â–â–ƒâ–„â–…â–†â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_9 â–ˆâ–‡â–…â–…â–„â–…â–ƒâ–ƒâ–‚â–ƒâ–
wandb: 
wandb: Run summary:
wandb:                       epoch 11
wandb:             meta_loss_epoch 0.16205
wandb:              meta_loss_step 0.04085
wandb:                    test_auc 0.7403
wandb:   test_auc/dataloader_idx_0 0.80498
wandb:   test_auc/dataloader_idx_1 0.8195
wandb:  test_auc/dataloader_idx_10 0.75969
wandb:  test_auc/dataloader_idx_11 0.7403
wandb:   test_auc/dataloader_idx_2 0.84134
wandb:   test_auc/dataloader_idx_3 0.83172
wandb:   test_auc/dataloader_idx_4 0.83284
wandb:   test_auc/dataloader_idx_5 0.8298
wandb:   test_auc/dataloader_idx_6 0.80325
wandb:   test_auc/dataloader_idx_7 0.80888
wandb:   test_auc/dataloader_idx_8 0.79978
wandb:   test_auc/dataloader_idx_9 0.768
wandb:  test_loss/dataloader_idx_0 0.26955
wandb:  test_loss/dataloader_idx_1 0.30876
wandb: test_loss/dataloader_idx_10 0.31337
wandb: test_loss/dataloader_idx_11 0.3197
wandb:  test_loss/dataloader_idx_2 0.26421
wandb:  test_loss/dataloader_idx_3 0.27077
wandb:  test_loss/dataloader_idx_4 0.29592
wandb:  test_loss/dataloader_idx_5 0.27155
wandb:  test_loss/dataloader_idx_6 0.31044
wandb:  test_loss/dataloader_idx_7 0.28836
wandb:  test_loss/dataloader_idx_8 0.31959
wandb:  test_loss/dataloader_idx_9 0.30344
wandb:                   test_year 2024
wandb:         trainer/global_step 82247
wandb:    val_auc/dataloader_idx_0 0.81562
wandb:    val_auc/dataloader_idx_1 0.81851
wandb:   val_auc/dataloader_idx_10 0.75098
wandb:   val_auc/dataloader_idx_11 0.74347
wandb:    val_auc/dataloader_idx_2 0.83765
wandb:    val_auc/dataloader_idx_3 0.8507
wandb:    val_auc/dataloader_idx_4 0.83305
wandb:    val_auc/dataloader_idx_5 0.8118
wandb:    val_auc/dataloader_idx_6 0.82356
wandb:    val_auc/dataloader_idx_7 0.8057
wandb:    val_auc/dataloader_idx_8 0.80313
wandb:    val_auc/dataloader_idx_9 0.78054
wandb:   val_loss/dataloader_idx_0 0.27546
wandb:   val_loss/dataloader_idx_1 0.28436
wandb:  val_loss/dataloader_idx_10 0.31369
wandb:  val_loss/dataloader_idx_11 0.31844
wandb:   val_loss/dataloader_idx_2 0.2519
wandb:   val_loss/dataloader_idx_3 0.2593
wandb:   val_loss/dataloader_idx_4 0.28208
wandb:   val_loss/dataloader_idx_5 0.29437
wandb:   val_loss/dataloader_idx_6 0.27677
wandb:   val_loss/dataloader_idx_7 0.30439
wandb:   val_loss/dataloader_idx_8 0.32174
wandb:   val_loss/dataloader_idx_9 0.29327
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2021-seed-10 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/4dom5gjx
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260128_135606-4dom5gjx/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260129_044314-hkz4t5ls
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2022-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/hkz4t5ls
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2022.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2022.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80787336826324â€¦ â”‚ 0.82411038875579â€¦ â”‚ 0.8478705883026â€¦ â”‚
â”‚     test_loss     â”‚ 0.25961771607398â€¦ â”‚ 0.29097032546997â€¦ â”‚ 0.2501614987850â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83861911296844â€¦ â”‚ 0.83335673809051â€¦ â”‚ 0.8353425264358â€¦ â”‚
â”‚     test_loss     â”‚ 0.25625708699226â€¦ â”‚ 0.28713303804397â€¦ â”‚ 0.2629804611206â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80693054199218â€¦ â”‚ 0.81149411201477â€¦ â”‚ 0.7979475259780â€¦ â”‚
â”‚     test_loss     â”‚ 0.30122652649879â€¦ â”‚ 0.27935725450515â€¦ â”‚ 0.3160267770290â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.76708364486694â€¦ â”‚ 0.766775369644165 â”‚ 0.7438204884529â€¦ â”‚
â”‚     test_loss     â”‚ 0.31071248650550â€¦ â”‚ 0.31096151471138  â”‚ 0.3173210620880â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–†â–ƒâ–
wandb:              meta_loss_step â–†â–ƒâ–…â–ˆâ–‚â–„â–â–‚â–„â–‚â–‚â–‚â–…â–‚â–ˆâ–â–â–â–â–‚â–‚â–„â–â–‚â–‚â–â–„â–â–†â–‚â–„â–‚â–†â–‚â–†â–…â–ƒâ–„â–â–
wandb:                    test_auc â–…â–†â–ˆâ–‡â–‡â–‡â–…â–†â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–â–„â–
wandb:    val_auc/dataloader_idx_1 â–ˆâ–â–ƒâ–‚
wandb:   val_auc/dataloader_idx_10 â–â–†â–…â–ˆ
wandb:   val_auc/dataloader_idx_11 â–â–…â–†â–ˆ
wandb:    val_auc/dataloader_idx_2 â–ˆâ–„â–„â–
wandb:    val_auc/dataloader_idx_3 â–ˆâ–ƒâ–…â–
wandb:    val_auc/dataloader_idx_4 â–ˆâ–â–†â–‚
wandb:    val_auc/dataloader_idx_5 â–†â–ƒâ–ˆâ–
wandb:    val_auc/dataloader_idx_6 â–â–ƒâ–ˆâ–
wandb:    val_auc/dataloader_idx_7 â–ˆâ–…â–‚â–
wandb:    val_auc/dataloader_idx_8 â–†â–ˆâ–„â–
wandb:    val_auc/dataloader_idx_9 â–ˆâ–‡â–ƒâ–
wandb:   val_loss/dataloader_idx_0 â–…â–ˆâ–â–„
wandb:   val_loss/dataloader_idx_1 â–ƒâ–ˆâ–â–ƒ
wandb:  val_loss/dataloader_idx_10 â–ˆâ–…â–‡â–
wandb:  val_loss/dataloader_idx_11 â–â–â–ˆâ–‚
wandb:   val_loss/dataloader_idx_2 â–â–ˆâ–…â–†
wandb:   val_loss/dataloader_idx_3 â–„â–ˆâ–â–„
wandb:   val_loss/dataloader_idx_4 â–ƒâ–ˆâ–â–‚
wandb:   val_loss/dataloader_idx_5 â–…â–ˆâ–â–ƒ
wandb:   val_loss/dataloader_idx_6 â–†â–ˆâ–â–
wandb:   val_loss/dataloader_idx_7 â–â–…â–†â–ˆ
wandb:   val_loss/dataloader_idx_8 â–â–‚â–…â–ˆ
wandb:   val_loss/dataloader_idx_9 â–â–‚â–†â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 4
wandb:             meta_loss_epoch 0.16482
wandb:              meta_loss_step 0.26518
wandb:                    test_auc 0.74382
wandb:   test_auc/dataloader_idx_0 0.80787
wandb:   test_auc/dataloader_idx_1 0.82411
wandb:  test_auc/dataloader_idx_10 0.76678
wandb:  test_auc/dataloader_idx_11 0.74382
wandb:   test_auc/dataloader_idx_2 0.84787
wandb:   test_auc/dataloader_idx_3 0.83862
wandb:   test_auc/dataloader_idx_4 0.83336
wandb:   test_auc/dataloader_idx_5 0.83534
wandb:   test_auc/dataloader_idx_6 0.80693
wandb:   test_auc/dataloader_idx_7 0.81149
wandb:   test_auc/dataloader_idx_8 0.79795
wandb:   test_auc/dataloader_idx_9 0.76708
wandb:  test_loss/dataloader_idx_0 0.25962
wandb:  test_loss/dataloader_idx_1 0.29097
wandb: test_loss/dataloader_idx_10 0.31096
wandb: test_loss/dataloader_idx_11 0.31732
wandb:  test_loss/dataloader_idx_2 0.25016
wandb:  test_loss/dataloader_idx_3 0.25626
wandb:  test_loss/dataloader_idx_4 0.28713
wandb:  test_loss/dataloader_idx_5 0.26298
wandb:  test_loss/dataloader_idx_6 0.30123
wandb:  test_loss/dataloader_idx_7 0.27936
wandb:  test_loss/dataloader_idx_8 0.31603
wandb:  test_loss/dataloader_idx_9 0.31071
wandb:                   test_year 2024
wandb:         trainer/global_step 65020
wandb:    val_auc/dataloader_idx_0 0.81052
wandb:    val_auc/dataloader_idx_1 0.81983
wandb:   val_auc/dataloader_idx_10 0.76382
wandb:   val_auc/dataloader_idx_11 0.75145
wandb:    val_auc/dataloader_idx_2 0.82958
wandb:    val_auc/dataloader_idx_3 0.85164
wandb:    val_auc/dataloader_idx_4 0.83028
wandb:    val_auc/dataloader_idx_5 0.81521
wandb:    val_auc/dataloader_idx_6 0.82468
wandb:    val_auc/dataloader_idx_7 0.80257
wandb:    val_auc/dataloader_idx_8 0.79882
wandb:    val_auc/dataloader_idx_9 0.76253
wandb:   val_loss/dataloader_idx_0 0.26961
wandb:   val_loss/dataloader_idx_1 0.27708
wandb:  val_loss/dataloader_idx_10 0.3053
wandb:  val_loss/dataloader_idx_11 0.32171
wandb:   val_loss/dataloader_idx_2 0.25178
wandb:   val_loss/dataloader_idx_3 0.25401
wandb:   val_loss/dataloader_idx_4 0.28195
wandb:   val_loss/dataloader_idx_5 0.29008
wandb:   val_loss/dataloader_idx_6 0.27447
wandb:   val_loss/dataloader_idx_7 0.30322
wandb:   val_loss/dataloader_idx_8 0.33359
wandb:   val_loss/dataloader_idx_9 0.37638
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2022-seed-10 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/hkz4t5ls
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260129_044314-hkz4t5ls/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260129_145414-07wg8i3q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2023-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/07wg8i3q
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2023.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2023.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80146580934524â€¦ â”‚ 0.82117760181427  â”‚ 0.8510992527008â€¦ â”‚
â”‚     test_loss     â”‚ 0.26796522736549â€¦ â”‚ 0.29988592863082â€¦ â”‚ 0.2499166578054â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83705294132232â€¦ â”‚ 0.83220487833023â€¦ â”‚ 0.8350026607513â€¦ â”‚
â”‚     test_loss     â”‚ 0.26104411482810â€¦ â”‚ 0.29399022459983â€¦ â”‚ 0.2642565071582â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80486553907394â€¦ â”‚ 0.80909341573715â€¦ â”‚ 0.8006466031074â€¦ â”‚
â”‚     test_loss     â”‚ 0.30434849858283â€¦ â”‚ 0.28201976418495â€¦ â”‚ 0.3147898018360â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.76719927787780â€¦ â”‚ 0.77021574974060â€¦ â”‚ 0.7440074682235â€¦ â”‚
â”‚     test_loss     â”‚ 0.30976566672325â€¦ â”‚ 0.31104797124862â€¦ â”‚ 0.3174442648887â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–â–â–â–â–„â–ˆ
wandb:              meta_loss_step â–„â–‚â–â–„â–‚â–„â–â–â–â–‚â–â–…â–ˆâ–ƒâ–‚â–â–…â–…â–ƒâ–„â–‚â–â–‚â–â–ˆâ–ƒâ–â–â–â–ƒâ–â–â–„â–â–â–„â–„â–„â–„â–
wandb:                    test_auc â–…â–†â–ˆâ–‡â–‡â–‡â–…â–…â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚
wandb:    val_auc/dataloader_idx_1 â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚
wandb:   val_auc/dataloader_idx_10 â–ˆâ–ˆâ–ˆâ–ˆâ–â–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–ˆâ–ˆâ–ˆâ–â–
wandb:    val_auc/dataloader_idx_2 â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚
wandb:    val_auc/dataloader_idx_3 â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚
wandb:    val_auc/dataloader_idx_4 â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚
wandb:    val_auc/dataloader_idx_5 â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚
wandb:    val_auc/dataloader_idx_6 â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚
wandb:    val_auc/dataloader_idx_7 â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚
wandb:    val_auc/dataloader_idx_8 â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚
wandb:    val_auc/dataloader_idx_9 â–ˆâ–ˆâ–ˆâ–ˆâ–â–
wandb:   val_loss/dataloader_idx_0 â–‚â–â–â–â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_1 â–‚â–â–â–â–ˆâ–ˆ
wandb:  val_loss/dataloader_idx_10 â–â–â–â–â–ˆâ–ˆ
wandb:  val_loss/dataloader_idx_11 â–â–â–â–â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_2 â–â–â–â–â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_3 â–â–â–â–â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_4 â–â–â–â–â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_5 â–‚â–â–â–â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_6 â–â–â–â–â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_7 â–â–â–‚â–â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_8 â–â–â–‚â–â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_9 â–â–â–â–â–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 6
wandb:             meta_loss_epoch 0.32883
wandb:              meta_loss_step 0.06475
wandb:                    test_auc 0.74401
wandb:   test_auc/dataloader_idx_0 0.80147
wandb:   test_auc/dataloader_idx_1 0.82118
wandb:  test_auc/dataloader_idx_10 0.77022
wandb:  test_auc/dataloader_idx_11 0.74401
wandb:   test_auc/dataloader_idx_2 0.8511
wandb:   test_auc/dataloader_idx_3 0.83705
wandb:   test_auc/dataloader_idx_4 0.8322
wandb:   test_auc/dataloader_idx_5 0.835
wandb:   test_auc/dataloader_idx_6 0.80487
wandb:   test_auc/dataloader_idx_7 0.80909
wandb:   test_auc/dataloader_idx_8 0.80065
wandb:   test_auc/dataloader_idx_9 0.7672
wandb:  test_loss/dataloader_idx_0 0.26797
wandb:  test_loss/dataloader_idx_1 0.29989
wandb: test_loss/dataloader_idx_10 0.31105
wandb: test_loss/dataloader_idx_11 0.31744
wandb:  test_loss/dataloader_idx_2 0.24992
wandb:  test_loss/dataloader_idx_3 0.26104
wandb:  test_loss/dataloader_idx_4 0.29399
wandb:  test_loss/dataloader_idx_5 0.26426
wandb:  test_loss/dataloader_idx_6 0.30435
wandb:  test_loss/dataloader_idx_7 0.28202
wandb:  test_loss/dataloader_idx_8 0.31479
wandb:  test_loss/dataloader_idx_9 0.30977
wandb:                   test_year 2024
wandb:         trainer/global_step 109290
wandb:    val_auc/dataloader_idx_0 0.50951
wandb:    val_auc/dataloader_idx_1 0.48241
wandb:   val_auc/dataloader_idx_10 0.6003
wandb:   val_auc/dataloader_idx_11 0.60245
wandb:    val_auc/dataloader_idx_2 0.51701
wandb:    val_auc/dataloader_idx_3 0.4895
wandb:    val_auc/dataloader_idx_4 0.50037
wandb:    val_auc/dataloader_idx_5 0.51589
wandb:    val_auc/dataloader_idx_6 0.52718
wandb:    val_auc/dataloader_idx_7 0.55543
wandb:    val_auc/dataloader_idx_8 0.58286
wandb:    val_auc/dataloader_idx_9 0.63144
wandb:   val_loss/dataloader_idx_0 0.33289
wandb:   val_loss/dataloader_idx_1 0.3511
wandb:  val_loss/dataloader_idx_10 0.35292
wandb:  val_loss/dataloader_idx_11 0.35218
wandb:   val_loss/dataloader_idx_2 0.31965
wandb:   val_loss/dataloader_idx_3 0.34112
wandb:   val_loss/dataloader_idx_4 0.36022
wandb:   val_loss/dataloader_idx_5 0.35389
wandb:   val_loss/dataloader_idx_6 0.34765
wandb:   val_loss/dataloader_idx_7 0.34754
wandb:   val_loss/dataloader_idx_8 0.37237
wandb:   val_loss/dataloader_idx_9 0.34697
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2023-seed-10 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/07wg8i3q
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260129_145414-07wg8i3q/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260130_074948-25z2y6wy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2024-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/25z2y6wy
Skipping year 2024: TMAML requires future year at index 12, but only 12 training years are available.
Saved results to: /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/results/la_maml_clinical_v2/tmaml-sequential-2013-2024/tmaml-sequential-2013-2024-seed-10.csv
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mtmaml-sequential-2013-2024-2024-seed-10[0m at: [34mhttps://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/25z2y6wy[0m
[1;34mwandb[0m: Find logs at: [1;35m../../../../../scratch/slj9342/wandb/wandb/run-20260130_074948-25z2y6wy/logs[0m
============================================
End time: Fri Jan 30 07:49:59 EST 2026
Job completed successfully
