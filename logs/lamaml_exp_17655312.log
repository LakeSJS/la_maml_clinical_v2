============================================
Job ID: 17655312
Job Name: lamaml_exp
Node: a100-4022
Partition: a100_short
Start time: Sat Jan 24 16:46:00 EST 2026
Config: tmaml_seq_2013_2024
Seed: 11
Paths: gpfs
============================================
Running: python /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/scripts/run_experiment.py --config tmaml_seq_2013_2024 --paths gpfs --seed 11
============================================
[rank: 0] Global seed set to 11
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /gpfs/data/oermannlab/NYUTron/model_zoos/nyutron_small/checkpoint-736000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: lakej98 (lakej98-nyu-langone-health) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260124_164741-9b2uk46c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2013-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/9b2uk46c
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11/best-checkpoint-2013-v2.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11/best-checkpoint-2013-v2.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82274705171585â€¦ â”‚ 0.83206480741500â€¦ â”‚ 0.8425393700599â€¦ â”‚
â”‚     test_loss     â”‚ 0.25887686014175â€¦ â”‚ 0.27839508652687â€¦ â”‚ 0.2578675746917â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83243560791015â€¦ â”‚ 0.81956726312637â€¦ â”‚ 0.8169859051704â€¦ â”‚
â”‚     test_loss     â”‚ 0.26074251532554â€¦ â”‚ 0.29329514503479â€¦ â”‚ 0.2690441906452â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78307431936264â€¦ â”‚ 0.78299093246459â€¦ â”‚ 0.7706130146980â€¦ â”‚
â”‚     test_loss     â”‚ 0.30510109663009â€¦ â”‚ 0.28301614522933â€¦ â”‚ 0.3178445398807â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74526178836822â€¦ â”‚ 0.73131549358367â€¦ â”‚ 0.7078484296798â€¦ â”‚
â”‚     test_loss     â”‚ 0.31823170185089â€¦ â”‚ 0.32660853862762â€¦ â”‚ 0.3315620124340â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb:              meta_loss_step â–…â–ƒâ–â–‚â–…â–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–†â–â–‚â–„â–â–‚â–â–ƒâ–ƒâ–â–â–„â–…â–â–â–â–‚â–ˆâ–â–â–ˆâ–†â–â–‚â–â–â–â–â–‚
wandb:                    test_auc â–‡â–‡â–ˆâ–‡â–‡â–‡â–…â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–â–ƒâ–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_1 â–â–„â–…â–†â–†â–†â–‡â–†â–‡â–†â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡
wandb:   val_auc/dataloader_idx_10 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡
wandb:   val_auc/dataloader_idx_11 â–â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡
wandb:    val_auc/dataloader_idx_2 â–â–ƒâ–„â–…â–…â–…â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_3 â–â–„â–…â–…â–…â–†â–†â–…â–†â–‡â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:    val_auc/dataloader_idx_4 â–â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:    val_auc/dataloader_idx_5 â–â–„â–„â–…â–…â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_6 â–â–„â–…â–†â–†â–†â–‡â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–ƒâ–…â–…â–…â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_8 â–â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡
wandb:    val_auc/dataloader_idx_9 â–â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_0 â–ˆâ–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–„â–ƒ
wandb:   val_loss/dataloader_idx_1 â–ˆâ–‡â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:  val_loss/dataloader_idx_10 â–†â–ˆâ–‚â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  val_loss/dataloader_idx_11 â–†â–ˆâ–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–
wandb:   val_loss/dataloader_idx_2 â–ˆâ–ˆâ–†â–…â–…â–…â–„â–„â–ƒâ–„â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–‚â–â–â–‚â–â–
wandb:   val_loss/dataloader_idx_3 â–ˆâ–ˆâ–…â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–‚â–â–‚â–‚â–‚â–â–â–
wandb:   val_loss/dataloader_idx_4 â–‡â–ˆâ–†â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–â–
wandb:   val_loss/dataloader_idx_5 â–‡â–ˆâ–†â–…â–†â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:   val_loss/dataloader_idx_6 â–‡â–ˆâ–†â–„â–…â–„â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:   val_loss/dataloader_idx_7 â–†â–ˆâ–†â–…â–…â–„â–„â–„â–„â–…â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–
wandb:   val_loss/dataloader_idx_8 â–‡â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:   val_loss/dataloader_idx_9 â–†â–ˆâ–„â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–â–â–â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:                       epoch 22
wandb:             meta_loss_epoch 0.15263
wandb:              meta_loss_step 0.12789
wandb:                    test_auc 0.70785
wandb:   test_auc/dataloader_idx_0 0.82275
wandb:   test_auc/dataloader_idx_1 0.83206
wandb:  test_auc/dataloader_idx_10 0.73132
wandb:  test_auc/dataloader_idx_11 0.70785
wandb:   test_auc/dataloader_idx_2 0.84254
wandb:   test_auc/dataloader_idx_3 0.83244
wandb:   test_auc/dataloader_idx_4 0.81957
wandb:   test_auc/dataloader_idx_5 0.81699
wandb:   test_auc/dataloader_idx_6 0.78307
wandb:   test_auc/dataloader_idx_7 0.78299
wandb:   test_auc/dataloader_idx_8 0.77061
wandb:   test_auc/dataloader_idx_9 0.74526
wandb:  test_loss/dataloader_idx_0 0.25888
wandb:  test_loss/dataloader_idx_1 0.2784
wandb: test_loss/dataloader_idx_10 0.32661
wandb: test_loss/dataloader_idx_11 0.33156
wandb:  test_loss/dataloader_idx_2 0.25787
wandb:  test_loss/dataloader_idx_3 0.26074
wandb:  test_loss/dataloader_idx_4 0.2933
wandb:  test_loss/dataloader_idx_5 0.26904
wandb:  test_loss/dataloader_idx_6 0.3051
wandb:  test_loss/dataloader_idx_7 0.28302
wandb:  test_loss/dataloader_idx_8 0.31784
wandb:  test_loss/dataloader_idx_9 0.31823
wandb:                   test_year 2024
wandb:         trainer/global_step 139106
wandb:    val_auc/dataloader_idx_0 0.83222
wandb:    val_auc/dataloader_idx_1 0.83116
wandb:   val_auc/dataloader_idx_10 0.72473
wandb:   val_auc/dataloader_idx_11 0.71379
wandb:    val_auc/dataloader_idx_2 0.83458
wandb:    val_auc/dataloader_idx_3 0.83714
wandb:    val_auc/dataloader_idx_4 0.81575
wandb:    val_auc/dataloader_idx_5 0.80585
wandb:    val_auc/dataloader_idx_6 0.80087
wandb:    val_auc/dataloader_idx_7 0.77078
wandb:    val_auc/dataloader_idx_8 0.7637
wandb:    val_auc/dataloader_idx_9 0.74264
wandb:   val_loss/dataloader_idx_0 0.26878
wandb:   val_loss/dataloader_idx_1 0.26974
wandb:  val_loss/dataloader_idx_10 0.3253
wandb:  val_loss/dataloader_idx_11 0.32975
wandb:   val_loss/dataloader_idx_2 0.24907
wandb:   val_loss/dataloader_idx_3 0.25963
wandb:   val_loss/dataloader_idx_4 0.28546
wandb:   val_loss/dataloader_idx_5 0.28715
wandb:   val_loss/dataloader_idx_6 0.28153
wandb:   val_loss/dataloader_idx_7 0.29626
wandb:   val_loss/dataloader_idx_8 0.31467
wandb:   val_loss/dataloader_idx_9 0.31401
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2013-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/9b2uk46c
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260124_164741-9b2uk46c/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260125_153708-tt6a2zjk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2014-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/tt6a2zjk
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11/best-checkpoint-2014.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11/best-checkpoint-2014.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82486796379089â€¦ â”‚ 0.83529835939407â€¦ â”‚ 0.8484323024749â€¦ â”‚
â”‚     test_loss     â”‚ 0.25996732711791â€¦ â”‚ 0.28145205974578â€¦ â”‚ 0.2551093399524â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83948087692260â€¦ â”‚ 0.83060455322265â€¦ â”‚ 0.8265148401260â€¦ â”‚
â”‚     test_loss     â”‚ 0.25742274522781â€¦ â”‚ 0.28914803266525â€¦ â”‚ 0.2655384540557â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78795707225799â€¦ â”‚ 0.787980318069458 â”‚ 0.7698365449905â€¦ â”‚
â”‚     test_loss     â”‚ 0.30622529983520â€¦ â”‚ 0.28208336234092â€¦ â”‚ 0.3214940726757â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74626898765563â€¦ â”‚ 0.73518455028533â€¦ â”‚ 0.70912104845047 â”‚
â”‚     test_loss     â”‚ 0.32066190242767â€¦ â”‚ 0.32850411534309â€¦ â”‚ 0.3340166211128â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:             meta_loss_epoch â–ˆâ–†â–…â–„â–ƒâ–
wandb:              meta_loss_step â–â–‚â–â–…â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ˆâ–â–â–ƒâ–‚â–‚â–â–â–ƒâ–â–ƒâ–â–â–‚â–†â–‚â–â–ƒâ–„â–ƒâ–‚â–â–‚â–‚â–â–â–‚â–…â–ƒâ–
wandb:                    test_auc â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–…â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–‡â–‡â–„â–‚â–
wandb:    val_auc/dataloader_idx_1 â–â–…â–ˆâ–‚â–‚â–„
wandb:   val_auc/dataloader_idx_10 â–‚â–†â–â–„â–â–ˆ
wandb:   val_auc/dataloader_idx_11 â–â–†â–„â–†â–ƒâ–ˆ
wandb:    val_auc/dataloader_idx_2 â–â–„â–…â–„â–…â–ˆ
wandb:    val_auc/dataloader_idx_3 â–„â–â–‡â–ˆâ–„â–†
wandb:    val_auc/dataloader_idx_4 â–â–ƒâ–†â–ˆâ–…â–‡
wandb:    val_auc/dataloader_idx_5 â–â–„â–…â–†â–…â–ˆ
wandb:    val_auc/dataloader_idx_6 â–â–ƒâ–‡â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–†â–‡â–‡â–†â–ˆ
wandb:    val_auc/dataloader_idx_8 â–â–…â–†â–ˆâ–…â–†
wandb:    val_auc/dataloader_idx_9 â–†â–ˆâ–‡â–ˆâ–â–
wandb:   val_loss/dataloader_idx_0 â–ƒâ–â–‚â–ƒâ–ˆâ–‡
wandb:   val_loss/dataloader_idx_1 â–ƒâ–â–‚â–‚â–ˆâ–…
wandb:  val_loss/dataloader_idx_10 â–„â–‚â–…â–â–ˆâ–ƒ
wandb:  val_loss/dataloader_idx_11 â–…â–„â–…â–â–ˆâ–„
wandb:   val_loss/dataloader_idx_2 â–ˆâ–ˆâ–†â–ƒâ–ˆâ–
wandb:   val_loss/dataloader_idx_3 â–†â–„â–ƒâ–â–ˆâ–„
wandb:   val_loss/dataloader_idx_4 â–†â–‚â–ƒâ–â–ˆâ–ƒ
wandb:   val_loss/dataloader_idx_5 â–…â–‚â–„â–â–ˆâ–ƒ
wandb:   val_loss/dataloader_idx_6 â–†â–ƒâ–ƒâ–â–ˆâ–ƒ
wandb:   val_loss/dataloader_idx_7 â–†â–‚â–ƒâ–â–ˆâ–ƒ
wandb:   val_loss/dataloader_idx_8 â–…â–ƒâ–„â–â–ˆâ–„
wandb:   val_loss/dataloader_idx_9 â–„â–ƒâ–„â–â–ˆâ–„
wandb: 
wandb: Run summary:
wandb:                       epoch 6
wandb:             meta_loss_epoch 0.14399
wandb:              meta_loss_step 0.01558
wandb:                    test_auc 0.70912
wandb:   test_auc/dataloader_idx_0 0.82487
wandb:   test_auc/dataloader_idx_1 0.8353
wandb:  test_auc/dataloader_idx_10 0.73518
wandb:  test_auc/dataloader_idx_11 0.70912
wandb:   test_auc/dataloader_idx_2 0.84843
wandb:   test_auc/dataloader_idx_3 0.83948
wandb:   test_auc/dataloader_idx_4 0.8306
wandb:   test_auc/dataloader_idx_5 0.82651
wandb:   test_auc/dataloader_idx_6 0.78796
wandb:   test_auc/dataloader_idx_7 0.78798
wandb:   test_auc/dataloader_idx_8 0.76984
wandb:   test_auc/dataloader_idx_9 0.74627
wandb:  test_loss/dataloader_idx_0 0.25997
wandb:  test_loss/dataloader_idx_1 0.28145
wandb: test_loss/dataloader_idx_10 0.3285
wandb: test_loss/dataloader_idx_11 0.33402
wandb:  test_loss/dataloader_idx_2 0.25511
wandb:  test_loss/dataloader_idx_3 0.25742
wandb:  test_loss/dataloader_idx_4 0.28915
wandb:  test_loss/dataloader_idx_5 0.26554
wandb:  test_loss/dataloader_idx_6 0.30623
wandb:  test_loss/dataloader_idx_7 0.28208
wandb:  test_loss/dataloader_idx_8 0.32149
wandb:  test_loss/dataloader_idx_9 0.32066
wandb:                   test_year 2024
wandb:         trainer/global_step 41424
wandb:    val_auc/dataloader_idx_0 0.82533
wandb:    val_auc/dataloader_idx_1 0.83512
wandb:   val_auc/dataloader_idx_10 0.73138
wandb:   val_auc/dataloader_idx_11 0.71866
wandb:    val_auc/dataloader_idx_2 0.84351
wandb:    val_auc/dataloader_idx_3 0.84541
wandb:    val_auc/dataloader_idx_4 0.8262
wandb:    val_auc/dataloader_idx_5 0.81273
wandb:    val_auc/dataloader_idx_6 0.80887
wandb:    val_auc/dataloader_idx_7 0.77722
wandb:    val_auc/dataloader_idx_8 0.77365
wandb:    val_auc/dataloader_idx_9 0.74512
wandb:   val_loss/dataloader_idx_0 0.27975
wandb:   val_loss/dataloader_idx_1 0.27737
wandb:  val_loss/dataloader_idx_10 0.32791
wandb:  val_loss/dataloader_idx_11 0.3327
wandb:   val_loss/dataloader_idx_2 0.2453
wandb:   val_loss/dataloader_idx_3 0.25947
wandb:   val_loss/dataloader_idx_4 0.28565
wandb:   val_loss/dataloader_idx_5 0.29033
wandb:   val_loss/dataloader_idx_6 0.28217
wandb:   val_loss/dataloader_idx_7 0.29971
wandb:   val_loss/dataloader_idx_8 0.31726
wandb:   val_loss/dataloader_idx_9 0.31867
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2014-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/tt6a2zjk
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260125_153708-tt6a2zjk/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260125_224117-rox28vo7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2015-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/rox28vo7
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11/best-checkpoint-2015.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11/best-checkpoint-2015.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82467532157897â€¦ â”‚ 0.835483193397522 â”‚ 0.8509303927421â€¦ â”‚
â”‚     test_loss     â”‚ 0.26596143841743â€¦ â”‚ 0.29218313097953â€¦ â”‚ 0.2591999471187â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.848930835723877 â”‚ 0.83691251277923â€¦ â”‚ 0.8315184712409â€¦ â”‚
â”‚     test_loss     â”‚ 0.24966053664684â€¦ â”‚ 0.27530354261398â€¦ â”‚ 0.2581313252449â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78981018066406â€¦ â”‚ 0.795863926410675 â”‚ 0.7708893418312â€¦ â”‚
â”‚     test_loss     â”‚ 0.29737240076065â€¦ â”‚ 0.27370885014533â€¦ â”‚ 0.3142042160034â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.75036150217056â€¦ â”‚ 0.73828697204589â€¦ â”‚ 0.7114409208297â€¦ â”‚
â”‚     test_loss     â”‚ 0.314830482006073 â”‚ 0.32275748252868â€¦ â”‚ 0.3287846446037â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:             meta_loss_epoch â–ˆâ–‡â–…â–„â–ƒâ–ƒâ–â–
wandb:              meta_loss_step â–‚â–â–‚â–„â–â–‚â–‚â–…â–â–â–‚â–‚â–â–…â–â–â–‡â–â–â–ˆâ–ƒâ–â–â–„â–‚â–‡â–ƒâ–†â–â–‡â–â–ƒâ–ƒâ–â–â–‚â–‚â–â–†â–
wandb:                    test_auc â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–…â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–‡â–†â–„â–†â–ƒâ–â–
wandb:    val_auc/dataloader_idx_1 â–â–…â–â–†â–ˆâ–„â–‡â–†
wandb:   val_auc/dataloader_idx_10 â–â–„â–ƒâ–ˆâ–„â–‚â–…â–„
wandb:   val_auc/dataloader_idx_11 â–â–†â–„â–ˆâ–†â–„â–†â–…
wandb:    val_auc/dataloader_idx_2 â–ƒâ–ƒâ–‚â–ˆâ–ˆâ–â–‡â–‚
wandb:    val_auc/dataloader_idx_3 â–â–ƒâ–„â–†â–†â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_4 â–â–„â–„â–…â–†â–„â–‡â–ˆ
wandb:    val_auc/dataloader_idx_5 â–â–ƒâ–„â–…â–ˆâ–†â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_6 â–â–ƒâ–„â–†â–†â–„â–‡â–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–ƒâ–ƒâ–‡â–ˆâ–…â–‡â–ˆ
wandb:    val_auc/dataloader_idx_8 â–â–‡â–„â–ˆâ–ˆâ–…â–ˆâ–„
wandb:    val_auc/dataloader_idx_9 â–â–‚â–â–ˆâ–ƒâ–‚â–‡â–†
wandb:   val_loss/dataloader_idx_0 â–â–â–‚â–ƒâ–„â–…â–ˆâ–‡
wandb:   val_loss/dataloader_idx_1 â–‚â–â–‚â–ƒâ–ƒâ–…â–ˆâ–ˆ
wandb:  val_loss/dataloader_idx_10 â–ˆâ–ƒâ–ƒâ–„â–â–‚â–…â–†
wandb:  val_loss/dataloader_idx_11 â–ˆâ–ƒâ–ƒâ–†â–â–â–…â–ˆ
wandb:   val_loss/dataloader_idx_2 â–â–â–‚â–ƒâ–„â–…â–‡â–ˆ
wandb:   val_loss/dataloader_idx_3 â–ˆâ–†â–…â–…â–ƒâ–â–‚â–
wandb:   val_loss/dataloader_idx_4 â–ˆâ–…â–…â–„â–‚â–‚â–‚â–
wandb:   val_loss/dataloader_idx_5 â–ˆâ–†â–„â–„â–‚â–â–‚â–‚
wandb:   val_loss/dataloader_idx_6 â–ˆâ–†â–„â–ƒâ–‚â–â–‚â–
wandb:   val_loss/dataloader_idx_7 â–ˆâ–†â–„â–„â–â–â–ƒâ–‚
wandb:   val_loss/dataloader_idx_8 â–ˆâ–…â–„â–ƒâ–â–â–ƒâ–„
wandb:   val_loss/dataloader_idx_9 â–ˆâ–…â–ƒâ–ƒâ–â–â–ƒâ–…
wandb: 
wandb: Run summary:
wandb:                       epoch 8
wandb:             meta_loss_epoch 0.13987
wandb:              meta_loss_step 0.29969
wandb:                    test_auc 0.71144
wandb:   test_auc/dataloader_idx_0 0.82468
wandb:   test_auc/dataloader_idx_1 0.83548
wandb:  test_auc/dataloader_idx_10 0.73829
wandb:  test_auc/dataloader_idx_11 0.71144
wandb:   test_auc/dataloader_idx_2 0.85093
wandb:   test_auc/dataloader_idx_3 0.84893
wandb:   test_auc/dataloader_idx_4 0.83691
wandb:   test_auc/dataloader_idx_5 0.83152
wandb:   test_auc/dataloader_idx_6 0.78981
wandb:   test_auc/dataloader_idx_7 0.79586
wandb:   test_auc/dataloader_idx_8 0.77089
wandb:   test_auc/dataloader_idx_9 0.75036
wandb:  test_loss/dataloader_idx_0 0.26596
wandb:  test_loss/dataloader_idx_1 0.29218
wandb: test_loss/dataloader_idx_10 0.32276
wandb: test_loss/dataloader_idx_11 0.32878
wandb:  test_loss/dataloader_idx_2 0.2592
wandb:  test_loss/dataloader_idx_3 0.24966
wandb:  test_loss/dataloader_idx_4 0.2753
wandb:  test_loss/dataloader_idx_5 0.25813
wandb:  test_loss/dataloader_idx_6 0.29737
wandb:  test_loss/dataloader_idx_7 0.27371
wandb:  test_loss/dataloader_idx_8 0.3142
wandb:  test_loss/dataloader_idx_9 0.31483
wandb:                   test_year 2024
wandb:         trainer/global_step 58480
wandb:    val_auc/dataloader_idx_0 0.82697
wandb:    val_auc/dataloader_idx_1 0.83574
wandb:   val_auc/dataloader_idx_10 0.73262
wandb:   val_auc/dataloader_idx_11 0.71903
wandb:    val_auc/dataloader_idx_2 0.83864
wandb:    val_auc/dataloader_idx_3 0.85859
wandb:    val_auc/dataloader_idx_4 0.83647
wandb:    val_auc/dataloader_idx_5 0.81785
wandb:    val_auc/dataloader_idx_6 0.81423
wandb:    val_auc/dataloader_idx_7 0.78291
wandb:    val_auc/dataloader_idx_8 0.7751
wandb:    val_auc/dataloader_idx_9 0.75017
wandb:   val_loss/dataloader_idx_0 0.28849
wandb:   val_loss/dataloader_idx_1 0.28784
wandb:  val_loss/dataloader_idx_10 0.32706
wandb:  val_loss/dataloader_idx_11 0.33265
wandb:   val_loss/dataloader_idx_2 0.26498
wandb:   val_loss/dataloader_idx_3 0.2463
wandb:   val_loss/dataloader_idx_4 0.27252
wandb:   val_loss/dataloader_idx_5 0.27991
wandb:   val_loss/dataloader_idx_6 0.274
wandb:   val_loss/dataloader_idx_7 0.29095
wandb:   val_loss/dataloader_idx_8 0.31217
wandb:   val_loss/dataloader_idx_9 0.31559
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2015-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/rox28vo7
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260125_224117-rox28vo7/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260126_085037-o8yn6lcb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2016-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/o8yn6lcb
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11/best-checkpoint-2016.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11/best-checkpoint-2016.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82135736942291â€¦ â”‚ 0.83186000585556â€¦ â”‚ 0.8501030802726â€¦ â”‚
â”‚     test_loss     â”‚ 0.27281445264816â€¦ â”‚ 0.30647346377372â€¦ â”‚ 0.2672740817070â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.85020494461059â€¦ â”‚ 0.84097242355346â€¦ â”‚ 0.8421959877014â€¦ â”‚
â”‚     test_loss     â”‚ 0.25917989015579â€¦ â”‚ 0.26961994171142â€¦ â”‚ 0.2519514858722â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.79819536209106â€¦ â”‚ 0.80628573894500â€¦ â”‚ 0.7797769308090â€¦ â”‚
â”‚     test_loss     â”‚ 0.29334515333175â€¦ â”‚ 0.26943430304527â€¦ â”‚ 0.3176930546760â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.75300383567810â€¦ â”‚ 0.73837876319885â€¦ â”‚ 0.7166674137115â€¦ â”‚
â”‚     test_loss     â”‚ 0.323688268661499 â”‚ 0.33727347850799â€¦ â”‚ 0.3457281887531â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–‡â–†â–…â–„â–„â–ƒâ–‚â–â–
wandb:              meta_loss_step â–â–â–â–†â–â–‚â–â–â–ˆâ–â–â–„â–â–â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–„â–â–ƒâ–‚â–„â–‚â–ƒâ–â–ˆâ–â–â–ƒâ–‚â–
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–…â–†â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–‡â–„â–‡â–â–â–ƒâ–‚â–ƒâ–‡
wandb:    val_auc/dataloader_idx_1 â–‡â–‡â–ˆâ–ˆâ–ƒâ–‚â–ƒâ–‚â–â–„
wandb:   val_auc/dataloader_idx_10 â–„â–„â–„â–â–ƒâ–†â–ˆâ–†â–‡â–ˆ
wandb:   val_auc/dataloader_idx_11 â–ˆâ–ˆâ–…â–„â–…â–„â–†â–â–„â–…
wandb:    val_auc/dataloader_idx_2 â–ˆâ–ˆâ–‡â–‡â–„â–…â–„â–‚â–â–
wandb:    val_auc/dataloader_idx_3 â–‚â–†â–‚â–â–†â–ƒâ–ˆâ–…â–„â–ƒ
wandb:    val_auc/dataloader_idx_4 â–â–‚â–„â–…â–…â–…â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_5 â–â–„â–„â–ˆâ–†â–†â–ˆâ–‡â–‡â–‡
wandb:    val_auc/dataloader_idx_6 â–â–‚â–„â–†â–†â–…â–ˆâ–…â–…â–…
wandb:    val_auc/dataloader_idx_7 â–â–„â–…â–…â–„â–…â–ˆâ–…â–…â–…
wandb:    val_auc/dataloader_idx_8 â–„â–†â–â–ƒâ–„â–‚â–ˆâ–ƒâ–ƒâ–‚
wandb:    val_auc/dataloader_idx_9 â–â–‚â–â–â–„â–…â–ˆâ–†â–ˆâ–‡
wandb:   val_loss/dataloader_idx_0 â–â–‚â–â–‚â–ˆâ–…â–…â–„â–†â–†
wandb:   val_loss/dataloader_idx_1 â–â–‚â–â–‚â–‡â–†â–†â–†â–ˆâ–ˆ
wandb:  val_loss/dataloader_idx_10 â–‚â–â–‚â–â–ƒâ–‚â–„â–†â–ˆâ–†
wandb:  val_loss/dataloader_idx_11 â–â–â–‚â–â–‚â–ƒâ–…â–†â–ˆâ–†
wandb:   val_loss/dataloader_idx_2 â–â–â–‚â–‚â–…â–„â–…â–†â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_3 â–â–â–‚â–‚â–ƒâ–„â–…â–†â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_4 â–ˆâ–‡â–†â–…â–†â–„â–ƒâ–‚â–‚â–
wandb:   val_loss/dataloader_idx_5 â–ˆâ–‡â–…â–ƒâ–…â–‚â–‚â–â–â–
wandb:   val_loss/dataloader_idx_6 â–ˆâ–ˆâ–„â–‚â–…â–â–â–â–â–‚
wandb:   val_loss/dataloader_idx_7 â–‡â–…â–‚â–â–ˆâ–ƒâ–‚â–…â–†â–†
wandb:   val_loss/dataloader_idx_8 â–â–‚â–â–â–„â–ƒâ–„â–†â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_9 â–‚â–â–‚â–â–„â–‚â–ƒâ–†â–ˆâ–‡
wandb: 
wandb: Run summary:
wandb:                       epoch 10
wandb:             meta_loss_epoch 0.13807
wandb:              meta_loss_step 0.00917
wandb:                    test_auc 0.71667
wandb:   test_auc/dataloader_idx_0 0.82136
wandb:   test_auc/dataloader_idx_1 0.83186
wandb:  test_auc/dataloader_idx_10 0.73838
wandb:  test_auc/dataloader_idx_11 0.71667
wandb:   test_auc/dataloader_idx_2 0.8501
wandb:   test_auc/dataloader_idx_3 0.8502
wandb:   test_auc/dataloader_idx_4 0.84097
wandb:   test_auc/dataloader_idx_5 0.8422
wandb:   test_auc/dataloader_idx_6 0.7982
wandb:   test_auc/dataloader_idx_7 0.80629
wandb:   test_auc/dataloader_idx_8 0.77978
wandb:   test_auc/dataloader_idx_9 0.753
wandb:  test_loss/dataloader_idx_0 0.27281
wandb:  test_loss/dataloader_idx_1 0.30647
wandb: test_loss/dataloader_idx_10 0.33727
wandb: test_loss/dataloader_idx_11 0.34573
wandb:  test_loss/dataloader_idx_2 0.26727
wandb:  test_loss/dataloader_idx_3 0.25918
wandb:  test_loss/dataloader_idx_4 0.26962
wandb:  test_loss/dataloader_idx_5 0.25195
wandb:  test_loss/dataloader_idx_6 0.29335
wandb:  test_loss/dataloader_idx_7 0.26943
wandb:  test_loss/dataloader_idx_8 0.31769
wandb:  test_loss/dataloader_idx_9 0.32369
wandb:                   test_year 2024
wandb:         trainer/global_step 84090
wandb:    val_auc/dataloader_idx_0 0.82757
wandb:    val_auc/dataloader_idx_1 0.83492
wandb:   val_auc/dataloader_idx_10 0.73993
wandb:   val_auc/dataloader_idx_11 0.71931
wandb:    val_auc/dataloader_idx_2 0.83285
wandb:    val_auc/dataloader_idx_3 0.8558
wandb:    val_auc/dataloader_idx_4 0.84607
wandb:    val_auc/dataloader_idx_5 0.82615
wandb:    val_auc/dataloader_idx_6 0.81638
wandb:    val_auc/dataloader_idx_7 0.78741
wandb:    val_auc/dataloader_idx_8 0.77648
wandb:    val_auc/dataloader_idx_9 0.75471
wandb:   val_loss/dataloader_idx_0 0.29199
wandb:   val_loss/dataloader_idx_1 0.29718
wandb:  val_loss/dataloader_idx_10 0.33847
wandb:  val_loss/dataloader_idx_11 0.35275
wandb:   val_loss/dataloader_idx_2 0.28056
wandb:   val_loss/dataloader_idx_3 0.26896
wandb:   val_loss/dataloader_idx_4 0.26328
wandb:   val_loss/dataloader_idx_5 0.27105
wandb:   val_loss/dataloader_idx_6 0.2714
wandb:   val_loss/dataloader_idx_7 0.29193
wandb:   val_loss/dataloader_idx_8 0.31878
wandb:   val_loss/dataloader_idx_9 0.32426
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2016-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/o8yn6lcb
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260126_085037-o8yn6lcb/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260126_225350-8wstkj1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2017-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/8wstkj1b
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11/best-checkpoint-2017.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11/best-checkpoint-2017.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82376885414123â€¦ â”‚ 0.83392643928527â€¦ â”‚ 0.8508709669113â€¦ â”‚
â”‚     test_loss     â”‚ 0.27176785469055â€¦ â”‚ 0.30916720628738â€¦ â”‚ 0.2664926946163â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.849634051322937 â”‚ 0.841204047203064 â”‚ 0.8429260849952â€¦ â”‚
â”‚     test_loss     â”‚ 0.26479580998420â€¦ â”‚ 0.28625097870826â€¦ â”‚ 0.2500652074813â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80412709712982â€¦ â”‚ 0.80906915664672â€¦ â”‚ 0.7796750068664â€¦ â”‚
â”‚     test_loss     â”‚ 0.28783318400382â€¦ â”‚ 0.26544585824012â€¦ â”‚ 0.3152415752410â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74672675132751â€¦ â”‚ 0.73777568340301â€¦ â”‚ 0.7123090028762â€¦ â”‚
â”‚     test_loss     â”‚ 0.32396656274795â€¦ â”‚ 0.33184945583343â€¦ â”‚ 0.3398306369781â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–…â–„â–‚â–
wandb:              meta_loss_step â–‚â–ƒâ–‚â–†â–â–†â–‚â–‚â–ˆâ–‚â–„â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–†â–â–‚â–†â–„â–â–†â–ƒâ–‚â–â–‚â–„â–„â–â–â–‚â–‡â–
wandb:                    test_auc â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–‡â–…â–â–„
wandb:    val_auc/dataloader_idx_1 â–…â–ˆâ–„â–â–ƒ
wandb:   val_auc/dataloader_idx_10 â–â–ƒâ–‡â–‡â–ˆ
wandb:   val_auc/dataloader_idx_11 â–ƒâ–â–‡â–ˆâ–‡
wandb:    val_auc/dataloader_idx_2 â–ˆâ–‡â–‚â–ƒâ–
wandb:    val_auc/dataloader_idx_3 â–ˆâ–„â–â–„â–„
wandb:    val_auc/dataloader_idx_4 â–‡â–ˆâ–†â–‚â–
wandb:    val_auc/dataloader_idx_5 â–â–†â–ƒâ–…â–ˆ
wandb:    val_auc/dataloader_idx_6 â–â–„â–„â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–†â–…â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_8 â–‚â–†â–ˆâ–â–‡
wandb:    val_auc/dataloader_idx_9 â–â–‚â–ˆâ–‡â–ˆ
wandb:   val_loss/dataloader_idx_0 â–â–ƒâ–ˆâ–ˆâ–‡
wandb:   val_loss/dataloader_idx_1 â–â–‚â–ˆâ–ˆâ–ˆ
wandb:  val_loss/dataloader_idx_10 â–â–‚â–„â–†â–ˆ
wandb:  val_loss/dataloader_idx_11 â–â–ƒâ–…â–‡â–ˆ
wandb:   val_loss/dataloader_idx_2 â–â–ƒâ–†â–†â–ˆ
wandb:   val_loss/dataloader_idx_3 â–â–„â–‡â–‡â–ˆ
wandb:   val_loss/dataloader_idx_4 â–â–„â–†â–‡â–ˆ
wandb:   val_loss/dataloader_idx_5 â–ˆâ–…â–…â–ƒâ–
wandb:   val_loss/dataloader_idx_6 â–ˆâ–‡â–†â–â–
wandb:   val_loss/dataloader_idx_7 â–‡â–„â–ˆâ–â–„
wandb:   val_loss/dataloader_idx_8 â–â–ƒâ–†â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_9 â–â–„â–…â–‡â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 5
wandb:             meta_loss_epoch 0.14085
wandb:              meta_loss_step 0.0501
wandb:                    test_auc 0.71231
wandb:   test_auc/dataloader_idx_0 0.82377
wandb:   test_auc/dataloader_idx_1 0.83393
wandb:  test_auc/dataloader_idx_10 0.73778
wandb:  test_auc/dataloader_idx_11 0.71231
wandb:   test_auc/dataloader_idx_2 0.85087
wandb:   test_auc/dataloader_idx_3 0.84963
wandb:   test_auc/dataloader_idx_4 0.8412
wandb:   test_auc/dataloader_idx_5 0.84293
wandb:   test_auc/dataloader_idx_6 0.80413
wandb:   test_auc/dataloader_idx_7 0.80907
wandb:   test_auc/dataloader_idx_8 0.77968
wandb:   test_auc/dataloader_idx_9 0.74673
wandb:  test_loss/dataloader_idx_0 0.27177
wandb:  test_loss/dataloader_idx_1 0.30917
wandb: test_loss/dataloader_idx_10 0.33185
wandb: test_loss/dataloader_idx_11 0.33983
wandb:  test_loss/dataloader_idx_2 0.26649
wandb:  test_loss/dataloader_idx_3 0.2648
wandb:  test_loss/dataloader_idx_4 0.28625
wandb:  test_loss/dataloader_idx_5 0.25007
wandb:  test_loss/dataloader_idx_6 0.28783
wandb:  test_loss/dataloader_idx_7 0.26545
wandb:  test_loss/dataloader_idx_8 0.31524
wandb:  test_loss/dataloader_idx_9 0.32397
wandb:                   test_year 2024
wandb:         trainer/global_step 58200
wandb:    val_auc/dataloader_idx_0 0.82498
wandb:    val_auc/dataloader_idx_1 0.83356
wandb:   val_auc/dataloader_idx_10 0.74152
wandb:   val_auc/dataloader_idx_11 0.72007
wandb:    val_auc/dataloader_idx_2 0.83399
wandb:    val_auc/dataloader_idx_3 0.85624
wandb:    val_auc/dataloader_idx_4 0.83958
wandb:    val_auc/dataloader_idx_5 0.83293
wandb:    val_auc/dataloader_idx_6 0.82343
wandb:    val_auc/dataloader_idx_7 0.79578
wandb:    val_auc/dataloader_idx_8 0.77799
wandb:    val_auc/dataloader_idx_9 0.75494
wandb:   val_loss/dataloader_idx_0 0.29741
wandb:   val_loss/dataloader_idx_1 0.30152
wandb:  val_loss/dataloader_idx_10 0.34019
wandb:  val_loss/dataloader_idx_11 0.35602
wandb:   val_loss/dataloader_idx_2 0.28149
wandb:   val_loss/dataloader_idx_3 0.27362
wandb:   val_loss/dataloader_idx_4 0.30013
wandb:   val_loss/dataloader_idx_5 0.26452
wandb:   val_loss/dataloader_idx_6 0.26511
wandb:   val_loss/dataloader_idx_7 0.2843
wandb:   val_loss/dataloader_idx_8 0.31831
wandb:   val_loss/dataloader_idx_9 0.32732
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2017-seed-11 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/8wstkj1b
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260126_225350-8wstkj1b/logs
wandb: creating run
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260127_082805-9oxltv3x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2018-seed-11
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/9oxltv3x
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-11 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
