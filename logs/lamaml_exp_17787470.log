============================================
Job ID: 17787470
Job Name: lamaml_exp
Node: a100-4024
Partition: a100_short
Start time: Wed Jan 28 00:49:48 EST 2026
Config: tmaml_seq_2013_2024
Seed: 12
Paths: gpfs
============================================
Running: python /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/scripts/run_experiment.py --config tmaml_seq_2013_2024 --paths gpfs --seed 12
============================================
[rank: 0] Global seed set to 12
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /gpfs/data/oermannlab/NYUTron/model_zoos/nyutron_small/checkpoint-736000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: lakej98 (lakej98-nyu-langone-health) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260128_005111-jc7vyzio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2013-seed-12
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/jc7vyzio
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2013.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2013.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Resume enabled but no completed checkpoints found, starting fresh
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81131243705749â€¦ â”‚ 0.82278323173522â€¦ â”‚ 0.8319269418716â€¦ â”‚
â”‚     test_loss     â”‚ 0.25805819034576â€¦ â”‚ 0.28565534949302â€¦ â”‚ 0.2620789110660â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81917870044708â€¦ â”‚ 0.81175494194030â€¦ â”‚ 0.8025562763214â€¦ â”‚
â”‚     test_loss     â”‚ 0.26739335060119â€¦ â”‚ 0.29716587066650â€¦ â”‚ 0.2780421078205â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.77076095342636â€¦ â”‚ 0.77000004053115â€¦ â”‚ 0.7600073218345â€¦ â”‚
â”‚     test_loss     â”‚ 0.31337788701057â€¦ â”‚ 0.29244482517242â€¦ â”‚ 0.3266217112541â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74041628837585â€¦ â”‚ 0.72294157743453â€¦ â”‚ 0.6967470645904â€¦ â”‚
â”‚     test_loss     â”‚ 0.31701061129570â€¦ â”‚ 0.32675179839134â€¦ â”‚ 0.3342130184173â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:             meta_loss_epoch â–†â–„â–ƒâ–‚â–â–â–ƒâ–ˆâ–ˆ
wandb:              meta_loss_step â–†â–‚â–…â–â–…â–„â–„â–†â–…â–„â–â–„â–‡â–â–†â–â–†â–‚â–â–‚â–â–ƒâ–‚â–ƒâ–â–‚â–‡â–ˆâ–ˆâ–†â–â–ˆâ–â–‡â–…â–â–â–ˆâ–â–‚
wandb:                    test_auc â–‡â–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ƒ
wandb:    val_auc/dataloader_idx_1 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ƒ
wandb:   val_auc/dataloader_idx_10 â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–
wandb:   val_auc/dataloader_idx_11 â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–
wandb:    val_auc/dataloader_idx_2 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ƒ
wandb:    val_auc/dataloader_idx_3 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ƒ
wandb:    val_auc/dataloader_idx_4 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ƒ
wandb:    val_auc/dataloader_idx_5 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ƒ
wandb:    val_auc/dataloader_idx_6 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ƒ
wandb:    val_auc/dataloader_idx_7 â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ƒ
wandb:    val_auc/dataloader_idx_8 â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ƒ
wandb:    val_auc/dataloader_idx_9 â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–â–ƒâ–
wandb:   val_loss/dataloader_idx_0 â–„â–ƒâ–‚â–â–â–â–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_1 â–ƒâ–‚â–â–â–â–â–ˆâ–ˆâ–ˆ
wandb:  val_loss/dataloader_idx_10 â–‡â–†â–‚â–â–â–‚â–ˆâ–ˆâ–ˆ
wandb:  val_loss/dataloader_idx_11 â–ˆâ–‡â–‚â–â–‚â–‚â–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_2 â–ƒâ–‚â–â–â–â–â–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_3 â–„â–ƒâ–â–â–â–â–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_4 â–ƒâ–ƒâ–â–â–â–â–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_5 â–ƒâ–ƒâ–â–â–â–â–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_6 â–ƒâ–‚â–â–â–â–â–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_7 â–ƒâ–ƒâ–â–â–‚â–‚â–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_8 â–…â–…â–‚â–â–‚â–‚â–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_9 â–‡â–‡â–‚â–â–â–‚â–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 9
wandb:             meta_loss_epoch 0.31563
wandb:              meta_loss_step 0.39101
wandb:                    test_auc 0.69675
wandb:   test_auc/dataloader_idx_0 0.81131
wandb:   test_auc/dataloader_idx_1 0.82278
wandb:  test_auc/dataloader_idx_10 0.72294
wandb:  test_auc/dataloader_idx_11 0.69675
wandb:   test_auc/dataloader_idx_2 0.83193
wandb:   test_auc/dataloader_idx_3 0.81918
wandb:   test_auc/dataloader_idx_4 0.81175
wandb:   test_auc/dataloader_idx_5 0.80256
wandb:   test_auc/dataloader_idx_6 0.77076
wandb:   test_auc/dataloader_idx_7 0.77
wandb:   test_auc/dataloader_idx_8 0.76001
wandb:   test_auc/dataloader_idx_9 0.74042
wandb:  test_loss/dataloader_idx_0 0.25806
wandb:  test_loss/dataloader_idx_1 0.28566
wandb: test_loss/dataloader_idx_10 0.32675
wandb: test_loss/dataloader_idx_11 0.33421
wandb:  test_loss/dataloader_idx_2 0.26208
wandb:  test_loss/dataloader_idx_3 0.26739
wandb:  test_loss/dataloader_idx_4 0.29717
wandb:  test_loss/dataloader_idx_5 0.27804
wandb:  test_loss/dataloader_idx_6 0.31338
wandb:  test_loss/dataloader_idx_7 0.29244
wandb:  test_loss/dataloader_idx_8 0.32662
wandb:  test_loss/dataloader_idx_9 0.31701
wandb:                   test_year 2024
wandb:         trainer/global_step 56907
wandb:    val_auc/dataloader_idx_0 0.57319
wandb:    val_auc/dataloader_idx_1 0.58506
wandb:   val_auc/dataloader_idx_10 0.58696
wandb:   val_auc/dataloader_idx_11 0.59818
wandb:    val_auc/dataloader_idx_2 0.60755
wandb:    val_auc/dataloader_idx_3 0.58557
wandb:    val_auc/dataloader_idx_4 0.56801
wandb:    val_auc/dataloader_idx_5 0.58886
wandb:    val_auc/dataloader_idx_6 0.59249
wandb:    val_auc/dataloader_idx_7 0.56969
wandb:    val_auc/dataloader_idx_8 0.63303
wandb:    val_auc/dataloader_idx_9 0.61127
wandb:   val_loss/dataloader_idx_0 0.3306
wandb:   val_loss/dataloader_idx_1 0.34793
wandb:  val_loss/dataloader_idx_10 0.35391
wandb:  val_loss/dataloader_idx_11 0.35327
wandb:   val_loss/dataloader_idx_2 0.31796
wandb:   val_loss/dataloader_idx_3 0.3384
wandb:   val_loss/dataloader_idx_4 0.35669
wandb:   val_loss/dataloader_idx_5 0.3507
wandb:   val_loss/dataloader_idx_6 0.3448
wandb:   val_loss/dataloader_idx_7 0.34478
wandb:   val_loss/dataloader_idx_8 0.37139
wandb:   val_loss/dataloader_idx_9 0.34903
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2013-seed-12 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/jc7vyzio
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260128_005111-jc7vyzio/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260128_103127-mk4eu3fp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2014-seed-12
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/mk4eu3fp
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2014.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2014.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.812022864818573 â”‚ 0.83483839035034â€¦ â”‚ 0.8446377515792â€¦ â”‚
â”‚     test_loss     â”‚ 0.26645338535308â€¦ â”‚ 0.28603902459144â€¦ â”‚ 0.2603959143161â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.836532711982727 â”‚ 0.82282984256744â€¦ â”‚ 0.8193833231925â€¦ â”‚
â”‚     test_loss     â”‚ 0.260783851146698 â”‚ 0.29756462574005â€¦ â”‚ 0.2740220129489â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78046178817749â€¦ â”‚ 0.784447431564331 â”‚ 0.76506507396698 â”‚
â”‚     test_loss     â”‚ 0.31505316495895â€¦ â”‚ 0.29018768668174â€¦ â”‚ 0.3301023840904â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74052691459655â€¦ â”‚ 0.72434622049331â€¦ â”‚ 0.7044556140899â€¦ â”‚
â”‚     test_loss     â”‚ 0.32609945535659â€¦ â”‚ 0.33439466357231â€¦ â”‚ 0.3388900160789â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–‡â–†â–…â–„â–„â–ƒâ–‚â–‚â–â–
wandb:              meta_loss_step â–‚â–ƒâ–â–ƒâ–â–â–â–‚â–‚â–‡â–ˆâ–ƒâ–â–†â–‚â–‚â–â–…â–‚â–â–‚â–â–â–‚â–‚â–‚â–„â–‚â–â–…â–‡â–‚â–‚â–†â–â–…â–â–‚â–‡â–‡
wandb:                    test_auc â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–„â–ƒâ–†â–„â–ˆâ–†â–…â–‡â–…â–„â–
wandb:    val_auc/dataloader_idx_1 â–â–ƒâ–…â–…â–†â–ˆâ–†â–ˆâ–†â–†â–†
wandb:   val_auc/dataloader_idx_10 â–†â–…â–†â–‡â–†â–‡â–‡â–ˆâ–…â–…â–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–„â–†â–„â–„â–
wandb:    val_auc/dataloader_idx_2 â–â–‚â–„â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_3 â–â–‚â–ƒâ–„â–…â–…â–†â–‡â–ˆâ–‡â–ˆ
wandb:    val_auc/dataloader_idx_4 â–â–‚â–„â–„â–†â–†â–‡â–‡â–‡â–ˆâ–‡
wandb:    val_auc/dataloader_idx_5 â–â–‚â–ƒâ–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_6 â–â–‚â–ƒâ–„â–…â–…â–†â–‡â–‡â–ˆâ–‡
wandb:    val_auc/dataloader_idx_7 â–â–â–ƒâ–ƒâ–…â–…â–†â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_8 â–â–‚â–‚â–ƒâ–„â–‡â–„â–ˆâ–†â–†â–…
wandb:    val_auc/dataloader_idx_9 â–‚â–‚â–„â–„â–…â–ˆâ–„â–ˆâ–…â–†â–
wandb:   val_loss/dataloader_idx_0 â–ƒâ–â–ˆâ–‡â–‡â–…â–†â–ˆâ–‡â–†â–ˆ
wandb:   val_loss/dataloader_idx_1 â–ˆâ–‚â–ˆâ–„â–†â–â–ƒâ–…â–†â–„â–‚
wandb:  val_loss/dataloader_idx_10 â–â–ƒâ–‡â–ƒâ–ˆâ–â–â–„â–†â–â–ˆ
wandb:  val_loss/dataloader_idx_11 â–ƒâ–ƒâ–‡â–‚â–ˆâ–„â–ƒâ–‡â–‡â–â–‡
wandb:   val_loss/dataloader_idx_2 â–ˆâ–†â–†â–„â–„â–…â–ƒâ–ƒâ–‚â–â–
wandb:   val_loss/dataloader_idx_3 â–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–„â–‚â–‚â–
wandb:   val_loss/dataloader_idx_4 â–ˆâ–†â–ˆâ–†â–†â–ƒâ–ƒâ–„â–ƒâ–â–‚
wandb:   val_loss/dataloader_idx_5 â–‡â–…â–ˆâ–…â–†â–ƒâ–ƒâ–„â–„â–â–‚
wandb:   val_loss/dataloader_idx_6 â–ˆâ–‡â–ˆâ–†â–…â–…â–ƒâ–„â–ƒâ–â–‚
wandb:   val_loss/dataloader_idx_7 â–ˆâ–ˆâ–ˆâ–†â–†â–†â–„â–„â–ƒâ–â–
wandb:   val_loss/dataloader_idx_8 â–‡â–…â–ˆâ–†â–†â–ƒâ–„â–„â–„â–â–‚
wandb:   val_loss/dataloader_idx_9 â–„â–ƒâ–ˆâ–…â–ˆâ–â–…â–…â–…â–‚â–†
wandb: 
wandb: Run summary:
wandb:                       epoch 11
wandb:             meta_loss_epoch 0.14961
wandb:              meta_loss_step 0.07029
wandb:                    test_auc 0.70446
wandb:   test_auc/dataloader_idx_0 0.81202
wandb:   test_auc/dataloader_idx_1 0.83484
wandb:  test_auc/dataloader_idx_10 0.72435
wandb:  test_auc/dataloader_idx_11 0.70446
wandb:   test_auc/dataloader_idx_2 0.84464
wandb:   test_auc/dataloader_idx_3 0.83653
wandb:   test_auc/dataloader_idx_4 0.82283
wandb:   test_auc/dataloader_idx_5 0.81938
wandb:   test_auc/dataloader_idx_6 0.78046
wandb:   test_auc/dataloader_idx_7 0.78445
wandb:   test_auc/dataloader_idx_8 0.76507
wandb:   test_auc/dataloader_idx_9 0.74053
wandb:  test_loss/dataloader_idx_0 0.26645
wandb:  test_loss/dataloader_idx_1 0.28604
wandb: test_loss/dataloader_idx_10 0.33439
wandb: test_loss/dataloader_idx_11 0.33889
wandb:  test_loss/dataloader_idx_2 0.2604
wandb:  test_loss/dataloader_idx_3 0.26078
wandb:  test_loss/dataloader_idx_4 0.29756
wandb:  test_loss/dataloader_idx_5 0.27402
wandb:  test_loss/dataloader_idx_6 0.31505
wandb:  test_loss/dataloader_idx_7 0.29019
wandb:  test_loss/dataloader_idx_8 0.3301
wandb:  test_loss/dataloader_idx_9 0.3261
wandb:                   test_year 2024
wandb:         trainer/global_step 75944
wandb:    val_auc/dataloader_idx_0 0.81767
wandb:    val_auc/dataloader_idx_1 0.82783
wandb:   val_auc/dataloader_idx_10 0.72754
wandb:   val_auc/dataloader_idx_11 0.7093
wandb:    val_auc/dataloader_idx_2 0.83842
wandb:    val_auc/dataloader_idx_3 0.84932
wandb:    val_auc/dataloader_idx_4 0.82284
wandb:    val_auc/dataloader_idx_5 0.80451
wandb:    val_auc/dataloader_idx_6 0.80037
wandb:    val_auc/dataloader_idx_7 0.77526
wandb:    val_auc/dataloader_idx_8 0.75844
wandb:    val_auc/dataloader_idx_9 0.73757
wandb:   val_loss/dataloader_idx_0 0.27591
wandb:   val_loss/dataloader_idx_1 0.27977
wandb:  val_loss/dataloader_idx_10 0.33118
wandb:  val_loss/dataloader_idx_11 0.3384
wandb:   val_loss/dataloader_idx_2 0.25183
wandb:   val_loss/dataloader_idx_3 0.25702
wandb:   val_loss/dataloader_idx_4 0.28819
wandb:   val_loss/dataloader_idx_5 0.29699
wandb:   val_loss/dataloader_idx_6 0.28849
wandb:   val_loss/dataloader_idx_7 0.30344
wandb:   val_loss/dataloader_idx_8 0.32738
wandb:   val_loss/dataloader_idx_9 0.32482
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2014-seed-12 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/mk4eu3fp
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260128_103127-mk4eu3fp/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260128_231740-npkq3vv8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2015-seed-12
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/npkq3vv8
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2015.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2015.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81499707698822â€¦ â”‚ 0.83522719144821â€¦ â”‚ 0.8449924588203â€¦ â”‚
â”‚     test_loss     â”‚ 0.26678094267845â€¦ â”‚ 0.28756937384605â€¦ â”‚ 0.2616641819477â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.84314531087875â€¦ â”‚ 0.83342343568801â€¦ â”‚ 0.8262171149253â€¦ â”‚
â”‚     test_loss     â”‚ 0.25250747799873â€¦ â”‚ 0.27851650118827â€¦ â”‚ 0.2621710300445â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78998899459838â€¦ â”‚ 0.79215013980865â€¦ â”‚ 0.7644118070602â€¦ â”‚
â”‚     test_loss     â”‚ 0.29747021198272â€¦ â”‚ 0.27651798725128â€¦ â”‚ 0.3199739754199â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.73428165912628â€¦ â”‚ 0.72189545631408â€¦ â”‚ 0.6953431367874â€¦ â”‚
â”‚     test_loss     â”‚ 0.323561429977417 â”‚ 0.32815593481063â€¦ â”‚ 0.3323410153388â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:              meta_loss_step â–…â–ƒâ–„â–„â–â–â–…â–ƒâ–â–‚â–â–â–â–‚â–„â–„â–‚â–„â–„â–â–â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–†â–ˆâ–‚â–‚â–‚â–â–‡â–â–ƒâ–‚â–â–â–ƒ
wandb:                    test_auc â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–†â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–‡â–‡â–‡â–â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:    val_auc/dataloader_idx_1 â–‡â–ˆâ–ˆâ–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   val_auc/dataloader_idx_10 â–‡â–ˆâ–‡â–â–†â–†â–…â–†â–†â–ˆ
wandb:   val_auc/dataloader_idx_11 â–‡â–ˆâ–†â–â–†â–†â–…â–†â–…â–‡
wandb:    val_auc/dataloader_idx_2 â–‡â–‡â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_3 â–†â–‡â–‡â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:    val_auc/dataloader_idx_4 â–†â–‡â–‡â–â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_5 â–†â–†â–†â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_6 â–‡â–‡â–‡â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_7 â–…â–†â–†â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_8 â–†â–†â–†â–â–†â–‡â–†â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_9 â–‡â–‡â–‡â–â–†â–†â–†â–†â–‡â–ˆ
wandb:   val_loss/dataloader_idx_0 â–â–ƒâ–…â–†â–ƒâ–„â–„â–…â–†â–ˆ
wandb:   val_loss/dataloader_idx_1 â–â–‚â–„â–„â–„â–†â–…â–†â–ˆâ–ˆ
wandb:  val_loss/dataloader_idx_10 â–„â–…â–†â–†â–ƒâ–‡â–‡â–ˆâ–†â–
wandb:  val_loss/dataloader_idx_11 â–†â–†â–‡â–ƒâ–ƒâ–ˆâ–‡â–ˆâ–†â–
wandb:   val_loss/dataloader_idx_2 â–â–ƒâ–‚â–ˆâ–ƒâ–ƒâ–â–ƒâ–†â–†
wandb:   val_loss/dataloader_idx_3 â–ƒâ–ƒâ–‚â–ˆâ–â–â–â–â–â–‚
wandb:   val_loss/dataloader_idx_4 â–„â–„â–„â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–
wandb:   val_loss/dataloader_idx_5 â–…â–…â–…â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–
wandb:   val_loss/dataloader_idx_6 â–„â–„â–„â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–
wandb:   val_loss/dataloader_idx_7 â–ˆâ–ˆâ–‡â–‡â–„â–ƒâ–‚â–ƒâ–ƒâ–
wandb:   val_loss/dataloader_idx_8 â–†â–…â–…â–ˆâ–„â–„â–„â–„â–„â–
wandb:   val_loss/dataloader_idx_9 â–†â–‡â–‡â–ˆâ–…â–ˆâ–ˆâ–ˆâ–†â–
wandb: 
wandb: Run summary:
wandb:                       epoch 10
wandb:             meta_loss_epoch 0.13941
wandb:              meta_loss_step 0.68468
wandb:                    test_auc 0.69534
wandb:   test_auc/dataloader_idx_0 0.815
wandb:   test_auc/dataloader_idx_1 0.83523
wandb:  test_auc/dataloader_idx_10 0.7219
wandb:  test_auc/dataloader_idx_11 0.69534
wandb:   test_auc/dataloader_idx_2 0.84499
wandb:   test_auc/dataloader_idx_3 0.84315
wandb:   test_auc/dataloader_idx_4 0.83342
wandb:   test_auc/dataloader_idx_5 0.82622
wandb:   test_auc/dataloader_idx_6 0.78999
wandb:   test_auc/dataloader_idx_7 0.79215
wandb:   test_auc/dataloader_idx_8 0.76441
wandb:   test_auc/dataloader_idx_9 0.73428
wandb:  test_loss/dataloader_idx_0 0.26678
wandb:  test_loss/dataloader_idx_1 0.28757
wandb: test_loss/dataloader_idx_10 0.32816
wandb: test_loss/dataloader_idx_11 0.33234
wandb:  test_loss/dataloader_idx_2 0.26166
wandb:  test_loss/dataloader_idx_3 0.25251
wandb:  test_loss/dataloader_idx_4 0.27852
wandb:  test_loss/dataloader_idx_5 0.26217
wandb:  test_loss/dataloader_idx_6 0.29747
wandb:  test_loss/dataloader_idx_7 0.27652
wandb:  test_loss/dataloader_idx_8 0.31997
wandb:  test_loss/dataloader_idx_9 0.32356
wandb:                   test_year 2024
wandb:         trainer/global_step 73100
wandb:    val_auc/dataloader_idx_0 0.82942
wandb:    val_auc/dataloader_idx_1 0.82854
wandb:   val_auc/dataloader_idx_10 0.73237
wandb:   val_auc/dataloader_idx_11 0.71379
wandb:    val_auc/dataloader_idx_2 0.84069
wandb:    val_auc/dataloader_idx_3 0.85565
wandb:    val_auc/dataloader_idx_4 0.83471
wandb:    val_auc/dataloader_idx_5 0.81915
wandb:    val_auc/dataloader_idx_6 0.81213
wandb:    val_auc/dataloader_idx_7 0.7849
wandb:    val_auc/dataloader_idx_8 0.77265
wandb:    val_auc/dataloader_idx_9 0.74622
wandb:   val_loss/dataloader_idx_0 0.27647
wandb:   val_loss/dataloader_idx_1 0.28858
wandb:  val_loss/dataloader_idx_10 0.3199
wandb:  val_loss/dataloader_idx_11 0.32663
wandb:   val_loss/dataloader_idx_2 0.25853
wandb:   val_loss/dataloader_idx_3 0.25135
wandb:   val_loss/dataloader_idx_4 0.27375
wandb:   val_loss/dataloader_idx_5 0.27948
wandb:   val_loss/dataloader_idx_6 0.27507
wandb:   val_loss/dataloader_idx_7 0.28934
wandb:   val_loss/dataloader_idx_8 0.31009
wandb:   val_loss/dataloader_idx_9 0.31076
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2015-seed-12 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/npkq3vv8
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260128_231740-npkq3vv8/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260129_111431-ql34jy5p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2016-seed-12
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/ql34jy5p
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2016.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2016.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81677085161209â€¦ â”‚ 0.83212959766387â€¦ â”‚ 0.8454591035842â€¦ â”‚
â”‚     test_loss     â”‚ 0.27198973298072â€¦ â”‚ 0.29967793822288â€¦ â”‚ 0.2704068422317â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.84489047527313â€¦ â”‚ 0.83814942836761â€¦ â”‚ 0.8373487591743â€¦ â”‚
â”‚     test_loss     â”‚ 0.26415619254112â€¦ â”‚ 0.27052775025367â€¦ â”‚ 0.2541248202323â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.79578685760498â€¦ â”‚ 0.80259025096893â€¦ â”‚ 0.7746099233627â€¦ â”‚
â”‚     test_loss     â”‚ 0.29275098443031â€¦ â”‚ 0.27115240693092â€¦ â”‚ 0.3177348375320â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74419915676116â€¦ â”‚ 0.735382080078125 â”‚ 0.7114187479019â€¦ â”‚
â”‚     test_loss     â”‚ 0.32340857386589â€¦ â”‚ 0.32880634069442â€¦ â”‚ 0.3349793255329â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:             meta_loss_epoch â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:              meta_loss_step â–‚â–â–†â–‚â–â–â–â–â–ƒâ–ƒâ–‡â–â–‚â–‚â–…â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–…â–â–„â–‚â–â–†â–‚â–ƒâ–ƒâ–…â–â–â–„â–ƒâ–ˆâ–â–…â–…â–ˆ
wandb:                    test_auc â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–…â–†â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–…â–…â–‡â–‡â–â–‚â–…â–ƒâ–ƒâ–ˆ
wandb:    val_auc/dataloader_idx_1 â–…â–…â–†â–ˆâ–â–†â–‚â–â–ƒâ–
wandb:   val_auc/dataloader_idx_10 â–ƒâ–„â–â–…â–ƒâ–ƒâ–†â–ƒâ–„â–ˆ
wandb:   val_auc/dataloader_idx_11 â–ƒâ–ƒâ–â–†â–…â–„â–†â–ƒâ–…â–ˆ
wandb:    val_auc/dataloader_idx_2 â–…â–†â–„â–ˆâ–†â–†â–…â–â–‡â–ˆ
wandb:    val_auc/dataloader_idx_3 â–‚â–ƒâ–„â–…â–„â–‡â–ˆâ–…â–…â–
wandb:    val_auc/dataloader_idx_4 â–â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–ˆ
wandb:    val_auc/dataloader_idx_5 â–â–ƒâ–ƒâ–„â–†â–†â–†â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_6 â–ƒâ–ƒâ–â–ƒâ–„â–„â–†â–†â–…â–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–ƒâ–ƒâ–„â–…â–ƒâ–…â–ƒâ–†â–ˆ
wandb:    val_auc/dataloader_idx_8 â–ƒâ–‚â–â–ƒâ–ƒâ–„â–†â–†â–‡â–ˆ
wandb:    val_auc/dataloader_idx_9 â–‚â–ƒâ–â–„â–„â–…â–‡â–‡â–‡â–ˆ
wandb:   val_loss/dataloader_idx_0 â–‚â–ƒâ–â–ƒâ–ƒâ–„â–…â–‡â–‡â–ˆ
wandb:   val_loss/dataloader_idx_1 â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–…â–†â–‡â–ˆ
wandb:  val_loss/dataloader_idx_10 â–‚â–â–â–‚â–‚â–‚â–„â–‡â–ˆâ–‡
wandb:  val_loss/dataloader_idx_11 â–‚â–â–â–ƒâ–‚â–‚â–„â–ˆâ–ˆâ–‡
wandb:   val_loss/dataloader_idx_2 â–‚â–‚â–â–ƒâ–‚â–ƒâ–…â–‡â–‡â–ˆ
wandb:   val_loss/dataloader_idx_3 â–â–‚â–â–ƒâ–‚â–ƒâ–„â–†â–‡â–ˆ
wandb:   val_loss/dataloader_idx_4 â–ˆâ–‡â–…â–…â–ƒâ–‚â–‚â–‚â–â–
wandb:   val_loss/dataloader_idx_5 â–ˆâ–ˆâ–…â–…â–ƒâ–‚â–â–‚â–‚â–‚
wandb:   val_loss/dataloader_idx_6 â–ˆâ–ˆâ–†â–†â–„â–‚â–â–„â–„â–„
wandb:   val_loss/dataloader_idx_7 â–‡â–†â–‚â–…â–‚â–â–â–ˆâ–†â–‡
wandb:   val_loss/dataloader_idx_8 â–„â–…â–ƒâ–„â–‚â–â–â–‡â–†â–ˆ
wandb:   val_loss/dataloader_idx_9 â–…â–…â–…â–…â–„â–ƒâ–â–†â–‡â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 10
wandb:             meta_loss_epoch 0.13605
wandb:              meta_loss_step 0.06354
wandb:                    test_auc 0.71142
wandb:   test_auc/dataloader_idx_0 0.81677
wandb:   test_auc/dataloader_idx_1 0.83213
wandb:  test_auc/dataloader_idx_10 0.73538
wandb:  test_auc/dataloader_idx_11 0.71142
wandb:   test_auc/dataloader_idx_2 0.84546
wandb:   test_auc/dataloader_idx_3 0.84489
wandb:   test_auc/dataloader_idx_4 0.83815
wandb:   test_auc/dataloader_idx_5 0.83735
wandb:   test_auc/dataloader_idx_6 0.79579
wandb:   test_auc/dataloader_idx_7 0.80259
wandb:   test_auc/dataloader_idx_8 0.77461
wandb:   test_auc/dataloader_idx_9 0.7442
wandb:  test_loss/dataloader_idx_0 0.27199
wandb:  test_loss/dataloader_idx_1 0.29968
wandb: test_loss/dataloader_idx_10 0.32881
wandb: test_loss/dataloader_idx_11 0.33498
wandb:  test_loss/dataloader_idx_2 0.27041
wandb:  test_loss/dataloader_idx_3 0.26416
wandb:  test_loss/dataloader_idx_4 0.27053
wandb:  test_loss/dataloader_idx_5 0.25412
wandb:  test_loss/dataloader_idx_6 0.29275
wandb:  test_loss/dataloader_idx_7 0.27115
wandb:  test_loss/dataloader_idx_8 0.31773
wandb:  test_loss/dataloader_idx_9 0.32341
wandb:                   test_year 2024
wandb:         trainer/global_step 84090
wandb:    val_auc/dataloader_idx_0 0.82857
wandb:    val_auc/dataloader_idx_1 0.82742
wandb:   val_auc/dataloader_idx_10 0.7347
wandb:   val_auc/dataloader_idx_11 0.71923
wandb:    val_auc/dataloader_idx_2 0.83968
wandb:    val_auc/dataloader_idx_3 0.85801
wandb:    val_auc/dataloader_idx_4 0.84481
wandb:    val_auc/dataloader_idx_5 0.82949
wandb:    val_auc/dataloader_idx_6 0.8181
wandb:    val_auc/dataloader_idx_7 0.79139
wandb:    val_auc/dataloader_idx_8 0.77395
wandb:    val_auc/dataloader_idx_9 0.75105
wandb:   val_loss/dataloader_idx_0 0.28904
wandb:   val_loss/dataloader_idx_1 0.30268
wandb:  val_loss/dataloader_idx_10 0.33544
wandb:  val_loss/dataloader_idx_11 0.34337
wandb:   val_loss/dataloader_idx_2 0.27006
wandb:   val_loss/dataloader_idx_3 0.26707
wandb:   val_loss/dataloader_idx_4 0.2657
wandb:   val_loss/dataloader_idx_5 0.27327
wandb:   val_loss/dataloader_idx_6 0.27357
wandb:   val_loss/dataloader_idx_7 0.29368
wandb:   val_loss/dataloader_idx_8 0.32199
wandb:   val_loss/dataloader_idx_9 0.32477
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2016-seed-12 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/ql34jy5p
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260129_111431-ql34jy5p/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260130_003313-h9e4xkmf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2017-seed-12
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/h9e4xkmf
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2017.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2017.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81473422050476â€¦ â”‚ 0.82904076576232â€¦ â”‚ 0.8444994688034â€¦ â”‚
â”‚     test_loss     â”‚ 0.26611945033073â€¦ â”‚ 0.29974547028541â€¦ â”‚ 0.2650396227836â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.84387803077697â€¦ â”‚ 0.84062469005584â€¦ â”‚ 0.8381997346878â€¦ â”‚
â”‚     test_loss     â”‚ 0.26202857494354â€¦ â”‚ 0.27635639905929â€¦ â”‚ 0.2534142732620â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.801868200302124 â”‚ 0.80622911453247â€¦ â”‚ 0.7721772789955â€¦ â”‚
â”‚     test_loss     â”‚ 0.29086083173751â€¦ â”‚ 0.26903471350669â€¦ â”‚ 0.3206119239330â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.732261061668396 â”‚ 0.73363929986953â€¦ â”‚ 0.7049661874771â€¦ â”‚
â”‚     test_loss     â”‚ 0.33091583847999â€¦ â”‚ 0.32792973518371â€¦ â”‚ 0.3341941535472â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–…â–‚â–
wandb:              meta_loss_step â–â–‚â–â–…â–…â–‚â–ˆâ–ƒâ–â–‚â–â–‚â–â–â–â–†â–‚â–…â–‚â–‚â–‚â–ˆâ–ƒâ–â–‚â–‚â–‚â–â–‚â–ƒâ–…â–â–â–‚â–„â–…â–â–‚â–„â–ƒ
wandb:                    test_auc â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–„â–‚â–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–‡â–â–ƒ
wandb:    val_auc/dataloader_idx_1 â–â–†â–ˆâ–†
wandb:   val_auc/dataloader_idx_10 â–â–„â–‡â–ˆ
wandb:   val_auc/dataloader_idx_11 â–â–ƒâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_2 â–ˆâ–ˆâ–„â–
wandb:    val_auc/dataloader_idx_3 â–…â–ˆâ–â–„
wandb:    val_auc/dataloader_idx_4 â–ˆâ–†â–‚â–
wandb:    val_auc/dataloader_idx_5 â–â–ˆâ–‡â–ˆ
wandb:    val_auc/dataloader_idx_6 â–â–ƒâ–†â–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–ƒâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_8 â–â–…â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_9 â–â–…â–‡â–ˆ
wandb:   val_loss/dataloader_idx_0 â–â–â–ˆâ–‡
wandb:   val_loss/dataloader_idx_1 â–‚â–â–†â–ˆ
wandb:  val_loss/dataloader_idx_10 â–â–‚â–„â–ˆ
wandb:  val_loss/dataloader_idx_11 â–â–ƒâ–„â–ˆ
wandb:   val_loss/dataloader_idx_2 â–â–‚â–†â–ˆ
wandb:   val_loss/dataloader_idx_3 â–â–‚â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_4 â–â–ƒâ–†â–ˆ
wandb:   val_loss/dataloader_idx_5 â–ˆâ–ƒâ–„â–
wandb:   val_loss/dataloader_idx_6 â–ˆâ–„â–ƒâ–
wandb:   val_loss/dataloader_idx_7 â–„â–â–â–ˆ
wandb:   val_loss/dataloader_idx_8 â–„â–‚â–â–ˆ
wandb:   val_loss/dataloader_idx_9 â–â–â–„â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 4
wandb:             meta_loss_epoch 0.14317
wandb:              meta_loss_step 0.03716
wandb:                    test_auc 0.70497
wandb:   test_auc/dataloader_idx_0 0.81473
wandb:   test_auc/dataloader_idx_1 0.82904
wandb:  test_auc/dataloader_idx_10 0.73364
wandb:  test_auc/dataloader_idx_11 0.70497
wandb:   test_auc/dataloader_idx_2 0.8445
wandb:   test_auc/dataloader_idx_3 0.84388
wandb:   test_auc/dataloader_idx_4 0.84062
wandb:   test_auc/dataloader_idx_5 0.8382
wandb:   test_auc/dataloader_idx_6 0.80187
wandb:   test_auc/dataloader_idx_7 0.80623
wandb:   test_auc/dataloader_idx_8 0.77218
wandb:   test_auc/dataloader_idx_9 0.73226
wandb:  test_loss/dataloader_idx_0 0.26612
wandb:  test_loss/dataloader_idx_1 0.29975
wandb: test_loss/dataloader_idx_10 0.32793
wandb: test_loss/dataloader_idx_11 0.33419
wandb:  test_loss/dataloader_idx_2 0.26504
wandb:  test_loss/dataloader_idx_3 0.26203
wandb:  test_loss/dataloader_idx_4 0.27636
wandb:  test_loss/dataloader_idx_5 0.25341
wandb:  test_loss/dataloader_idx_6 0.29086
wandb:  test_loss/dataloader_idx_7 0.26903
wandb:  test_loss/dataloader_idx_8 0.32061
wandb:  test_loss/dataloader_idx_9 0.33092
wandb:                   test_year 2024
wandb:         trainer/global_step 46560
wandb:    val_auc/dataloader_idx_0 0.82219
wandb:    val_auc/dataloader_idx_1 0.82593
wandb:   val_auc/dataloader_idx_10 0.73382
wandb:   val_auc/dataloader_idx_11 0.71645
wandb:    val_auc/dataloader_idx_2 0.83646
wandb:    val_auc/dataloader_idx_3 0.85653
wandb:    val_auc/dataloader_idx_4 0.8408
wandb:    val_auc/dataloader_idx_5 0.83116
wandb:    val_auc/dataloader_idx_6 0.82135
wandb:    val_auc/dataloader_idx_7 0.79772
wandb:    val_auc/dataloader_idx_8 0.77891
wandb:    val_auc/dataloader_idx_9 0.75281
wandb:   val_loss/dataloader_idx_0 0.28705
wandb:   val_loss/dataloader_idx_1 0.29661
wandb:  val_loss/dataloader_idx_10 0.34365
wandb:  val_loss/dataloader_idx_11 0.35259
wandb:   val_loss/dataloader_idx_2 0.26815
wandb:   val_loss/dataloader_idx_3 0.26558
wandb:   val_loss/dataloader_idx_4 0.2925
wandb:   val_loss/dataloader_idx_5 0.26819
wandb:   val_loss/dataloader_idx_6 0.26909
wandb:   val_loss/dataloader_idx_7 0.28707
wandb:   val_loss/dataloader_idx_8 0.31915
wandb:   val_loss/dataloader_idx_9 0.32635
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2017-seed-12 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/h9e4xkmf
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260130_003313-h9e4xkmf/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260130_074613-krlkq4ye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2018-seed-12
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/krlkq4ye
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2018.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12/best-checkpoint-2018.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81015682220458â€¦ â”‚ 0.82518482208251â€¦ â”‚ 0.8453115224838â€¦ â”‚
â”‚     test_loss     â”‚ 0.26888814568519â€¦ â”‚ 0.30707868933677â€¦ â”‚ 0.2651027143001â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.84123396873474â€¦ â”‚ 0.84174543619155â€¦ â”‚ 0.8418259620666â€¦ â”‚
â”‚     test_loss     â”‚ 0.26616907119750â€¦ â”‚ 0.27885407209396â€¦ â”‚ 0.2545483708381â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80422705411911â€¦ â”‚ 0.810335636138916 â”‚ 0.7760849595069â€¦ â”‚
â”‚     test_loss     â”‚ 0.29038867354393â€¦ â”‚ 0.26673126220703â€¦ â”‚ 0.3165967464447â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.73548483848571â€¦ â”‚ 0.73437196016311â€¦ â”‚ 0.7092782855033â€¦ â”‚
â”‚     test_loss     â”‚ 0.325998991727829 â”‚ 0.32591852545738â€¦ â”‚ 0.3294224739074â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–†â–‚â–
wandb:              meta_loss_step â–‚â–ˆâ–â–â–â–„â–„â–â–â–‚â–ƒâ–„â–â–…â–â–‚â–â–ƒâ–‚â–ƒâ–‚â–â–â–‚â–â–‡â–„â–‚â–â–‚â–â–â–‚â–ƒâ–â–â–‚â–ƒâ–â–
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–„â–‚â–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–‡â–ƒâ–â–ˆ
wandb:    val_auc/dataloader_idx_1 â–„â–â–â–ˆ
wandb:   val_auc/dataloader_idx_10 â–ƒâ–â–†â–ˆ
wandb:   val_auc/dataloader_idx_11 â–„â–â–†â–ˆ
wandb:    val_auc/dataloader_idx_2 â–ˆâ–â–ƒâ–‡
wandb:    val_auc/dataloader_idx_3 â–ˆâ–ƒâ–â–„
wandb:    val_auc/dataloader_idx_4 â–ˆâ–â–â–‚
wandb:    val_auc/dataloader_idx_5 â–ˆâ–ˆâ–„â–
wandb:    val_auc/dataloader_idx_6 â–â–‚â–„â–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–ƒâ–…â–ˆ
wandb:    val_auc/dataloader_idx_8 â–â–ƒâ–ƒâ–ˆ
wandb:    val_auc/dataloader_idx_9 â–‚â–â–„â–ˆ
wandb:   val_loss/dataloader_idx_0 â–‚â–‚â–ˆâ–
wandb:   val_loss/dataloader_idx_1 â–„â–‡â–ˆâ–
wandb:  val_loss/dataloader_idx_10 â–â–‚â–„â–ˆ
wandb:  val_loss/dataloader_idx_11 â–â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_2 â–â–„â–„â–ˆ
wandb:   val_loss/dataloader_idx_3 â–â–‡â–ˆâ–‡
wandb:   val_loss/dataloader_idx_4 â–â–„â–‡â–ˆ
wandb:   val_loss/dataloader_idx_5 â–â–‚â–…â–ˆ
wandb:   val_loss/dataloader_idx_6 â–ˆâ–…â–ƒâ–
wandb:   val_loss/dataloader_idx_7 â–ˆâ–„â–ƒâ–
wandb:   val_loss/dataloader_idx_8 â–†â–â–ˆâ–„
wandb:   val_loss/dataloader_idx_9 â–ƒâ–â–ˆâ–‡
wandb: 
wandb: Run summary:
wandb:                       epoch 4
wandb:             meta_loss_epoch 0.14945
wandb:              meta_loss_step 0.01965
wandb:                    test_auc 0.70928
wandb:   test_auc/dataloader_idx_0 0.81016
wandb:   test_auc/dataloader_idx_1 0.82518
wandb:  test_auc/dataloader_idx_10 0.73437
wandb:  test_auc/dataloader_idx_11 0.70928
wandb:   test_auc/dataloader_idx_2 0.84531
wandb:   test_auc/dataloader_idx_3 0.84123
wandb:   test_auc/dataloader_idx_4 0.84175
wandb:   test_auc/dataloader_idx_5 0.84183
wandb:   test_auc/dataloader_idx_6 0.80423
wandb:   test_auc/dataloader_idx_7 0.81034
wandb:   test_auc/dataloader_idx_8 0.77608
wandb:   test_auc/dataloader_idx_9 0.73548
wandb:  test_loss/dataloader_idx_0 0.26889
wandb:  test_loss/dataloader_idx_1 0.30708
wandb: test_loss/dataloader_idx_10 0.32592
wandb: test_loss/dataloader_idx_11 0.32942
wandb:  test_loss/dataloader_idx_2 0.2651
wandb:  test_loss/dataloader_idx_3 0.26617
wandb:  test_loss/dataloader_idx_4 0.27885
wandb:  test_loss/dataloader_idx_5 0.25455
wandb:  test_loss/dataloader_idx_6 0.29039
wandb:  test_loss/dataloader_idx_7 0.26673
wandb:  test_loss/dataloader_idx_8 0.3166
wandb:  test_loss/dataloader_idx_9 0.326
wandb:                   test_year 2024
wandb:         trainer/global_step 46612
wandb:    val_auc/dataloader_idx_0 0.82269
wandb:    val_auc/dataloader_idx_1 0.82668
wandb:   val_auc/dataloader_idx_10 0.73524
wandb:   val_auc/dataloader_idx_11 0.71805
wandb:    val_auc/dataloader_idx_2 0.83783
wandb:    val_auc/dataloader_idx_3 0.8526
wandb:    val_auc/dataloader_idx_4 0.83936
wandb:    val_auc/dataloader_idx_5 0.82281
wandb:    val_auc/dataloader_idx_6 0.8255
wandb:    val_auc/dataloader_idx_7 0.8037
wandb:    val_auc/dataloader_idx_8 0.78453
wandb:    val_auc/dataloader_idx_9 0.75281
wandb:   val_loss/dataloader_idx_0 0.28327
wandb:   val_loss/dataloader_idx_1 0.29278
wandb:  val_loss/dataloader_idx_10 0.33488
wandb:  val_loss/dataloader_idx_11 0.34387
wandb:   val_loss/dataloader_idx_2 0.26336
wandb:   val_loss/dataloader_idx_3 0.26646
wandb:   val_loss/dataloader_idx_4 0.29153
wandb:   val_loss/dataloader_idx_5 0.29896
wandb:   val_loss/dataloader_idx_6 0.2639
wandb:   val_loss/dataloader_idx_7 0.27701
wandb:   val_loss/dataloader_idx_8 0.31162
wandb:   val_loss/dataloader_idx_9 0.31912
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2018-seed-12 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/krlkq4ye
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260130_074613-krlkq4ye/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260130_150156-8i2rhvzq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2019-seed-12
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/8i2rhvzq
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-12 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
[2026-01-31T00:49:57.005] error: *** JOB 17787470 ON a100-4024 CANCELLED AT 2026-01-31T00:49:57 DUE TO TIME LIMIT ***
