============================================
Job ID: 17943903
Job Name: lamaml_exp
Node: a100-4012
Partition: a100_short
Start time: Sat Jan 31 17:51:58 EST 2026
Config: traditional_seq_2013_2024
Seed: 13
Paths: gpfs
============================================
Running: python /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/scripts/run_experiment.py --config traditional_seq_2013_2024 --paths gpfs --seed 13
============================================
[rank: 0] Global seed set to 13
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /gpfs/data/oermannlab/NYUTron/model_zoos/nyutron_small/checkpoint-736000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: lakej98 (lakej98-nyu-langone-health) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260131_175211-7p3j23sk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2013-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/7p3j23sk
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2013.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2013.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82980167865753â€¦ â”‚ 0.83814561367034â€¦ â”‚ 0.8432021141052â€¦ â”‚
â”‚     test_loss     â”‚ 0.35079452395439â€¦ â”‚ 0.35153216123580â€¦ â”‚ 0.3616518080234â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83538860082626â€¦ â”‚ 0.82429713010787â€¦ â”‚ 0.8218070268630â€¦ â”‚
â”‚     test_loss     â”‚ 0.34363532066345â€¦ â”‚ 0.34312048554420â€¦ â”‚ 0.3368091285228â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78519058227539â€¦ â”‚ 0.792635440826416 â”‚ 0.7780528068542â€¦ â”‚
â”‚     test_loss     â”‚ 0.36545673012733â€¦ â”‚ 0.35636141896247â€¦ â”‚ 0.3784963488578â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.75515675544738â€¦ â”‚ 0.73803466558456â€¦ â”‚ 0.7099850177764â€¦ â”‚
â”‚     test_loss     â”‚ 0.37696608901023â€¦ â”‚ 0.39686644077301â€¦ â”‚ 0.4081988632678â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                    test_auc â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–…â–…â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–…â–…â–„â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–
wandb:             train_loss_step â–‡â–†â–…â–‚â–†â–„â–‚â–‚â–ˆâ–ƒâ–†â–ˆâ–…â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–â–‚â–†â–„â–…â–‡â–‚â–ƒâ–â–ƒâ–…â–‚â–‚â–â–â–‚â–â–„â–ƒâ–â–‚
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_1 â–â–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   val_auc/dataloader_idx_10 â–â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   val_auc/dataloader_idx_11 â–â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:    val_auc/dataloader_idx_2 â–â–„â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_3 â–â–„â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_4 â–â–„â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_5 â–â–„â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:    val_auc/dataloader_idx_6 â–â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–„â–„â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_8 â–â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:    val_auc/dataloader_idx_9 â–â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:   val_loss/dataloader_idx_0 â–â–‚â–ˆâ–„â–‚â–‚â–ƒâ–‚â–‚â–†â–„â–â–‚
wandb:   val_loss/dataloader_idx_1 â–â–‚â–ˆâ–„â–‚â–‚â–ƒâ–‚â–‚â–†â–„â–‚â–‚
wandb:  val_loss/dataloader_idx_10 â–â–‚â–ˆâ–…â–…â–„â–…â–ƒâ–„â–†â–„â–‚â–ƒ
wandb:  val_loss/dataloader_idx_11 â–â–‚â–ˆâ–…â–…â–…â–…â–„â–„â–†â–…â–ƒâ–ƒ
wandb:   val_loss/dataloader_idx_2 â–â–‚â–ˆâ–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–‡â–…â–‚â–ƒ
wandb:   val_loss/dataloader_idx_3 â–‚â–‚â–ˆâ–„â–‚â–â–ƒâ–‚â–‚â–†â–„â–â–‚
wandb:   val_loss/dataloader_idx_4 â–‚â–‚â–ˆâ–„â–‚â–‚â–ƒâ–â–‚â–…â–„â–â–‚
wandb:   val_loss/dataloader_idx_5 â–â–â–ˆâ–„â–â–â–‚â–‚â–‚â–†â–„â–â–‚
wandb:   val_loss/dataloader_idx_6 â–â–â–ˆâ–„â–â–â–ƒâ–‚â–‚â–†â–…â–â–‚
wandb:   val_loss/dataloader_idx_7 â–â–‚â–ˆâ–„â–‚â–‚â–ƒâ–‚â–ƒâ–†â–„â–‚â–‚
wandb:   val_loss/dataloader_idx_8 â–â–â–ˆâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–†â–„â–‚â–ƒ
wandb:   val_loss/dataloader_idx_9 â–â–‚â–ˆâ–…â–„â–„â–„â–ƒâ–ƒâ–…â–„â–‚â–‚
wandb: 
wandb: Run summary:
wandb:                       epoch 13
wandb:                    test_auc 0.70999
wandb:   test_auc/dataloader_idx_0 0.8298
wandb:   test_auc/dataloader_idx_1 0.83815
wandb:  test_auc/dataloader_idx_10 0.73803
wandb:  test_auc/dataloader_idx_11 0.70999
wandb:   test_auc/dataloader_idx_2 0.8432
wandb:   test_auc/dataloader_idx_3 0.83539
wandb:   test_auc/dataloader_idx_4 0.8243
wandb:   test_auc/dataloader_idx_5 0.82181
wandb:   test_auc/dataloader_idx_6 0.78519
wandb:   test_auc/dataloader_idx_7 0.79264
wandb:   test_auc/dataloader_idx_8 0.77805
wandb:   test_auc/dataloader_idx_9 0.75516
wandb:  test_loss/dataloader_idx_0 0.35079
wandb:  test_loss/dataloader_idx_1 0.35153
wandb: test_loss/dataloader_idx_10 0.39687
wandb: test_loss/dataloader_idx_11 0.4082
wandb:  test_loss/dataloader_idx_2 0.36165
wandb:  test_loss/dataloader_idx_3 0.34364
wandb:  test_loss/dataloader_idx_4 0.34312
wandb:  test_loss/dataloader_idx_5 0.33681
wandb:  test_loss/dataloader_idx_6 0.36546
wandb:  test_loss/dataloader_idx_7 0.35636
wandb:  test_loss/dataloader_idx_8 0.3785
wandb:  test_loss/dataloader_idx_9 0.37697
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.38947
wandb:             train_loss_step 0.27288
wandb:         trainer/global_step 82199
wandb:    val_auc/dataloader_idx_0 0.83335
wandb:    val_auc/dataloader_idx_1 0.83923
wandb:   val_auc/dataloader_idx_10 0.73797
wandb:   val_auc/dataloader_idx_11 0.72089
wandb:    val_auc/dataloader_idx_2 0.84014
wandb:    val_auc/dataloader_idx_3 0.85393
wandb:    val_auc/dataloader_idx_4 0.82916
wandb:    val_auc/dataloader_idx_5 0.80833
wandb:    val_auc/dataloader_idx_6 0.80478
wandb:    val_auc/dataloader_idx_7 0.78365
wandb:    val_auc/dataloader_idx_8 0.77259
wandb:    val_auc/dataloader_idx_9 0.75233
wandb:   val_loss/dataloader_idx_0 0.30442
wandb:   val_loss/dataloader_idx_1 0.31203
wandb:  val_loss/dataloader_idx_10 0.3506
wandb:  val_loss/dataloader_idx_11 0.36006
wandb:   val_loss/dataloader_idx_2 0.30453
wandb:   val_loss/dataloader_idx_3 0.29366
wandb:   val_loss/dataloader_idx_4 0.31115
wandb:   val_loss/dataloader_idx_5 0.31706
wandb:   val_loss/dataloader_idx_6 0.31674
wandb:   val_loss/dataloader_idx_7 0.32903
wandb:   val_loss/dataloader_idx_8 0.34804
wandb:   val_loss/dataloader_idx_9 0.33839
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2013-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/7p3j23sk
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260131_175211-7p3j23sk/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260131_234103-f0q5ndnu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2014-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/f0q5ndnu
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2014.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2014.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82936227321624â€¦ â”‚ 0.84191918373107â€¦ â”‚ 0.8515905737876â€¦ â”‚
â”‚     test_loss     â”‚ 0.29075053334236â€¦ â”‚ 0.29524371027946â€¦ â”‚ 0.2899655699729â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.84679508209228â€¦ â”‚ 0.827858567237854 â”‚ 0.8275129795074â€¦ â”‚
â”‚     test_loss     â”‚ 0.27626755833625â€¦ â”‚ 0.29324430227279â€¦ â”‚ 0.2833817899227â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.79226708412170â€¦ â”‚ 0.80129319429397â€¦ â”‚ 0.7846915125846â€¦ â”‚
â”‚     test_loss     â”‚ 0.31154504418373â€¦ â”‚ 0.29428994655609â€¦ â”‚ 0.3280064463615â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.75877857208251â€¦ â”‚ 0.744143009185791 â”‚ 0.7120435833930â€¦ â”‚
â”‚     test_loss     â”‚ 0.32769101858139â€¦ â”‚ 0.33750528097152â€¦ â”‚ 0.3481989800930â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–…â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–‡â–†â–…â–„â–„â–ƒâ–‚â–
wandb:             train_loss_step â–‚â–â–â–‚â–„â–â–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–ƒâ–„â–†â–ˆâ–ƒâ–â–‚â–ƒâ–„â–â–ƒâ–ƒâ–â–‚â–ƒâ–‚â–„â–‚â–‚â–‚â–ƒâ–â–‚â–…â–‚â–‚
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–‡â–â–‚
wandb:    val_auc/dataloader_idx_1 â–„â–‚â–‡â–‡â–ˆâ–ˆâ–â–…â–ƒ
wandb:   val_auc/dataloader_idx_10 â–‡â–ˆâ–ˆâ–†â–„â–‡â–†â–â–‚
wandb:   val_auc/dataloader_idx_11 â–†â–‡â–ˆâ–ˆâ–ƒâ–‡â–ˆâ–‚â–
wandb:    val_auc/dataloader_idx_2 â–‚â–â–…â–†â–†â–ˆâ–‚â–…â–‚
wandb:    val_auc/dataloader_idx_3 â–…â–‡â–‡â–ˆâ–…â–†â–…â–‚â–
wandb:    val_auc/dataloader_idx_4 â–…â–†â–ˆâ–‡â–‡â–‡â–…â–…â–
wandb:    val_auc/dataloader_idx_5 â–â–‡â–ˆâ–‡â–†â–†â–ƒâ–ƒâ–‚
wandb:    val_auc/dataloader_idx_6 â–„â–†â–ˆâ–†â–†â–†â–…â–…â–
wandb:    val_auc/dataloader_idx_7 â–â–ƒâ–†â–„â–ˆâ–ˆâ–†â–‡â–ƒ
wandb:    val_auc/dataloader_idx_8 â–ƒâ–…â–‡â–‡â–â–‡â–ˆâ–‚â–‚
wandb:    val_auc/dataloader_idx_9 â–‚â–„â–†â–„â–ƒâ–ˆâ–‡â–â–ƒ
wandb:   val_loss/dataloader_idx_0 â–ˆâ–„â–„â–ƒâ–‚â–‚â–â–‚â–‚
wandb:   val_loss/dataloader_idx_1 â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–â–â–‚â–‚
wandb:  val_loss/dataloader_idx_10 â–ˆâ–ƒâ–ƒâ–„â–â–â–â–â–
wandb:  val_loss/dataloader_idx_11 â–ˆâ–ƒâ–ƒâ–„â–â–â–â–â–
wandb:   val_loss/dataloader_idx_2 â–ˆâ–ƒâ–„â–ƒâ–‚â–â–â–‚â–‚
wandb:   val_loss/dataloader_idx_3 â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–â–â–‚â–‚
wandb:   val_loss/dataloader_idx_4 â–ˆâ–ƒâ–ƒâ–ƒâ–â–â–â–â–‚
wandb:   val_loss/dataloader_idx_5 â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–â–â–â–
wandb:   val_loss/dataloader_idx_6 â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–â–â–â–‚
wandb:   val_loss/dataloader_idx_7 â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–â–â–â–
wandb:   val_loss/dataloader_idx_8 â–ˆâ–ƒâ–ƒâ–„â–‚â–â–â–â–‚
wandb:   val_loss/dataloader_idx_9 â–ˆâ–ƒâ–ƒâ–„â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                       epoch 9
wandb:                    test_auc 0.71204
wandb:   test_auc/dataloader_idx_0 0.82936
wandb:   test_auc/dataloader_idx_1 0.84192
wandb:  test_auc/dataloader_idx_10 0.74414
wandb:  test_auc/dataloader_idx_11 0.71204
wandb:   test_auc/dataloader_idx_2 0.85159
wandb:   test_auc/dataloader_idx_3 0.8468
wandb:   test_auc/dataloader_idx_4 0.82786
wandb:   test_auc/dataloader_idx_5 0.82751
wandb:   test_auc/dataloader_idx_6 0.79227
wandb:   test_auc/dataloader_idx_7 0.80129
wandb:   test_auc/dataloader_idx_8 0.78469
wandb:   test_auc/dataloader_idx_9 0.75878
wandb:  test_loss/dataloader_idx_0 0.29075
wandb:  test_loss/dataloader_idx_1 0.29524
wandb: test_loss/dataloader_idx_10 0.33751
wandb: test_loss/dataloader_idx_11 0.3482
wandb:  test_loss/dataloader_idx_2 0.28997
wandb:  test_loss/dataloader_idx_3 0.27627
wandb:  test_loss/dataloader_idx_4 0.29324
wandb:  test_loss/dataloader_idx_5 0.28338
wandb:  test_loss/dataloader_idx_6 0.31155
wandb:  test_loss/dataloader_idx_7 0.29429
wandb:  test_loss/dataloader_idx_8 0.32801
wandb:  test_loss/dataloader_idx_9 0.32769
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.39338
wandb:             train_loss_step 0.02543
wandb:         trainer/global_step 62136
wandb:    val_auc/dataloader_idx_0 0.82895
wandb:    val_auc/dataloader_idx_1 0.84129
wandb:   val_auc/dataloader_idx_10 0.73545
wandb:   val_auc/dataloader_idx_11 0.71894
wandb:    val_auc/dataloader_idx_2 0.84364
wandb:    val_auc/dataloader_idx_3 0.85034
wandb:    val_auc/dataloader_idx_4 0.82705
wandb:    val_auc/dataloader_idx_5 0.81217
wandb:    val_auc/dataloader_idx_6 0.8044
wandb:    val_auc/dataloader_idx_7 0.78645
wandb:    val_auc/dataloader_idx_8 0.77786
wandb:    val_auc/dataloader_idx_9 0.75639
wandb:   val_loss/dataloader_idx_0 0.29021
wandb:   val_loss/dataloader_idx_1 0.29372
wandb:  val_loss/dataloader_idx_10 0.33619
wandb:  val_loss/dataloader_idx_11 0.34529
wandb:   val_loss/dataloader_idx_2 0.283
wandb:   val_loss/dataloader_idx_3 0.27435
wandb:   val_loss/dataloader_idx_4 0.29396
wandb:   val_loss/dataloader_idx_5 0.29976
wandb:   val_loss/dataloader_idx_6 0.29912
wandb:   val_loss/dataloader_idx_7 0.30963
wandb:   val_loss/dataloader_idx_8 0.32834
wandb:   val_loss/dataloader_idx_9 0.32548
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2014-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/f0q5ndnu
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260131_234103-f0q5ndnu/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260201_035858-r3mpzwth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2015-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/r3mpzwth
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2015.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2015.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83160650730133â€¦ â”‚ 0.84534084796905â€¦ â”‚ 0.8635122776031â€¦ â”‚
â”‚     test_loss     â”‚ 0.27863639593124â€¦ â”‚ 0.28366249799728â€¦ â”‚ 0.2715153396129â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.85253703594207â€¦ â”‚ 0.838054895401001 â”‚ 0.8361606597900â€¦ â”‚
â”‚     test_loss     â”‚ 0.26150318980216â€¦ â”‚ 0.28403079509735â€¦ â”‚ 0.2718482315540â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80101346969604â€¦ â”‚ 0.80969232320785â€¦ â”‚ 0.7897269725799â€¦ â”‚
â”‚     test_loss     â”‚ 0.30163809657096â€¦ â”‚ 0.28071272373199â€¦ â”‚ 0.3151973187923â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.75491839647293â€¦ â”‚ 0.74560284614562â€¦ â”‚ 0.7169579267501â€¦ â”‚
â”‚     test_loss     â”‚ 0.32018178701400â€¦ â”‚ 0.33081567287445â€¦ â”‚ 0.3406404852867â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–‡â–‡â–‡â–…â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–‡â–†â–†â–…â–„â–„â–ƒâ–‚â–
wandb:             train_loss_step â–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–‚â–‚â–ƒâ–‚â–‡â–‚â–‚â–â–ƒâ–â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–…â–ƒâ–ˆâ–ƒâ–‚â–â–â–‚â–ƒâ–‚â–„
wandb:         trainer/global_step â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–…â–„â–ƒâ–
wandb:    val_auc/dataloader_idx_1 â–ˆâ–ˆâ–‡â–†â–‡â–†â–…â–„â–ƒâ–
wandb:   val_auc/dataloader_idx_10 â–‡â–ˆâ–ˆâ–ˆâ–†â–…â–†â–†â–ƒâ–
wandb:   val_auc/dataloader_idx_11 â–†â–†â–‡â–ˆâ–†â–„â–†â–†â–‚â–
wandb:    val_auc/dataloader_idx_2 â–†â–†â–†â–‡â–ˆâ–‡â–ˆâ–‡â–„â–
wandb:    val_auc/dataloader_idx_3 â–‡â–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–„â–
wandb:    val_auc/dataloader_idx_4 â–„â–†â–‡â–†â–‡â–ˆâ–‡â–†â–‚â–
wandb:    val_auc/dataloader_idx_5 â–‡â–ˆâ–ˆâ–ˆâ–‡â–…â–†â–„â–„â–
wandb:    val_auc/dataloader_idx_6 â–‡â–ˆâ–ˆâ–‡â–†â–†â–…â–„â–â–‚
wandb:    val_auc/dataloader_idx_7 â–ƒâ–‡â–‡â–†â–‡â–ˆâ–‡â–…â–‚â–
wandb:    val_auc/dataloader_idx_8 â–†â–ˆâ–ˆâ–‡â–…â–…â–ˆâ–‡â–â–„
wandb:    val_auc/dataloader_idx_9 â–‡â–ˆâ–ˆâ–‡â–†â–…â–…â–…â–‚â–
wandb:   val_loss/dataloader_idx_0 â–ˆâ–…â–‚â–†â–†â–…â–â–ƒâ–…â–…
wandb:   val_loss/dataloader_idx_1 â–ˆâ–…â–‚â–†â–…â–„â–â–ƒâ–„â–„
wandb:  val_loss/dataloader_idx_10 â–ˆâ–…â–‚â–…â–„â–ƒâ–â–â–‚â–
wandb:  val_loss/dataloader_idx_11 â–ˆâ–…â–‚â–…â–„â–ƒâ–â–â–‚â–
wandb:   val_loss/dataloader_idx_2 â–ˆâ–†â–ƒâ–†â–…â–„â–â–ƒâ–„â–ƒ
wandb:   val_loss/dataloader_idx_3 â–ˆâ–…â–‚â–†â–…â–„â–â–ƒâ–„â–„
wandb:   val_loss/dataloader_idx_4 â–ˆâ–†â–‚â–†â–…â–ƒâ–â–‚â–„â–„
wandb:   val_loss/dataloader_idx_5 â–ˆâ–…â–â–†â–…â–„â–â–ƒâ–„â–†
wandb:   val_loss/dataloader_idx_6 â–ˆâ–…â–â–†â–…â–„â–â–‚â–„â–„
wandb:   val_loss/dataloader_idx_7 â–ˆâ–…â–‚â–†â–…â–„â–â–‚â–„â–„
wandb:   val_loss/dataloader_idx_8 â–ˆâ–…â–‚â–…â–„â–ƒâ–â–‚â–ƒâ–ƒ
wandb:   val_loss/dataloader_idx_9 â–ˆâ–…â–â–…â–ƒâ–ƒâ–â–â–‚â–‚
wandb: 
wandb: Run summary:
wandb:                       epoch 10
wandb:                    test_auc 0.71696
wandb:   test_auc/dataloader_idx_0 0.83161
wandb:   test_auc/dataloader_idx_1 0.84534
wandb:  test_auc/dataloader_idx_10 0.7456
wandb:  test_auc/dataloader_idx_11 0.71696
wandb:   test_auc/dataloader_idx_2 0.86351
wandb:   test_auc/dataloader_idx_3 0.85254
wandb:   test_auc/dataloader_idx_4 0.83805
wandb:   test_auc/dataloader_idx_5 0.83616
wandb:   test_auc/dataloader_idx_6 0.80101
wandb:   test_auc/dataloader_idx_7 0.80969
wandb:   test_auc/dataloader_idx_8 0.78973
wandb:   test_auc/dataloader_idx_9 0.75492
wandb:  test_loss/dataloader_idx_0 0.27864
wandb:  test_loss/dataloader_idx_1 0.28366
wandb: test_loss/dataloader_idx_10 0.33082
wandb: test_loss/dataloader_idx_11 0.34064
wandb:  test_loss/dataloader_idx_2 0.27152
wandb:  test_loss/dataloader_idx_3 0.2615
wandb:  test_loss/dataloader_idx_4 0.28403
wandb:  test_loss/dataloader_idx_5 0.27185
wandb:  test_loss/dataloader_idx_6 0.30164
wandb:  test_loss/dataloader_idx_7 0.28071
wandb:  test_loss/dataloader_idx_8 0.3152
wandb:  test_loss/dataloader_idx_9 0.32018
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.34351
wandb:             train_loss_step 0.04389
wandb:         trainer/global_step 73100
wandb:    val_auc/dataloader_idx_0 0.81419
wandb:    val_auc/dataloader_idx_1 0.83766
wandb:   val_auc/dataloader_idx_10 0.73726
wandb:   val_auc/dataloader_idx_11 0.72169
wandb:    val_auc/dataloader_idx_2 0.84617
wandb:    val_auc/dataloader_idx_3 0.84791
wandb:    val_auc/dataloader_idx_4 0.83866
wandb:    val_auc/dataloader_idx_5 0.8082
wandb:    val_auc/dataloader_idx_6 0.80914
wandb:    val_auc/dataloader_idx_7 0.79298
wandb:    val_auc/dataloader_idx_8 0.78498
wandb:    val_auc/dataloader_idx_9 0.7506
wandb:   val_loss/dataloader_idx_0 0.29995
wandb:   val_loss/dataloader_idx_1 0.2944
wandb:  val_loss/dataloader_idx_10 0.33293
wandb:  val_loss/dataloader_idx_11 0.33856
wandb:   val_loss/dataloader_idx_2 0.27577
wandb:   val_loss/dataloader_idx_3 0.28116
wandb:   val_loss/dataloader_idx_4 0.29059
wandb:   val_loss/dataloader_idx_5 0.31127
wandb:   val_loss/dataloader_idx_6 0.30265
wandb:   val_loss/dataloader_idx_7 0.3105
wandb:   val_loss/dataloader_idx_8 0.32483
wandb:   val_loss/dataloader_idx_9 0.32077
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2015-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/r3mpzwth
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260201_035858-r3mpzwth/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260201_085217-v7dc6aif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2016-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/v7dc6aif
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2016.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2016.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83566600084304â€¦ â”‚ 0.84692001342773â€¦ â”‚ 0.8542329072952â€¦ â”‚
â”‚     test_loss     â”‚ 0.29114174842834â€¦ â”‚ 0.29192158579826â€¦ â”‚ 0.2898090481758â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.85515093803405â€¦ â”‚ 0.84383392333984â€¦ â”‚ 0.8458631634712â€¦ â”‚
â”‚     test_loss     â”‚ 0.28041860461235â€¦ â”‚ 0.30039811134338â€¦ â”‚ 0.2967556118965â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80691331624984â€¦ â”‚ 0.81438511610031â€¦ â”‚ 0.7931262254714â€¦ â”‚
â”‚     test_loss     â”‚ 0.32224845886230â€¦ â”‚ 0.30816844105720â€¦ â”‚ 0.3367717564105â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.75522470474243â€¦ â”‚ 0.74955183267593â€¦ â”‚ 0.7171859741210â€¦ â”‚
â”‚     test_loss     â”‚ 0.33976930379867â€¦ â”‚ 0.35103189945220â€¦ â”‚ 0.3588743507862â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–†â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–
wandb:             train_loss_step â–‚â–‚â–…â–ƒâ–‚â–â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–â–‚â–‚â–ˆâ–
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–†â–ˆâ–†â–…â–…â–ƒâ–â–‚
wandb:    val_auc/dataloader_idx_1 â–ˆâ–ƒâ–ˆâ–‡â–„â–â–„â–‚
wandb:   val_auc/dataloader_idx_10 â–ˆâ–†â–‡â–†â–„â–„â–‚â–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–…â–†â–„â–„â–…â–â–
wandb:    val_auc/dataloader_idx_2 â–ˆâ–…â–†â–…â–‚â–ƒâ–â–‚
wandb:    val_auc/dataloader_idx_3 â–…â–ˆâ–„â–‡â–ˆâ–â–„â–„
wandb:    val_auc/dataloader_idx_4 â–‚â–ƒâ–ˆâ–†â–ƒâ–„â–â–„
wandb:    val_auc/dataloader_idx_5 â–ƒâ–†â–ˆâ–‡â–‡â–„â–â–
wandb:    val_auc/dataloader_idx_6 â–†â–ˆâ–ˆâ–ˆâ–ˆâ–„â–ƒâ–
wandb:    val_auc/dataloader_idx_7 â–†â–†â–ˆâ–†â–ˆâ–‡â–‚â–
wandb:    val_auc/dataloader_idx_8 â–ˆâ–ˆâ–†â–‡â–‡â–‡â–ƒâ–
wandb:    val_auc/dataloader_idx_9 â–ˆâ–‡â–ˆâ–†â–†â–†â–„â–
wandb:   val_loss/dataloader_idx_0 â–‡â–ˆâ–â–ƒâ–‚â–ƒâ–…â–ˆ
wandb:   val_loss/dataloader_idx_1 â–‡â–ˆâ–â–ƒâ–‚â–ƒâ–…â–ˆ
wandb:  val_loss/dataloader_idx_10 â–†â–ˆâ–â–ƒâ–‚â–‚â–…â–†
wandb:  val_loss/dataloader_idx_11 â–†â–ˆâ–â–ƒâ–‚â–‚â–…â–†
wandb:   val_loss/dataloader_idx_2 â–‡â–ˆâ–â–ƒâ–‚â–ƒâ–…â–ˆ
wandb:   val_loss/dataloader_idx_3 â–†â–‡â–â–ƒâ–‚â–ƒâ–…â–ˆ
wandb:   val_loss/dataloader_idx_4 â–†â–‡â–â–ƒâ–‚â–„â–…â–ˆ
wandb:   val_loss/dataloader_idx_5 â–†â–†â–â–ƒâ–‚â–„â–…â–ˆ
wandb:   val_loss/dataloader_idx_6 â–…â–†â–â–‚â–‚â–ƒâ–…â–ˆ
wandb:   val_loss/dataloader_idx_7 â–…â–†â–â–‚â–â–ƒâ–…â–ˆ
wandb:   val_loss/dataloader_idx_8 â–…â–‡â–â–ƒâ–‚â–ƒâ–†â–ˆ
wandb:   val_loss/dataloader_idx_9 â–†â–ˆâ–â–ƒâ–‚â–‚â–…â–†
wandb: 
wandb: Run summary:
wandb:                       epoch 8
wandb:                    test_auc 0.71719
wandb:   test_auc/dataloader_idx_0 0.83567
wandb:   test_auc/dataloader_idx_1 0.84692
wandb:  test_auc/dataloader_idx_10 0.74955
wandb:  test_auc/dataloader_idx_11 0.71719
wandb:   test_auc/dataloader_idx_2 0.85423
wandb:   test_auc/dataloader_idx_3 0.85515
wandb:   test_auc/dataloader_idx_4 0.84383
wandb:   test_auc/dataloader_idx_5 0.84586
wandb:   test_auc/dataloader_idx_6 0.80691
wandb:   test_auc/dataloader_idx_7 0.81439
wandb:   test_auc/dataloader_idx_8 0.79313
wandb:   test_auc/dataloader_idx_9 0.75522
wandb:  test_loss/dataloader_idx_0 0.29114
wandb:  test_loss/dataloader_idx_1 0.29192
wandb: test_loss/dataloader_idx_10 0.35103
wandb: test_loss/dataloader_idx_11 0.35887
wandb:  test_loss/dataloader_idx_2 0.28981
wandb:  test_loss/dataloader_idx_3 0.28042
wandb:  test_loss/dataloader_idx_4 0.3004
wandb:  test_loss/dataloader_idx_5 0.29676
wandb:  test_loss/dataloader_idx_6 0.32225
wandb:  test_loss/dataloader_idx_7 0.30817
wandb:  test_loss/dataloader_idx_8 0.33677
wandb:  test_loss/dataloader_idx_9 0.33977
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.35077
wandb:             train_loss_step 0.06592
wandb:         trainer/global_step 67272
wandb:    val_auc/dataloader_idx_0 0.83312
wandb:    val_auc/dataloader_idx_1 0.84225
wandb:   val_auc/dataloader_idx_10 0.72958
wandb:   val_auc/dataloader_idx_11 0.72053
wandb:    val_auc/dataloader_idx_2 0.84974
wandb:    val_auc/dataloader_idx_3 0.86832
wandb:    val_auc/dataloader_idx_4 0.85364
wandb:    val_auc/dataloader_idx_5 0.82501
wandb:    val_auc/dataloader_idx_6 0.82479
wandb:    val_auc/dataloader_idx_7 0.80185
wandb:    val_auc/dataloader_idx_8 0.78618
wandb:    val_auc/dataloader_idx_9 0.75267
wandb:   val_loss/dataloader_idx_0 0.32728
wandb:   val_loss/dataloader_idx_1 0.33442
wandb:  val_loss/dataloader_idx_10 0.39822
wandb:  val_loss/dataloader_idx_11 0.40366
wandb:   val_loss/dataloader_idx_2 0.32302
wandb:   val_loss/dataloader_idx_3 0.32372
wandb:   val_loss/dataloader_idx_4 0.34836
wandb:   val_loss/dataloader_idx_5 0.36312
wandb:   val_loss/dataloader_idx_6 0.37356
wandb:   val_loss/dataloader_idx_7 0.38504
wandb:   val_loss/dataloader_idx_8 0.39492
wandb:   val_loss/dataloader_idx_9 0.3746
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2016-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/v7dc6aif
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260201_085217-v7dc6aif/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260201_130310-n62fx103
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2017-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/n62fx103
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2017.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2017.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83859419822692â€¦ â”‚ 0.85263997316360â€¦ â”‚ 0.8622539639472â€¦ â”‚
â”‚     test_loss     â”‚ 0.31472212076187â€¦ â”‚ 0.30876106023788â€¦ â”‚ 0.3128919005393â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.86012327671051â€¦ â”‚ 0.85086995363235â€¦ â”‚ 0.8534704446792â€¦ â”‚
â”‚     test_loss     â”‚ 0.30082154273986â€¦ â”‚ 0.31414595246315  â”‚ 0.3117039501667â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81279850006103â€¦ â”‚ 0.81875085830688â€¦ â”‚ 0.8005700111389â€¦ â”‚
â”‚     test_loss     â”‚ 0.33614566922187â€¦ â”‚ 0.32095700502395â€¦ â”‚ 0.3467933833599â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.76288199424743â€¦ â”‚ 0.75326400995254â€¦ â”‚ 0.7266454696655â€¦ â”‚
â”‚     test_loss     â”‚ 0.35339242219924â€¦ â”‚ 0.37411430478096â€¦ â”‚ 0.3806412518024â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆ
wandb:                    test_auc â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–…â–†â–…â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–†â–„â–ƒâ–
wandb:             train_loss_step â–â–ƒâ–‚â–„â–‚â–‚â–‚â–â–â–„â–‚â–‚â–â–‚â–ƒâ–„â–…â–„â–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–ƒâ–„â–‚â–ˆâ–â–‚â–â–‚â–â–â–‚â–‚â–‚â–‚
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–†â–â–†â–„
wandb:    val_auc/dataloader_idx_1 â–‡â–†â–ˆâ–â–†
wandb:   val_auc/dataloader_idx_10 â–…â–ˆâ–‡â–„â–
wandb:   val_auc/dataloader_idx_11 â–…â–ˆâ–‡â–„â–
wandb:    val_auc/dataloader_idx_2 â–ˆâ–†â–†â–â–‚
wandb:    val_auc/dataloader_idx_3 â–†â–…â–â–‡â–ˆ
wandb:    val_auc/dataloader_idx_4 â–â–ˆâ–‡â–„â–‚
wandb:    val_auc/dataloader_idx_5 â–†â–ˆâ–„â–â–…
wandb:    val_auc/dataloader_idx_6 â–†â–ˆâ–…â–‚â–
wandb:    val_auc/dataloader_idx_7 â–â–‡â–ˆâ–‚â–„
wandb:    val_auc/dataloader_idx_8 â–†â–ˆâ–â–â–‡
wandb:    val_auc/dataloader_idx_9 â–†â–ˆâ–ˆâ–‚â–
wandb:   val_loss/dataloader_idx_0 â–‡â–ƒâ–â–ˆâ–…
wandb:   val_loss/dataloader_idx_1 â–‡â–ƒâ–â–ˆâ–…
wandb:  val_loss/dataloader_idx_10 â–‡â–ƒâ–â–ˆâ–…
wandb:  val_loss/dataloader_idx_11 â–‡â–ƒâ–â–ˆâ–„
wandb:   val_loss/dataloader_idx_2 â–‡â–ƒâ–â–ˆâ–…
wandb:   val_loss/dataloader_idx_3 â–‡â–ƒâ–â–ˆâ–„
wandb:   val_loss/dataloader_idx_4 â–‡â–ƒâ–â–ˆâ–…
wandb:   val_loss/dataloader_idx_5 â–‡â–ƒâ–â–ˆâ–„
wandb:   val_loss/dataloader_idx_6 â–ˆâ–ƒâ–â–ˆâ–„
wandb:   val_loss/dataloader_idx_7 â–ˆâ–ƒâ–â–ˆâ–ƒ
wandb:   val_loss/dataloader_idx_8 â–‡â–ƒâ–â–ˆâ–ƒ
wandb:   val_loss/dataloader_idx_9 â–‡â–ƒâ–â–ˆâ–„
wandb: 
wandb: Run summary:
wandb:                       epoch 5
wandb:                    test_auc 0.72665
wandb:   test_auc/dataloader_idx_0 0.83859
wandb:   test_auc/dataloader_idx_1 0.85264
wandb:  test_auc/dataloader_idx_10 0.75326
wandb:  test_auc/dataloader_idx_11 0.72665
wandb:   test_auc/dataloader_idx_2 0.86225
wandb:   test_auc/dataloader_idx_3 0.86012
wandb:   test_auc/dataloader_idx_4 0.85087
wandb:   test_auc/dataloader_idx_5 0.85347
wandb:   test_auc/dataloader_idx_6 0.8128
wandb:   test_auc/dataloader_idx_7 0.81875
wandb:   test_auc/dataloader_idx_8 0.80057
wandb:   test_auc/dataloader_idx_9 0.76288
wandb:  test_loss/dataloader_idx_0 0.31472
wandb:  test_loss/dataloader_idx_1 0.30876
wandb: test_loss/dataloader_idx_10 0.37411
wandb: test_loss/dataloader_idx_11 0.38064
wandb:  test_loss/dataloader_idx_2 0.31289
wandb:  test_loss/dataloader_idx_3 0.30082
wandb:  test_loss/dataloader_idx_4 0.31415
wandb:  test_loss/dataloader_idx_5 0.3117
wandb:  test_loss/dataloader_idx_6 0.33615
wandb:  test_loss/dataloader_idx_7 0.32096
wandb:  test_loss/dataloader_idx_8 0.34679
wandb:  test_loss/dataloader_idx_9 0.35339
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.38969
wandb:             train_loss_step 0.85736
wandb:         trainer/global_step 58200
wandb:    val_auc/dataloader_idx_0 0.83647
wandb:    val_auc/dataloader_idx_1 0.85142
wandb:   val_auc/dataloader_idx_10 0.73535
wandb:   val_auc/dataloader_idx_11 0.72251
wandb:    val_auc/dataloader_idx_2 0.85328
wandb:    val_auc/dataloader_idx_3 0.8742
wandb:    val_auc/dataloader_idx_4 0.85951
wandb:    val_auc/dataloader_idx_5 0.83385
wandb:    val_auc/dataloader_idx_6 0.82957
wandb:    val_auc/dataloader_idx_7 0.80911
wandb:    val_auc/dataloader_idx_8 0.79919
wandb:    val_auc/dataloader_idx_9 0.75891
wandb:   val_loss/dataloader_idx_0 0.32029
wandb:   val_loss/dataloader_idx_1 0.31335
wandb:  val_loss/dataloader_idx_10 0.38453
wandb:  val_loss/dataloader_idx_11 0.38684
wandb:   val_loss/dataloader_idx_2 0.30499
wandb:   val_loss/dataloader_idx_3 0.30219
wandb:   val_loss/dataloader_idx_4 0.32082
wandb:   val_loss/dataloader_idx_5 0.32742
wandb:   val_loss/dataloader_idx_6 0.32229
wandb:   val_loss/dataloader_idx_7 0.32823
wandb:   val_loss/dataloader_idx_8 0.34987
wandb:   val_loss/dataloader_idx_9 0.35609
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2017-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/n62fx103
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260201_130310-n62fx103/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260201_161635-j6xx5yui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2018-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/j6xx5yui
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2018.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2018.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83626806735992â€¦ â”‚ 0.85074317455291â€¦ â”‚ 0.8606790900230â€¦ â”‚
â”‚     test_loss     â”‚ 0.29088264703750â€¦ â”‚ 0.29283154010772â€¦ â”‚ 0.2879928946495â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.86237984895706â€¦ â”‚ 0.84832888841629â€¦ â”‚ 0.8549522161483â€¦ â”‚
â”‚     test_loss     â”‚ 0.27933529019355â€¦ â”‚ 0.29604977369308â€¦ â”‚ 0.2926387190818â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81586128473281â€¦ â”‚ 0.82146042585372â€¦ â”‚ 0.8033313155174â€¦ â”‚
â”‚     test_loss     â”‚ 0.31604927778244â€¦ â”‚ 0.29847329854965â€¦ â”‚ 0.3253234326839â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.76484405994415â€¦ â”‚ 0.75764304399490â€¦ â”‚ 0.7275059819221â€¦ â”‚
â”‚     test_loss     â”‚ 0.33381959795951â€¦ â”‚ 0.34638449549674â€¦ â”‚ 0.3523010611534â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–†â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–†â–…â–ƒâ–‚â–
wandb:             train_loss_step â–â–â–â–â–â–„â–â–â–ƒâ–„â–â–„â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–ƒâ–â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–â–‡â–„â–ˆâ–ƒâ–â–‚â–
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–…â–†â–‚â–â–
wandb:    val_auc/dataloader_idx_1 â–ˆâ–ˆâ–ƒâ–‚â–â–…
wandb:   val_auc/dataloader_idx_10 â–ˆâ–†â–‡â–„â–ƒâ–
wandb:   val_auc/dataloader_idx_11 â–ˆâ–‡â–‡â–ƒâ–â–
wandb:    val_auc/dataloader_idx_2 â–†â–ˆâ–ˆâ–…â–â–†
wandb:    val_auc/dataloader_idx_3 â–ˆâ–â–„â–‚â–‚â–…
wandb:    val_auc/dataloader_idx_4 â–†â–‡â–ˆâ–‡â–†â–
wandb:    val_auc/dataloader_idx_5 â–ƒâ–â–ˆâ–ƒâ–‚â–
wandb:    val_auc/dataloader_idx_6 â–†â–ˆâ–„â–…â–ƒâ–
wandb:    val_auc/dataloader_idx_7 â–â–‡â–‡â–‡â–ˆâ–
wandb:    val_auc/dataloader_idx_8 â–‡â–ˆâ–†â–‡â–…â–
wandb:    val_auc/dataloader_idx_9 â–ˆâ–‡â–‡â–†â–‚â–
wandb:   val_loss/dataloader_idx_0 â–ƒâ–ƒâ–‚â–â–…â–ˆ
wandb:   val_loss/dataloader_idx_1 â–ƒâ–ƒâ–‚â–â–…â–ˆ
wandb:  val_loss/dataloader_idx_10 â–…â–„â–ƒâ–â–†â–ˆ
wandb:  val_loss/dataloader_idx_11 â–…â–„â–ƒâ–â–†â–ˆ
wandb:   val_loss/dataloader_idx_2 â–„â–ƒâ–ƒâ–â–†â–ˆ
wandb:   val_loss/dataloader_idx_3 â–„â–„â–ƒâ–â–…â–ˆ
wandb:   val_loss/dataloader_idx_4 â–„â–„â–‚â–â–…â–ˆ
wandb:   val_loss/dataloader_idx_5 â–ƒâ–ƒâ–‚â–â–…â–ˆ
wandb:   val_loss/dataloader_idx_6 â–„â–„â–‚â–â–…â–ˆ
wandb:   val_loss/dataloader_idx_7 â–„â–„â–‚â–â–…â–ˆ
wandb:   val_loss/dataloader_idx_8 â–„â–„â–ƒâ–â–…â–ˆ
wandb:   val_loss/dataloader_idx_9 â–…â–„â–ƒâ–â–…â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 6
wandb:                    test_auc 0.72751
wandb:   test_auc/dataloader_idx_0 0.83627
wandb:   test_auc/dataloader_idx_1 0.85074
wandb:  test_auc/dataloader_idx_10 0.75764
wandb:  test_auc/dataloader_idx_11 0.72751
wandb:   test_auc/dataloader_idx_2 0.86068
wandb:   test_auc/dataloader_idx_3 0.86238
wandb:   test_auc/dataloader_idx_4 0.84833
wandb:   test_auc/dataloader_idx_5 0.85495
wandb:   test_auc/dataloader_idx_6 0.81586
wandb:   test_auc/dataloader_idx_7 0.82146
wandb:   test_auc/dataloader_idx_8 0.80333
wandb:   test_auc/dataloader_idx_9 0.76484
wandb:  test_loss/dataloader_idx_0 0.29088
wandb:  test_loss/dataloader_idx_1 0.29283
wandb: test_loss/dataloader_idx_10 0.34638
wandb: test_loss/dataloader_idx_11 0.3523
wandb:  test_loss/dataloader_idx_2 0.28799
wandb:  test_loss/dataloader_idx_3 0.27934
wandb:  test_loss/dataloader_idx_4 0.29605
wandb:  test_loss/dataloader_idx_5 0.29264
wandb:  test_loss/dataloader_idx_6 0.31605
wandb:  test_loss/dataloader_idx_7 0.29847
wandb:  test_loss/dataloader_idx_8 0.32532
wandb:  test_loss/dataloader_idx_9 0.33382
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.39595
wandb:             train_loss_step 0.10514
wandb:         trainer/global_step 69918
wandb:    val_auc/dataloader_idx_0 0.83209
wandb:    val_auc/dataloader_idx_1 0.85093
wandb:   val_auc/dataloader_idx_10 0.74497
wandb:   val_auc/dataloader_idx_11 0.73069
wandb:    val_auc/dataloader_idx_2 0.85579
wandb:    val_auc/dataloader_idx_3 0.87036
wandb:    val_auc/dataloader_idx_4 0.85764
wandb:    val_auc/dataloader_idx_5 0.83537
wandb:    val_auc/dataloader_idx_6 0.83071
wandb:    val_auc/dataloader_idx_7 0.8115
wandb:    val_auc/dataloader_idx_8 0.79701
wandb:    val_auc/dataloader_idx_9 0.76275
wandb:   val_loss/dataloader_idx_0 0.32191
wandb:   val_loss/dataloader_idx_1 0.32459
wandb:  val_loss/dataloader_idx_10 0.37596
wandb:  val_loss/dataloader_idx_11 0.37746
wandb:   val_loss/dataloader_idx_2 0.31167
wandb:   val_loss/dataloader_idx_3 0.31304
wandb:   val_loss/dataloader_idx_4 0.3317
wandb:   val_loss/dataloader_idx_5 0.34293
wandb:   val_loss/dataloader_idx_6 0.34033
wandb:   val_loss/dataloader_idx_7 0.34375
wandb:   val_loss/dataloader_idx_8 0.35778
wandb:   val_loss/dataloader_idx_9 0.35414
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2018-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/j6xx5yui
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260201_161635-j6xx5yui/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260201_201732-tsl8z8je
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2019-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/tsl8z8je
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2019.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2019.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83349096775054â€¦ â”‚ 0.84877204895019â€¦ â”‚ 0.8637804388999â€¦ â”‚
â”‚     test_loss     â”‚ 0.25514653325080â€¦ â”‚ 0.26799765229225â€¦ â”‚ 0.2525510787963â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.860759437084198 â”‚ 0.85008144378662â€¦ â”‚ 0.8560020923614â€¦ â”‚
â”‚     test_loss     â”‚ 0.24964597821235â€¦ â”‚ 0.27018669247627â€¦ â”‚ 0.2595217525959â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81887900829315â€¦ â”‚ 0.82440739870071â€¦ â”‚ 0.8030206561088â€¦ â”‚
â”‚     test_loss     â”‚ 0.28771173954010â€¦ â”‚ 0.26952618360519â€¦ â”‚ 0.3009891808032â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.76567935943603â€¦ â”‚ 0.75963324308395â€¦ â”‚ 0.7311211824417â€¦ â”‚
â”‚     test_loss     â”‚ 0.30835506319999â€¦ â”‚ 0.31744912266731â€¦ â”‚ 0.3233451843261â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–†â–…â–ƒâ–ƒâ–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–‡â–…â–„â–‚â–
wandb:             train_loss_step â–„â–‚â–‚â–ƒâ–†â–‚â–‚â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–„â–â–‚â–‚â–â–„â–ƒâ–‚â–ƒâ–â–…â–‚â–ƒâ–ƒâ–ƒâ–„â–‚â–â–â–‚â–„â–‡â–‚
wandb:         trainer/global_step â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–ˆâ–†â–‡â–‚â–
wandb:    val_auc/dataloader_idx_1 â–ˆâ–‡â–„â–„â–â–ƒ
wandb:   val_auc/dataloader_idx_10 â–…â–…â–ˆâ–â–…â–
wandb:   val_auc/dataloader_idx_11 â–†â–„â–ˆâ–â–†â–ƒ
wandb:    val_auc/dataloader_idx_2 â–†â–ˆâ–„â–…â–…â–
wandb:    val_auc/dataloader_idx_3 â–ˆâ–…â–‡â–„â–â–
wandb:    val_auc/dataloader_idx_4 â–ˆâ–‡â–‡â–„â–ƒâ–
wandb:    val_auc/dataloader_idx_5 â–ˆâ–†â–ˆâ–ˆâ–ƒâ–
wandb:    val_auc/dataloader_idx_6 â–‡â–ˆâ–ˆâ–†â–…â–
wandb:    val_auc/dataloader_idx_7 â–â–…â–‚â–…â–ˆâ–‡
wandb:    val_auc/dataloader_idx_8 â–…â–‚â–ˆâ–ƒâ–„â–
wandb:    val_auc/dataloader_idx_9 â–‡â–„â–ˆâ–‚â–„â–
wandb:   val_loss/dataloader_idx_0 â–…â–ˆâ–â–‡â–†â–‡
wandb:   val_loss/dataloader_idx_1 â–…â–ˆâ–â–‡â–†â–‡
wandb:  val_loss/dataloader_idx_10 â–†â–ˆâ–â–ˆâ–…â–‡
wandb:  val_loss/dataloader_idx_11 â–…â–ˆâ–â–ˆâ–…â–‡
wandb:   val_loss/dataloader_idx_2 â–†â–ˆâ–â–‡â–…â–‡
wandb:   val_loss/dataloader_idx_3 â–†â–ˆâ–â–‡â–†â–ˆ
wandb:   val_loss/dataloader_idx_4 â–†â–ˆâ–â–‡â–†â–ˆ
wandb:   val_loss/dataloader_idx_5 â–…â–ˆâ–â–‡â–†â–ˆ
wandb:   val_loss/dataloader_idx_6 â–†â–ˆâ–â–‡â–†â–ˆ
wandb:   val_loss/dataloader_idx_7 â–†â–ˆâ–â–‡â–†â–ˆ
wandb:   val_loss/dataloader_idx_8 â–†â–ˆâ–â–ˆâ–†â–ˆ
wandb:   val_loss/dataloader_idx_9 â–…â–ˆâ–â–‡â–…â–‡
wandb: 
wandb: Run summary:
wandb:                       epoch 6
wandb:                    test_auc 0.73112
wandb:   test_auc/dataloader_idx_0 0.83349
wandb:   test_auc/dataloader_idx_1 0.84877
wandb:  test_auc/dataloader_idx_10 0.75963
wandb:  test_auc/dataloader_idx_11 0.73112
wandb:   test_auc/dataloader_idx_2 0.86378
wandb:   test_auc/dataloader_idx_3 0.86076
wandb:   test_auc/dataloader_idx_4 0.85008
wandb:   test_auc/dataloader_idx_5 0.856
wandb:   test_auc/dataloader_idx_6 0.81888
wandb:   test_auc/dataloader_idx_7 0.82441
wandb:   test_auc/dataloader_idx_8 0.80302
wandb:   test_auc/dataloader_idx_9 0.76568
wandb:  test_loss/dataloader_idx_0 0.25515
wandb:  test_loss/dataloader_idx_1 0.268
wandb: test_loss/dataloader_idx_10 0.31745
wandb: test_loss/dataloader_idx_11 0.32335
wandb:  test_loss/dataloader_idx_2 0.25255
wandb:  test_loss/dataloader_idx_3 0.24965
wandb:  test_loss/dataloader_idx_4 0.27019
wandb:  test_loss/dataloader_idx_5 0.25952
wandb:  test_loss/dataloader_idx_6 0.28771
wandb:  test_loss/dataloader_idx_7 0.26953
wandb:  test_loss/dataloader_idx_8 0.30099
wandb:  test_loss/dataloader_idx_9 0.30836
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.41052
wandb:             train_loss_step 0.27493
wandb:         trainer/global_step 81900
wandb:    val_auc/dataloader_idx_0 0.83079
wandb:    val_auc/dataloader_idx_1 0.84984
wandb:   val_auc/dataloader_idx_10 0.74495
wandb:   val_auc/dataloader_idx_11 0.739
wandb:    val_auc/dataloader_idx_2 0.85438
wandb:    val_auc/dataloader_idx_3 0.86464
wandb:    val_auc/dataloader_idx_4 0.8535
wandb:    val_auc/dataloader_idx_5 0.83117
wandb:    val_auc/dataloader_idx_6 0.8385
wandb:    val_auc/dataloader_idx_7 0.81862
wandb:    val_auc/dataloader_idx_8 0.79895
wandb:    val_auc/dataloader_idx_9 0.76139
wandb:   val_loss/dataloader_idx_0 0.30359
wandb:   val_loss/dataloader_idx_1 0.30643
wandb:  val_loss/dataloader_idx_10 0.37695
wandb:  val_loss/dataloader_idx_11 0.37716
wandb:   val_loss/dataloader_idx_2 0.29732
wandb:   val_loss/dataloader_idx_3 0.30782
wandb:   val_loss/dataloader_idx_4 0.32956
wandb:   val_loss/dataloader_idx_5 0.34172
wandb:   val_loss/dataloader_idx_6 0.33786
wandb:   val_loss/dataloader_idx_7 0.34803
wandb:   val_loss/dataloader_idx_8 0.3546
wandb:   val_loss/dataloader_idx_9 0.35296
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2019-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/tsl8z8je
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260201_201732-tsl8z8je/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260202_003453-3saak2fs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2020-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/3saak2fs
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2020.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2020.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83354049921035â€¦ â”‚ 0.847771167755127 â”‚ 0.8605297803878â€¦ â”‚
â”‚     test_loss     â”‚ 0.295869380235672 â”‚ 0.30184528231620â€¦ â”‚ 0.2996214330196â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.86333489418029â€¦ â”‚ 0.84882056713104â€¦ â”‚ 0.8564620018005â€¦ â”‚
â”‚     test_loss     â”‚ 0.29235315322875â€¦ â”‚ 0.31279098987579â€¦ â”‚ 0.3127606511116â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82141506671905â€¦ â”‚ 0.82679128646850â€¦ â”‚ 0.8096067905426â€¦ â”‚
â”‚     test_loss     â”‚ 0.33892315626144â€¦ â”‚ 0.33006411790847â€¦ â”‚ 0.3505382239818â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.76893794536590â€¦ â”‚ 0.76346546411514â€¦ â”‚ 0.7376929521560â€¦ â”‚
â”‚     test_loss     â”‚ 0.363567054271698 â”‚ 0.38287758827209â€¦ â”‚ 0.3924543261528â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–†â–…â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–†â–„â–‚â–
wandb:             train_loss_step â–ƒâ–‚â–„â–†â–ˆâ–„â–‚â–‚â–‚â–‚â–â–â–‚â–â–ƒâ–‚â–ƒâ–‚â–„â–‚â–‚â–â–ƒâ–‚â–„â–â–„â–‚â–‚â–‚â–†â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–†
wandb:         trainer/global_step â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–‡â–ˆâ–†â–â–ƒ
wandb:    val_auc/dataloader_idx_1 â–„â–ˆâ–…â–â–„
wandb:   val_auc/dataloader_idx_10 â–ˆâ–†â–‡â–†â–
wandb:   val_auc/dataloader_idx_11 â–†â–…â–ˆâ–„â–
wandb:    val_auc/dataloader_idx_2 â–ˆâ–‡â–‡â–â–‡
wandb:    val_auc/dataloader_idx_3 â–‡â–‡â–ˆâ–â–ƒ
wandb:    val_auc/dataloader_idx_4 â–‚â–ˆâ–…â–â–
wandb:    val_auc/dataloader_idx_5 â–…â–ˆâ–‡â–â–ƒ
wandb:    val_auc/dataloader_idx_6 â–ƒâ–ˆâ–„â–‚â–
wandb:    val_auc/dataloader_idx_7 â–â–ˆâ–„â–„â–‡
wandb:    val_auc/dataloader_idx_8 â–†â–†â–‡â–ˆâ–
wandb:    val_auc/dataloader_idx_9 â–†â–‡â–†â–ˆâ–
wandb:   val_loss/dataloader_idx_0 â–ˆâ–†â–ƒâ–â–…
wandb:   val_loss/dataloader_idx_1 â–ˆâ–…â–ƒâ–â–…
wandb:  val_loss/dataloader_idx_10 â–ˆâ–†â–ƒâ–â–„
wandb:  val_loss/dataloader_idx_11 â–ˆâ–†â–ƒâ–â–„
wandb:   val_loss/dataloader_idx_2 â–ˆâ–†â–ƒâ–â–…
wandb:   val_loss/dataloader_idx_3 â–ˆâ–…â–‚â–â–„
wandb:   val_loss/dataloader_idx_4 â–ˆâ–„â–ƒâ–â–„
wandb:   val_loss/dataloader_idx_5 â–ˆâ–„â–ƒâ–â–„
wandb:   val_loss/dataloader_idx_6 â–ˆâ–…â–ƒâ–â–„
wandb:   val_loss/dataloader_idx_7 â–ˆâ–‡â–„â–â–…
wandb:   val_loss/dataloader_idx_8 â–ˆâ–‡â–ƒâ–â–†
wandb:   val_loss/dataloader_idx_9 â–ˆâ–†â–‚â–â–†
wandb: 
wandb: Run summary:
wandb:                       epoch 5
wandb:                    test_auc 0.73769
wandb:   test_auc/dataloader_idx_0 0.83354
wandb:   test_auc/dataloader_idx_1 0.84777
wandb:  test_auc/dataloader_idx_10 0.76347
wandb:  test_auc/dataloader_idx_11 0.73769
wandb:   test_auc/dataloader_idx_2 0.86053
wandb:   test_auc/dataloader_idx_3 0.86333
wandb:   test_auc/dataloader_idx_4 0.84882
wandb:   test_auc/dataloader_idx_5 0.85646
wandb:   test_auc/dataloader_idx_6 0.82142
wandb:   test_auc/dataloader_idx_7 0.82679
wandb:   test_auc/dataloader_idx_8 0.80961
wandb:   test_auc/dataloader_idx_9 0.76894
wandb:  test_loss/dataloader_idx_0 0.29587
wandb:  test_loss/dataloader_idx_1 0.30185
wandb: test_loss/dataloader_idx_10 0.38288
wandb: test_loss/dataloader_idx_11 0.39245
wandb:  test_loss/dataloader_idx_2 0.29962
wandb:  test_loss/dataloader_idx_3 0.29235
wandb:  test_loss/dataloader_idx_4 0.31279
wandb:  test_loss/dataloader_idx_5 0.31276
wandb:  test_loss/dataloader_idx_6 0.33892
wandb:  test_loss/dataloader_idx_7 0.33006
wandb:  test_loss/dataloader_idx_8 0.35054
wandb:  test_loss/dataloader_idx_9 0.36357
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.4272
wandb:             train_loss_step 0.31379
wandb:         trainer/global_step 85555
wandb:    val_auc/dataloader_idx_0 0.83246
wandb:    val_auc/dataloader_idx_1 0.85164
wandb:   val_auc/dataloader_idx_10 0.74983
wandb:   val_auc/dataloader_idx_11 0.74698
wandb:    val_auc/dataloader_idx_2 0.85467
wandb:    val_auc/dataloader_idx_3 0.86515
wandb:    val_auc/dataloader_idx_4 0.85893
wandb:    val_auc/dataloader_idx_5 0.83438
wandb:    val_auc/dataloader_idx_6 0.84101
wandb:    val_auc/dataloader_idx_7 0.82234
wandb:    val_auc/dataloader_idx_8 0.80403
wandb:    val_auc/dataloader_idx_9 0.77254
wandb:   val_loss/dataloader_idx_0 0.28989
wandb:   val_loss/dataloader_idx_1 0.29437
wandb:  val_loss/dataloader_idx_10 0.37365
wandb:  val_loss/dataloader_idx_11 0.37595
wandb:   val_loss/dataloader_idx_2 0.28608
wandb:   val_loss/dataloader_idx_3 0.29188
wandb:   val_loss/dataloader_idx_4 0.3054
wandb:   val_loss/dataloader_idx_5 0.3182
wandb:   val_loss/dataloader_idx_6 0.3158
wandb:   val_loss/dataloader_idx_7 0.3302
wandb:   val_loss/dataloader_idx_8 0.34904
wandb:   val_loss/dataloader_idx_9 0.35404
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2020-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/3saak2fs
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260202_003453-3saak2fs/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260202_044005-itl0wvjd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2021-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/itl0wvjd
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2021.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13/best-checkpoint-2021.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83460497856140â€¦ â”‚ 0.84561121463775â€¦ â”‚ 0.8626798987388â€¦ â”‚
â”‚     test_loss     â”‚ 0.27441293001174â€¦ â”‚ 0.28589254617691â€¦ â”‚ 0.2757179737091â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.86019223928451â€¦ â”‚ 0.84760046005249â€¦ â”‚ 0.8534178137779â€¦ â”‚
â”‚     test_loss     â”‚ 0.27233499288558â€¦ â”‚ 0.29397457838058â€¦ â”‚ 0.2868590056896â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81985282897949â€¦ â”‚ 0.82487934827804â€¦ â”‚ 0.8178370594978â€¦ â”‚
â”‚     test_loss     â”‚ 0.31449958682060â€¦ â”‚ 0.29857289791107â€¦ â”‚ 0.3209213316440â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.77468341588974  â”‚ 0.76289176940917â€¦ â”‚ 0.7399464845657â€¦ â”‚
â”‚     test_loss     â”‚ 0.34846320748329â€¦ â”‚ 0.37343233823776â€¦ â”‚ 0.3799387216567â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            train_loss_epoch â–ˆâ–†â–†â–…â–ƒâ–‚â–
wandb:             train_loss_step â–„â–‚â–ˆâ–‚â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–„â–‚â–†â–‚â–‚â–„â–â–‚â–„â–…â–‚â–‚â–‚â–‚â–„â–‚â–‚â–â–â–‚â–ƒâ–‚â–…â–â–ƒâ–ƒâ–„â–â–â–‚
wandb:         trainer/global_step â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_0 â–†â–‡â–†â–†â–ˆâ–‚â–
wandb:    val_auc/dataloader_idx_1 â–ˆâ–‡â–†â–†â–†â–„â–
wandb:   val_auc/dataloader_idx_10 â–†â–‡â–‡â–ˆâ–‡â–â–„
wandb:   val_auc/dataloader_idx_11 â–†â–‡â–ˆâ–ˆâ–†â–â–„
wandb:    val_auc/dataloader_idx_2 â–†â–†â–†â–…â–‡â–ˆâ–
wandb:    val_auc/dataloader_idx_3 â–ˆâ–‡â–†â–…â–†â–ƒâ–
wandb:    val_auc/dataloader_idx_4 â–‡â–ˆâ–‡â–†â–‡â–„â–
wandb:    val_auc/dataloader_idx_5 â–ˆâ–ˆâ–‡â–†â–‡â–„â–
wandb:    val_auc/dataloader_idx_6 â–ˆâ–ˆâ–‡â–†â–†â–ƒâ–
wandb:    val_auc/dataloader_idx_7 â–†â–ˆâ–†â–‡â–†â–‚â–
wandb:    val_auc/dataloader_idx_8 â–ƒâ–†â–‡â–ˆâ–†â–â–
wandb:    val_auc/dataloader_idx_9 â–…â–‡â–ˆâ–ˆâ–…â–â–„
wandb:   val_loss/dataloader_idx_0 â–ˆâ–‚â–ƒâ–â–…â–‡â–‚
wandb:   val_loss/dataloader_idx_1 â–ˆâ–‚â–ƒâ–â–†â–‡â–‚
wandb:  val_loss/dataloader_idx_10 â–‡â–ƒâ–„â–â–…â–ˆâ–‚
wandb:  val_loss/dataloader_idx_11 â–ˆâ–‚â–„â–â–…â–ˆâ–‚
wandb:   val_loss/dataloader_idx_2 â–ˆâ–‚â–ƒâ–â–†â–‡â–‚
wandb:   val_loss/dataloader_idx_3 â–ˆâ–‚â–ƒâ–â–†â–‡â–‚
wandb:   val_loss/dataloader_idx_4 â–ˆâ–‚â–ƒâ–â–†â–‡â–‚
wandb:   val_loss/dataloader_idx_5 â–ˆâ–‚â–ƒâ–â–†â–ˆâ–‚
wandb:   val_loss/dataloader_idx_6 â–ˆâ–‚â–ƒâ–â–†â–ˆâ–‚
wandb:   val_loss/dataloader_idx_7 â–ˆâ–‚â–ƒâ–â–†â–ˆâ–‚
wandb:   val_loss/dataloader_idx_8 â–ˆâ–‚â–ƒâ–â–†â–ˆâ–‚
wandb:   val_loss/dataloader_idx_9 â–ˆâ–‚â–ƒâ–â–…â–ˆâ–‚
wandb: 
wandb: Run summary:
wandb:                       epoch 7
wandb:                    test_auc 0.73995
wandb:   test_auc/dataloader_idx_0 0.8346
wandb:   test_auc/dataloader_idx_1 0.84561
wandb:  test_auc/dataloader_idx_10 0.76289
wandb:  test_auc/dataloader_idx_11 0.73995
wandb:   test_auc/dataloader_idx_2 0.86268
wandb:   test_auc/dataloader_idx_3 0.86019
wandb:   test_auc/dataloader_idx_4 0.8476
wandb:   test_auc/dataloader_idx_5 0.85342
wandb:   test_auc/dataloader_idx_6 0.81985
wandb:   test_auc/dataloader_idx_7 0.82488
wandb:   test_auc/dataloader_idx_8 0.81784
wandb:   test_auc/dataloader_idx_9 0.77468
wandb:  test_loss/dataloader_idx_0 0.27441
wandb:  test_loss/dataloader_idx_1 0.28589
wandb: test_loss/dataloader_idx_10 0.37343
wandb: test_loss/dataloader_idx_11 0.37994
wandb:  test_loss/dataloader_idx_2 0.27572
wandb:  test_loss/dataloader_idx_3 0.27233
wandb:  test_loss/dataloader_idx_4 0.29397
wandb:  test_loss/dataloader_idx_5 0.28686
wandb:  test_loss/dataloader_idx_6 0.3145
wandb:  test_loss/dataloader_idx_7 0.29857
wandb:  test_loss/dataloader_idx_8 0.32092
wandb:  test_loss/dataloader_idx_9 0.34846
wandb:                   test_year 2024
wandb:            train_loss_epoch 0.43187
wandb:             train_loss_step 0.18798
wandb:         trainer/global_step 52339
wandb:    val_auc/dataloader_idx_0 0.83206
wandb:    val_auc/dataloader_idx_1 0.84074
wandb:   val_auc/dataloader_idx_10 0.74568
wandb:   val_auc/dataloader_idx_11 0.7411
wandb:    val_auc/dataloader_idx_2 0.85317
wandb:    val_auc/dataloader_idx_3 0.85943
wandb:    val_auc/dataloader_idx_4 0.85221
wandb:    val_auc/dataloader_idx_5 0.8234
wandb:    val_auc/dataloader_idx_6 0.83657
wandb:    val_auc/dataloader_idx_7 0.81708
wandb:    val_auc/dataloader_idx_8 0.81596
wandb:    val_auc/dataloader_idx_9 0.77687
wandb:   val_loss/dataloader_idx_0 0.27998
wandb:   val_loss/dataloader_idx_1 0.28693
wandb:  val_loss/dataloader_idx_10 0.39224
wandb:  val_loss/dataloader_idx_11 0.39541
wandb:   val_loss/dataloader_idx_2 0.27387
wandb:   val_loss/dataloader_idx_3 0.28465
wandb:   val_loss/dataloader_idx_4 0.29787
wandb:   val_loss/dataloader_idx_5 0.30993
wandb:   val_loss/dataloader_idx_6 0.30276
wandb:   val_loss/dataloader_idx_7 0.31297
wandb:   val_loss/dataloader_idx_8 0.3302
wandb:   val_loss/dataloader_idx_9 0.35875
wandb: 
wandb: ğŸš€ View run traditional-sequential-2013-2024-2021-seed-13 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/itl0wvjd
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260202_044005-itl0wvjd/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260202_084101-v3juclzz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run traditional-sequential-2013-2024-2022-seed-13
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/v3juclzz
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/traditional-sequential-2013-2024/seed-13 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
