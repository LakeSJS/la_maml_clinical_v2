============================================
Job ID: 17655310
Job Name: lamaml_exp
Node: a100-4014
Partition: a100_short
Start time: Sat Jan 24 16:29:22 EST 2026
Config: tmaml_seq_2013_2024
Seed: 10
Paths: gpfs
============================================
Running: python /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/scripts/run_experiment.py --config tmaml_seq_2013_2024 --paths gpfs --seed 10
============================================
[rank: 0] Global seed set to 10
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /gpfs/data/oermannlab/NYUTron/model_zoos/nyutron_small/checkpoint-736000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: lakej98 (lakej98-nyu-langone-health) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260124_163048-stt1nc5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2013-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/stt1nc5q
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2013-v2.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2013-v2.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81263864040374â€¦ â”‚ 0.83203923702239â€¦ â”‚ 0.8416043519973â€¦ â”‚
â”‚     test_loss     â”‚ 0.26502972841262â€¦ â”‚ 0.28098392486572â€¦ â”‚ 0.2609334588050â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.82778620719909â€¦ â”‚ 0.81567645072937â€¦ â”‚ 0.8089542388916â€¦ â”‚
â”‚     test_loss     â”‚ 0.26573598384857â€¦ â”‚ 0.29793465137481â€¦ â”‚ 0.2787949144840â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.77392309904098â€¦ â”‚ 0.77796757221221â€¦ â”‚ 0.7667379379272â€¦ â”‚
â”‚     test_loss     â”‚ 0.31653243303298â€¦ â”‚ 0.29421609640121â€¦ â”‚ 0.3237562775611â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74257874488830â€¦ â”‚ 0.720832884311676 â”‚ 0.7011550068855â€¦ â”‚
â”‚     test_loss     â”‚ 0.31846019625663â€¦ â”‚ 0.33095160126686â€¦ â”‚ 0.3376081883907â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–†â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:              meta_loss_step â–ˆâ–‡â–‚â–â–‚â–†â–„â–â–â–‚â–ƒâ–â–ˆâ–„â–‚â–‚â–…â–„â–†â–‚â–â–â–‡â–‚â–‚â–„â–†â–ƒâ–‚â–â–â–ƒâ–‚â–‡â–â–‚â–…â–â–â–
wandb:                    test_auc â–‡â–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_0 â–â–„â–…â–†â–‡â–‡â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_1 â–â–…â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   val_auc/dataloader_idx_10 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:   val_auc/dataloader_idx_11 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:    val_auc/dataloader_idx_2 â–â–„â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_3 â–â–„â–…â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_4 â–â–„â–…â–†â–†â–‡â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_5 â–â–„â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_6 â–â–„â–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–„â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_8 â–â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_9 â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_0 â–ˆâ–†â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–
wandb:   val_loss/dataloader_idx_1 â–ˆâ–„â–‚â–â–â–‚â–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–‚
wandb:  val_loss/dataloader_idx_10 â–ˆâ–‡â–ƒâ–â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–ƒ
wandb:  val_loss/dataloader_idx_11 â–ˆâ–‡â–ƒâ–â–â–ƒâ–ƒâ–„â–„â–ƒâ–„â–ƒâ–…â–ƒ
wandb:   val_loss/dataloader_idx_2 â–ˆâ–†â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–
wandb:   val_loss/dataloader_idx_3 â–ˆâ–†â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–â–â–‚â–
wandb:   val_loss/dataloader_idx_4 â–ˆâ–†â–„â–‚â–ƒâ–ƒâ–„â–‚â–„â–‚â–‚â–â–‚â–
wandb:   val_loss/dataloader_idx_5 â–ˆâ–‡â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–‚â–‚â–
wandb:   val_loss/dataloader_idx_6 â–ˆâ–†â–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–
wandb:   val_loss/dataloader_idx_7 â–ˆâ–‡â–ƒâ–â–â–„â–ƒâ–„â–…â–‚â–ƒâ–â–†â–
wandb:   val_loss/dataloader_idx_8 â–ˆâ–‡â–„â–â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–
wandb:   val_loss/dataloader_idx_9 â–ˆâ–‡â–„â–â–â–‚â–‚â–‚â–‚â–â–‚â–â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:                       epoch 14
wandb:             meta_loss_epoch 0.16745
wandb:              meta_loss_step 0.07766
wandb:                    test_auc 0.70116
wandb:   test_auc/dataloader_idx_0 0.81264
wandb:   test_auc/dataloader_idx_1 0.83204
wandb:  test_auc/dataloader_idx_10 0.72083
wandb:  test_auc/dataloader_idx_11 0.70116
wandb:   test_auc/dataloader_idx_2 0.8416
wandb:   test_auc/dataloader_idx_3 0.82779
wandb:   test_auc/dataloader_idx_4 0.81568
wandb:   test_auc/dataloader_idx_5 0.80895
wandb:   test_auc/dataloader_idx_6 0.77392
wandb:   test_auc/dataloader_idx_7 0.77797
wandb:   test_auc/dataloader_idx_8 0.76674
wandb:   test_auc/dataloader_idx_9 0.74258
wandb:  test_loss/dataloader_idx_0 0.26503
wandb:  test_loss/dataloader_idx_1 0.28098
wandb: test_loss/dataloader_idx_10 0.33095
wandb: test_loss/dataloader_idx_11 0.33761
wandb:  test_loss/dataloader_idx_2 0.26093
wandb:  test_loss/dataloader_idx_3 0.26574
wandb:  test_loss/dataloader_idx_4 0.29793
wandb:  test_loss/dataloader_idx_5 0.27879
wandb:  test_loss/dataloader_idx_6 0.31653
wandb:  test_loss/dataloader_idx_7 0.29422
wandb:  test_loss/dataloader_idx_8 0.32376
wandb:  test_loss/dataloader_idx_9 0.31846
wandb:                   test_year 2024
wandb:         trainer/global_step 88522
wandb:    val_auc/dataloader_idx_0 0.82627
wandb:    val_auc/dataloader_idx_1 0.82235
wandb:   val_auc/dataloader_idx_10 0.72487
wandb:   val_auc/dataloader_idx_11 0.71027
wandb:    val_auc/dataloader_idx_2 0.8307
wandb:    val_auc/dataloader_idx_3 0.84142
wandb:    val_auc/dataloader_idx_4 0.81893
wandb:    val_auc/dataloader_idx_5 0.80284
wandb:    val_auc/dataloader_idx_6 0.79965
wandb:    val_auc/dataloader_idx_7 0.76866
wandb:    val_auc/dataloader_idx_8 0.76374
wandb:    val_auc/dataloader_idx_9 0.74612
wandb:   val_loss/dataloader_idx_0 0.26664
wandb:   val_loss/dataloader_idx_1 0.27965
wandb:  val_loss/dataloader_idx_10 0.32678
wandb:  val_loss/dataloader_idx_11 0.33388
wandb:   val_loss/dataloader_idx_2 0.25338
wandb:   val_loss/dataloader_idx_3 0.25867
wandb:   val_loss/dataloader_idx_4 0.28758
wandb:   val_loss/dataloader_idx_5 0.2943
wandb:   val_loss/dataloader_idx_6 0.28769
wandb:   val_loss/dataloader_idx_7 0.30806
wandb:   val_loss/dataloader_idx_8 0.32057
wandb:   val_loss/dataloader_idx_9 0.31351
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2013-seed-10 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/stt1nc5q
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260124_163048-stt1nc5q/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260125_071314-z4gxk6ic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2014-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/z4gxk6ic
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2014.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2014.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.811663031578064 â”‚ 0.83542239665985â€¦ â”‚ 0.8474752306938â€¦ â”‚
â”‚     test_loss     â”‚ 0.26774778962135â€¦ â”‚ 0.28899765014648â€¦ â”‚ 0.2578966021537â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83859658241271â€¦ â”‚ 0.82040017843246â€¦ â”‚ 0.8174459934234â€¦ â”‚
â”‚     test_loss     â”‚ 0.26058104634284â€¦ â”‚ 0.30498069524765â€¦ â”‚ 0.2770959734916â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.78271746635437â€¦ â”‚ 0.78609299659729  â”‚ 0.7745193243026â€¦ â”‚
â”‚     test_loss     â”‚ 0.31729590892791â€¦ â”‚ 0.28964838385581â€¦ â”‚ 0.3244625031948â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74194008111953â€¦ â”‚ 0.72507548332214â€¦ â”‚ 0.7046058177947â€¦ â”‚
â”‚     test_loss     â”‚ 0.32481145858764â€¦ â”‚ 0.33393228054046â€¦ â”‚ 0.3380189538002â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–
wandb:              meta_loss_step â–â–â–â–ƒâ–ƒâ–â–ˆâ–‚â–â–‚â–â–â–â–â–â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–†â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–‡â–…â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–…â–ˆâ–…â–„â–ƒâ–„â–ƒâ–
wandb:    val_auc/dataloader_idx_1 â–â–„â–‚â–‡â–ˆâ–ˆâ–„â–…
wandb:   val_auc/dataloader_idx_10 â–â–„â–ˆâ–ˆâ–ˆâ–ƒâ–â–‚
wandb:   val_auc/dataloader_idx_11 â–‡â–†â–†â–ˆâ–ˆâ–„â–…â–
wandb:    val_auc/dataloader_idx_2 â–â–„â–„â–†â–‡â–†â–‡â–ˆ
wandb:    val_auc/dataloader_idx_3 â–â–ƒâ–‚â–†â–‡â–ˆâ–…â–‡
wandb:    val_auc/dataloader_idx_4 â–â–„â–„â–†â–†â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_5 â–â–‚â–…â–†â–‡â–†â–†â–ˆ
wandb:    val_auc/dataloader_idx_6 â–â–‚â–ƒâ–…â–…â–†â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–‚â–„â–„â–…â–†â–‡â–ˆ
wandb:    val_auc/dataloader_idx_8 â–â–‚â–‚â–‚â–ˆâ–„â–…â–†
wandb:    val_auc/dataloader_idx_9 â–ˆâ–‡â–ˆâ–†â–†â–ƒâ–â–
wandb:   val_loss/dataloader_idx_0 â–„â–â–‚â–ˆâ–†â–ƒâ–…â–‡
wandb:   val_loss/dataloader_idx_1 â–‡â–‚â–‚â–ˆâ–…â–â–…â–…
wandb:  val_loss/dataloader_idx_10 â–…â–‚â–â–ˆâ–„â–‚â–„â–…
wandb:  val_loss/dataloader_idx_11 â–„â–â–â–ˆâ–„â–â–‚â–…
wandb:   val_loss/dataloader_idx_2 â–ˆâ–ƒâ–‚â–…â–‚â–‚â–â–
wandb:   val_loss/dataloader_idx_3 â–ˆâ–„â–„â–ˆâ–†â–â–„â–„
wandb:   val_loss/dataloader_idx_4 â–‡â–ƒâ–ƒâ–ˆâ–‡â–â–ƒâ–ƒ
wandb:   val_loss/dataloader_idx_5 â–†â–‚â–‚â–ˆâ–…â–â–ƒâ–ƒ
wandb:   val_loss/dataloader_idx_6 â–ˆâ–„â–ƒâ–ˆâ–†â–â–‚â–‚
wandb:   val_loss/dataloader_idx_7 â–‡â–„â–ƒâ–ˆâ–…â–â–‚â–‚
wandb:   val_loss/dataloader_idx_8 â–…â–ƒâ–‚â–ˆâ–„â–â–‚â–ƒ
wandb:   val_loss/dataloader_idx_9 â–„â–â–â–ˆâ–…â–‚â–…â–†
wandb: 
wandb: Run summary:
wandb:                       epoch 8
wandb:             meta_loss_epoch 0.14896
wandb:              meta_loss_step 0.01763
wandb:                    test_auc 0.70461
wandb:   test_auc/dataloader_idx_0 0.81166
wandb:   test_auc/dataloader_idx_1 0.83542
wandb:  test_auc/dataloader_idx_10 0.72508
wandb:  test_auc/dataloader_idx_11 0.70461
wandb:   test_auc/dataloader_idx_2 0.84748
wandb:   test_auc/dataloader_idx_3 0.8386
wandb:   test_auc/dataloader_idx_4 0.8204
wandb:   test_auc/dataloader_idx_5 0.81745
wandb:   test_auc/dataloader_idx_6 0.78272
wandb:   test_auc/dataloader_idx_7 0.78609
wandb:   test_auc/dataloader_idx_8 0.77452
wandb:   test_auc/dataloader_idx_9 0.74194
wandb:  test_loss/dataloader_idx_0 0.26775
wandb:  test_loss/dataloader_idx_1 0.289
wandb: test_loss/dataloader_idx_10 0.33393
wandb: test_loss/dataloader_idx_11 0.33802
wandb:  test_loss/dataloader_idx_2 0.2579
wandb:  test_loss/dataloader_idx_3 0.26058
wandb:  test_loss/dataloader_idx_4 0.30498
wandb:  test_loss/dataloader_idx_5 0.2771
wandb:  test_loss/dataloader_idx_6 0.3173
wandb:  test_loss/dataloader_idx_7 0.28965
wandb:  test_loss/dataloader_idx_8 0.32446
wandb:  test_loss/dataloader_idx_9 0.32481
wandb:                   test_year 2024
wandb:         trainer/global_step 55232
wandb:    val_auc/dataloader_idx_0 0.82043
wandb:    val_auc/dataloader_idx_1 0.82713
wandb:   val_auc/dataloader_idx_10 0.72686
wandb:   val_auc/dataloader_idx_11 0.71267
wandb:    val_auc/dataloader_idx_2 0.84083
wandb:    val_auc/dataloader_idx_3 0.84877
wandb:    val_auc/dataloader_idx_4 0.8259
wandb:    val_auc/dataloader_idx_5 0.80749
wandb:    val_auc/dataloader_idx_6 0.80852
wandb:    val_auc/dataloader_idx_7 0.77708
wandb:    val_auc/dataloader_idx_8 0.76978
wandb:    val_auc/dataloader_idx_9 0.74198
wandb:   val_loss/dataloader_idx_0 0.28087
wandb:   val_loss/dataloader_idx_1 0.28521
wandb:  val_loss/dataloader_idx_10 0.33223
wandb:  val_loss/dataloader_idx_11 0.33676
wandb:   val_loss/dataloader_idx_2 0.25173
wandb:   val_loss/dataloader_idx_3 0.25963
wandb:   val_loss/dataloader_idx_4 0.29067
wandb:   val_loss/dataloader_idx_5 0.30082
wandb:   val_loss/dataloader_idx_6 0.2879
wandb:   val_loss/dataloader_idx_7 0.30742
wandb:   val_loss/dataloader_idx_8 0.32265
wandb:   val_loss/dataloader_idx_9 0.32234
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2014-seed-10 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/z4gxk6ic
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260125_071314-z4gxk6ic/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260125_163354-m4f670im
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2015-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/m4f670im
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2015.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2015.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.815758228302002 â”‚ 0.83355283737182â€¦ â”‚ 0.8490228652954â€¦ â”‚
â”‚     test_loss     â”‚ 0.26121166348457â€¦ â”‚ 0.28271692991256â€¦ â”‚ 0.2548265159130â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83994865417480â€¦ â”‚ 0.82602369785308â€¦ â”‚ 0.8191830515861â€¦ â”‚
â”‚     test_loss     â”‚ 0.25426173210144â€¦ â”‚ 0.28886947035789â€¦ â”‚ 0.2690795063972â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.783113956451416 â”‚ 0.78945159912109â€¦ â”‚ 0.7763233780860â€¦ â”‚
â”‚     test_loss     â”‚ 0.30726096034049â€¦ â”‚ 0.28182300925254â€¦ â”‚ 0.3162585794925â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74002724885940â€¦ â”‚ 0.72516733407974â€¦ â”‚ 0.70611572265625 â”‚
â”‚     test_loss     â”‚ 0.31902974843978â€¦ â”‚ 0.32653942704200â€¦ â”‚ 0.3299916982650â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–†â–ƒâ–
wandb:              meta_loss_step â–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–â–ƒâ–â–‚â–‚â–â–‚â–ƒâ–â–â–ƒâ–ƒâ–‚â–ˆâ–â–â–â–â–â–â–‚â–â–ƒâ–â–â–â–â–â–â–ƒâ–â–„
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–‡â–…â–…â–„â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–‚â–…â–â–ˆ
wandb:    val_auc/dataloader_idx_1 â–ˆâ–ˆâ–â–…
wandb:   val_auc/dataloader_idx_10 â–…â–ˆâ–â–‚
wandb:   val_auc/dataloader_idx_11 â–†â–ˆâ–â–
wandb:    val_auc/dataloader_idx_2 â–ˆâ–â–ƒâ–
wandb:    val_auc/dataloader_idx_3 â–‚â–â–†â–ˆ
wandb:    val_auc/dataloader_idx_4 â–â–ˆâ–ˆâ–‡
wandb:    val_auc/dataloader_idx_5 â–â–…â–†â–ˆ
wandb:    val_auc/dataloader_idx_6 â–â–„â–ˆâ–‡
wandb:    val_auc/dataloader_idx_7 â–â–‡â–ˆâ–‡
wandb:    val_auc/dataloader_idx_8 â–â–ˆâ–…â–…
wandb:    val_auc/dataloader_idx_9 â–ˆâ–†â–â–…
wandb:   val_loss/dataloader_idx_0 â–â–‚â–„â–ˆ
wandb:   val_loss/dataloader_idx_1 â–â–ƒâ–„â–ˆ
wandb:  val_loss/dataloader_idx_10 â–‚â–„â–â–ˆ
wandb:  val_loss/dataloader_idx_11 â–…â–‡â–â–ˆ
wandb:   val_loss/dataloader_idx_2 â–â–„â–…â–ˆ
wandb:   val_loss/dataloader_idx_3 â–†â–ˆâ–â–…
wandb:   val_loss/dataloader_idx_4 â–ˆâ–ˆâ–â–‡
wandb:   val_loss/dataloader_idx_5 â–ˆâ–ˆâ–â–†
wandb:   val_loss/dataloader_idx_6 â–ˆâ–‡â–â–…
wandb:   val_loss/dataloader_idx_7 â–ˆâ–…â–â–„
wandb:   val_loss/dataloader_idx_8 â–‡â–ˆâ–â–‡
wandb:   val_loss/dataloader_idx_9 â–„â–ˆâ–â–†
wandb: 
wandb: Run summary:
wandb:                       epoch 4
wandb:             meta_loss_epoch 0.15195
wandb:              meta_loss_step 0.03513
wandb:                    test_auc 0.70612
wandb:   test_auc/dataloader_idx_0 0.81576
wandb:   test_auc/dataloader_idx_1 0.83355
wandb:  test_auc/dataloader_idx_10 0.72517
wandb:  test_auc/dataloader_idx_11 0.70612
wandb:   test_auc/dataloader_idx_2 0.84902
wandb:   test_auc/dataloader_idx_3 0.83995
wandb:   test_auc/dataloader_idx_4 0.82602
wandb:   test_auc/dataloader_idx_5 0.81918
wandb:   test_auc/dataloader_idx_6 0.78311
wandb:   test_auc/dataloader_idx_7 0.78945
wandb:   test_auc/dataloader_idx_8 0.77632
wandb:   test_auc/dataloader_idx_9 0.74003
wandb:  test_loss/dataloader_idx_0 0.26121
wandb:  test_loss/dataloader_idx_1 0.28272
wandb: test_loss/dataloader_idx_10 0.32654
wandb: test_loss/dataloader_idx_11 0.32999
wandb:  test_loss/dataloader_idx_2 0.25483
wandb:  test_loss/dataloader_idx_3 0.25426
wandb:  test_loss/dataloader_idx_4 0.28887
wandb:  test_loss/dataloader_idx_5 0.26908
wandb:  test_loss/dataloader_idx_6 0.30726
wandb:  test_loss/dataloader_idx_7 0.28182
wandb:  test_loss/dataloader_idx_8 0.31626
wandb:  test_loss/dataloader_idx_9 0.31903
wandb:                   test_year 2024
wandb:         trainer/global_step 29240
wandb:    val_auc/dataloader_idx_0 0.82598
wandb:    val_auc/dataloader_idx_1 0.82469
wandb:   val_auc/dataloader_idx_10 0.7258
wandb:   val_auc/dataloader_idx_11 0.713
wandb:    val_auc/dataloader_idx_2 0.83895
wandb:    val_auc/dataloader_idx_3 0.85555
wandb:    val_auc/dataloader_idx_4 0.82989
wandb:    val_auc/dataloader_idx_5 0.81366
wandb:    val_auc/dataloader_idx_6 0.81078
wandb:    val_auc/dataloader_idx_7 0.78212
wandb:    val_auc/dataloader_idx_8 0.77146
wandb:    val_auc/dataloader_idx_9 0.74308
wandb:   val_loss/dataloader_idx_0 0.27947
wandb:   val_loss/dataloader_idx_1 0.28804
wandb:  val_loss/dataloader_idx_10 0.327
wandb:  val_loss/dataloader_idx_11 0.32977
wandb:   val_loss/dataloader_idx_2 0.25606
wandb:   val_loss/dataloader_idx_3 0.25214
wandb:   val_loss/dataloader_idx_4 0.2817
wandb:   val_loss/dataloader_idx_5 0.29048
wandb:   val_loss/dataloader_idx_6 0.28127
wandb:   val_loss/dataloader_idx_7 0.29788
wandb:   val_loss/dataloader_idx_8 0.31599
wandb:   val_loss/dataloader_idx_9 0.315
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2015-seed-10 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/m4f670im
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260125_163354-m4f670im/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260125_215227-hum1cza8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2016-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/hum1cza8
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2016.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2016.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81795179843902â€¦ â”‚ 0.83293437957763â€¦ â”‚ 0.8459805250167â€¦ â”‚
â”‚     test_loss     â”‚ 0.26891893148422â€¦ â”‚ 0.29570642113685â€¦ â”‚ 0.2665847837924â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.84562170505523â€¦ â”‚ 0.83332300186157â€¦ â”‚ 0.8333128690719â€¦ â”‚
â”‚     test_loss     â”‚ 0.25759509205818â€¦ â”‚ 0.27786284685134â€¦ â”‚ 0.2576319277286â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.79520404338836â€¦ â”‚ 0.80260378122329â€¦ â”‚ 0.7846615314483â€¦ â”‚
â”‚     test_loss     â”‚ 0.29453334212303â€¦ â”‚ 0.27051028609275â€¦ â”‚ 0.3100528419017â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74496006965637â€¦ â”‚ 0.72396975755691â€¦ â”‚ 0.7058281898498â€¦ â”‚
â”‚     test_loss     â”‚ 0.31728786230087â€¦ â”‚ 0.32807561755180â€¦ â”‚ 0.3301151692867â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:              meta_loss_step â–…â–‚â–‚â–ƒâ–â–â–„â–…â–‚â–ˆâ–‚â–‚â–â–ƒâ–â–â–ƒâ–‚â–â–â–‚â–‚â–†â–â–â–‚â–â–â–„â–‚â–…â–„â–ƒâ–‚â–„â–‚â–â–„â–‚â–
wandb:                    test_auc â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–…â–†â–…â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ƒâ–â–…â–â–‡â–ˆâ–ƒâ–‡â–‡â–‡â–ƒ
wandb:    val_auc/dataloader_idx_1 â–‚â–â–‡â–ƒâ–„â–…â–…â–ˆâ–ƒâ–„â–„
wandb:   val_auc/dataloader_idx_10 â–‡â–†â–‡â–â–†â–ƒâ–…â–ƒâ–†â–ƒâ–ˆ
wandb:   val_auc/dataloader_idx_11 â–‡â–ˆâ–ˆâ–ƒâ–†â–‚â–„â–‚â–„â–â–ƒ
wandb:    val_auc/dataloader_idx_2 â–ƒâ–â–‚â–ƒâ–†â–ˆâ–†â–†â–„â–ƒâ–„
wandb:    val_auc/dataloader_idx_3 â–‚â–„â–ƒâ–â–†â–…â–…â–ˆâ–‡â–…â–…
wandb:    val_auc/dataloader_idx_4 â–â–‚â–„â–„â–…â–†â–†â–†â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_5 â–â–‚â–„â–„â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_6 â–â–‚â–„â–„â–ˆâ–ˆâ–‡â–‡â–‡â–†â–‡
wandb:    val_auc/dataloader_idx_7 â–â–â–„â–„â–†â–ˆâ–†â–ˆâ–†â–…â–†
wandb:    val_auc/dataloader_idx_8 â–„â–…â–†â–â–…â–‡â–ˆâ–‡â–‡â–„â–„
wandb:    val_auc/dataloader_idx_9 â–„â–ƒâ–„â–â–„â–„â–‡â–…â–‡â–†â–ˆ
wandb:   val_loss/dataloader_idx_0 â–â–‚â–‚â–‚â–„â–‚â–†â–…â–…â–ˆâ–†
wandb:   val_loss/dataloader_idx_1 â–‚â–‚â–â–‚â–„â–ƒâ–…â–„â–…â–ˆâ–†
wandb:  val_loss/dataloader_idx_10 â–„â–‚â–â–‚â–„â–â–ƒâ–ƒâ–…â–ˆâ–‡
wandb:  val_loss/dataloader_idx_11 â–ƒâ–â–â–â–„â–‚â–ƒâ–„â–†â–ˆâ–ˆ
wandb:   val_loss/dataloader_idx_2 â–â–‚â–ƒâ–â–ƒâ–â–„â–„â–…â–ˆâ–†
wandb:   val_loss/dataloader_idx_3 â–‚â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–†â–ˆâ–‡
wandb:   val_loss/dataloader_idx_4 â–ˆâ–†â–†â–…â–†â–„â–…â–ƒâ–‚â–ƒâ–
wandb:   val_loss/dataloader_idx_5 â–ˆâ–†â–†â–…â–†â–„â–…â–ƒâ–‚â–ƒâ–
wandb:   val_loss/dataloader_idx_6 â–ˆâ–‡â–†â–„â–…â–„â–…â–ƒâ–‚â–ƒâ–
wandb:   val_loss/dataloader_idx_7 â–ˆâ–‡â–†â–…â–†â–ƒâ–„â–‚â–â–ƒâ–
wandb:   val_loss/dataloader_idx_8 â–‡â–„â–ƒâ–ƒâ–‡â–‚â–…â–â–‚â–ˆâ–…
wandb:   val_loss/dataloader_idx_9 â–„â–‚â–â–‚â–…â–â–ƒâ–â–ƒâ–ˆâ–„
wandb: 
wandb: Run summary:
wandb:                       epoch 11
wandb:             meta_loss_epoch 0.14008
wandb:              meta_loss_step 0.01884
wandb:                    test_auc 0.70583
wandb:   test_auc/dataloader_idx_0 0.81795
wandb:   test_auc/dataloader_idx_1 0.83293
wandb:  test_auc/dataloader_idx_10 0.72397
wandb:  test_auc/dataloader_idx_11 0.70583
wandb:   test_auc/dataloader_idx_2 0.84598
wandb:   test_auc/dataloader_idx_3 0.84562
wandb:   test_auc/dataloader_idx_4 0.83332
wandb:   test_auc/dataloader_idx_5 0.83331
wandb:   test_auc/dataloader_idx_6 0.7952
wandb:   test_auc/dataloader_idx_7 0.8026
wandb:   test_auc/dataloader_idx_8 0.78466
wandb:   test_auc/dataloader_idx_9 0.74496
wandb:  test_loss/dataloader_idx_0 0.26892
wandb:  test_loss/dataloader_idx_1 0.29571
wandb: test_loss/dataloader_idx_10 0.32808
wandb: test_loss/dataloader_idx_11 0.33012
wandb:  test_loss/dataloader_idx_2 0.26658
wandb:  test_loss/dataloader_idx_3 0.2576
wandb:  test_loss/dataloader_idx_4 0.27786
wandb:  test_loss/dataloader_idx_5 0.25763
wandb:  test_loss/dataloader_idx_6 0.29453
wandb:  test_loss/dataloader_idx_7 0.27051
wandb:  test_loss/dataloader_idx_8 0.31005
wandb:  test_loss/dataloader_idx_9 0.31729
wandb:                   test_year 2024
wandb:         trainer/global_step 92499
wandb:    val_auc/dataloader_idx_0 0.82175
wandb:    val_auc/dataloader_idx_1 0.82655
wandb:   val_auc/dataloader_idx_10 0.7294
wandb:   val_auc/dataloader_idx_11 0.70931
wandb:    val_auc/dataloader_idx_2 0.83833
wandb:    val_auc/dataloader_idx_3 0.85626
wandb:    val_auc/dataloader_idx_4 0.84447
wandb:    val_auc/dataloader_idx_5 0.82576
wandb:    val_auc/dataloader_idx_6 0.81653
wandb:    val_auc/dataloader_idx_7 0.78551
wandb:    val_auc/dataloader_idx_8 0.77196
wandb:    val_auc/dataloader_idx_9 0.75041
wandb:   val_loss/dataloader_idx_0 0.28821
wandb:   val_loss/dataloader_idx_1 0.29164
wandb:  val_loss/dataloader_idx_10 0.33117
wandb:  val_loss/dataloader_idx_11 0.33959
wandb:   val_loss/dataloader_idx_2 0.26247
wandb:   val_loss/dataloader_idx_3 0.26044
wandb:   val_loss/dataloader_idx_4 0.26503
wandb:   val_loss/dataloader_idx_5 0.27183
wandb:   val_loss/dataloader_idx_6 0.26984
wandb:   val_loss/dataloader_idx_7 0.28884
wandb:   val_loss/dataloader_idx_8 0.31433
wandb:   val_loss/dataloader_idx_9 0.31605
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2016-seed-10 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/hum1cza8
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260125_215227-hum1cza8/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260126_133351-kxen0fc3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2017-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/kxen0fc3
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2017.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2017.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81783533096313â€¦ â”‚ 0.83332002162933â€¦ â”‚ 0.8449831008911â€¦ â”‚
â”‚     test_loss     â”‚ 0.26781493425369â€¦ â”‚ 0.29841935634613â€¦ â”‚ 0.2659559845924â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.84380364418029â€¦ â”‚ 0.83282208442687â€¦ â”‚ 0.8348302841186â€¦ â”‚
â”‚     test_loss     â”‚ 0.26089802384376â€¦ â”‚ 0.28448370099067â€¦ â”‚ 0.2578659951686â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.798173189163208 â”‚ 0.80493283271789â€¦ â”‚ 0.7859294414520â€¦ â”‚
â”‚     test_loss     â”‚ 0.29404693841934â€¦ â”‚ 0.26964086294174â€¦ â”‚ 0.3119056224822â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.74571841955184â€¦ â”‚ 0.72890639305114â€¦ â”‚ 0.7124289870262â€¦ â”‚
â”‚     test_loss     â”‚ 0.31944149732589â€¦ â”‚ 0.32837456464767â€¦ â”‚ 0.3298474848270â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–†â–ƒâ–
wandb:              meta_loss_step â–â–â–â–‚â–ƒâ–â–â–â–â–â–ƒâ–â–‚â–â–â–‚â–â–‚â–â–â–‚â–â–â–â–ˆâ–„â–â–â–â–â–ƒâ–â–â–„â–â–„â–â–‚â–‚â–‚
wandb:                    test_auc â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–ƒâ–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_0 â–ˆâ–â–†â–ˆ
wandb:    val_auc/dataloader_idx_1 â–ƒâ–â–ˆâ–‚
wandb:   val_auc/dataloader_idx_10 â–…â–â–„â–ˆ
wandb:   val_auc/dataloader_idx_11 â–…â–â–…â–ˆ
wandb:    val_auc/dataloader_idx_2 â–ˆâ–â–…â–„
wandb:    val_auc/dataloader_idx_3 â–ˆâ–ƒâ–ƒâ–
wandb:    val_auc/dataloader_idx_4 â–ˆâ–†â–‚â–
wandb:    val_auc/dataloader_idx_5 â–â–†â–ˆâ–‡
wandb:    val_auc/dataloader_idx_6 â–â–ƒâ–‡â–ˆ
wandb:    val_auc/dataloader_idx_7 â–ƒâ–â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_8 â–ˆâ–â–‚â–…
wandb:    val_auc/dataloader_idx_9 â–…â–â–ƒâ–ˆ
wandb:   val_loss/dataloader_idx_0 â–ƒâ–…â–â–ˆ
wandb:   val_loss/dataloader_idx_1 â–ƒâ–…â–â–ˆ
wandb:  val_loss/dataloader_idx_10 â–â–‚â–ƒâ–ˆ
wandb:  val_loss/dataloader_idx_11 â–â–‚â–ƒâ–ˆ
wandb:   val_loss/dataloader_idx_2 â–‚â–„â–â–ˆ
wandb:   val_loss/dataloader_idx_3 â–â–ƒâ–‚â–ˆ
wandb:   val_loss/dataloader_idx_4 â–â–‚â–ƒâ–ˆ
wandb:   val_loss/dataloader_idx_5 â–ˆâ–„â–â–†
wandb:   val_loss/dataloader_idx_6 â–ˆâ–ƒâ–â–†
wandb:   val_loss/dataloader_idx_7 â–ˆâ–„â–â–ˆ
wandb:   val_loss/dataloader_idx_8 â–â–â–â–ˆ
wandb:   val_loss/dataloader_idx_9 â–â–â–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 4
wandb:             meta_loss_epoch 0.14525
wandb:              meta_loss_step 0.08186
wandb:                    test_auc 0.71243
wandb:   test_auc/dataloader_idx_0 0.81784
wandb:   test_auc/dataloader_idx_1 0.83332
wandb:  test_auc/dataloader_idx_10 0.72891
wandb:  test_auc/dataloader_idx_11 0.71243
wandb:   test_auc/dataloader_idx_2 0.84498
wandb:   test_auc/dataloader_idx_3 0.8438
wandb:   test_auc/dataloader_idx_4 0.83282
wandb:   test_auc/dataloader_idx_5 0.83483
wandb:   test_auc/dataloader_idx_6 0.79817
wandb:   test_auc/dataloader_idx_7 0.80493
wandb:   test_auc/dataloader_idx_8 0.78593
wandb:   test_auc/dataloader_idx_9 0.74572
wandb:  test_loss/dataloader_idx_0 0.26781
wandb:  test_loss/dataloader_idx_1 0.29842
wandb: test_loss/dataloader_idx_10 0.32837
wandb: test_loss/dataloader_idx_11 0.32985
wandb:  test_loss/dataloader_idx_2 0.26596
wandb:  test_loss/dataloader_idx_3 0.2609
wandb:  test_loss/dataloader_idx_4 0.28448
wandb:  test_loss/dataloader_idx_5 0.25787
wandb:  test_loss/dataloader_idx_6 0.29405
wandb:  test_loss/dataloader_idx_7 0.26964
wandb:  test_loss/dataloader_idx_8 0.31191
wandb:  test_loss/dataloader_idx_9 0.31944
wandb:                   test_year 2024
wandb:         trainer/global_step 46560
wandb:    val_auc/dataloader_idx_0 0.82038
wandb:    val_auc/dataloader_idx_1 0.82679
wandb:   val_auc/dataloader_idx_10 0.73413
wandb:   val_auc/dataloader_idx_11 0.71669
wandb:    val_auc/dataloader_idx_2 0.83844
wandb:    val_auc/dataloader_idx_3 0.85393
wandb:    val_auc/dataloader_idx_4 0.83947
wandb:    val_auc/dataloader_idx_5 0.82732
wandb:    val_auc/dataloader_idx_6 0.82163
wandb:    val_auc/dataloader_idx_7 0.7945
wandb:    val_auc/dataloader_idx_8 0.77066
wandb:    val_auc/dataloader_idx_9 0.754
wandb:   val_loss/dataloader_idx_0 0.29694
wandb:   val_loss/dataloader_idx_1 0.30037
wandb:  val_loss/dataloader_idx_10 0.34018
wandb:  val_loss/dataloader_idx_11 0.35038
wandb:   val_loss/dataloader_idx_2 0.26855
wandb:   val_loss/dataloader_idx_3 0.27316
wandb:   val_loss/dataloader_idx_4 0.2966
wandb:   val_loss/dataloader_idx_5 0.27591
wandb:   val_loss/dataloader_idx_6 0.27003
wandb:   val_loss/dataloader_idx_7 0.2881
wandb:   val_loss/dataloader_idx_8 0.32463
wandb:   val_loss/dataloader_idx_9 0.32675
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2017-seed-10 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/kxen0fc3
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260126_133351-kxen0fc3/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260126_211949-sn7b9wyo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2018-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/sn7b9wyo
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Restoring states from the checkpoint path at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2018.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10/best-checkpoint-2018.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 0    â”ƒ   DataLoader 1    â”ƒ   DataLoader 2   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.81325340270996â€¦ â”‚ 0.82939600944519â€¦ â”‚ 0.8427141904830â€¦ â”‚
â”‚     test_loss     â”‚ 0.26419076323509â€¦ â”‚ 0.29421663284301â€¦ â”‚ 0.2605025768280â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 3    â”ƒ   DataLoader 4    â”ƒ   DataLoader 5   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.83888804912567â€¦ â”‚ 0.83297586441040â€¦ â”‚ 0.8345751166343â€¦ â”‚
â”‚     test_loss     â”‚ 0.26050484180450â€¦ â”‚ 0.28441888093948â€¦ â”‚ 0.2603857219219â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 6    â”ƒ   DataLoader 7    â”ƒ   DataLoader 8   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.80271935462951â€¦ â”‚ 0.80826222896575â€¦ â”‚ 0.7836366295814â€¦ â”‚
â”‚     test_loss     â”‚ 0.29116359353065â€¦ â”‚ 0.26821622252464â€¦ â”‚ 0.3104029595851â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Runningstage.tesâ€¦ â”ƒ                   â”ƒ                   â”ƒ                  â”ƒ
â”ƒ      metric       â”ƒ   DataLoader 9    â”ƒ   DataLoader 10   â”ƒ  DataLoader 11   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     test_auc      â”‚ 0.73871028423309â€¦ â”‚ 0.73027718067169â€¦ â”‚ 0.7107130885124â€¦ â”‚
â”‚     test_loss     â”‚ 0.32036942243576â€¦ â”‚ 0.32615551352500â€¦ â”‚ 0.3291185796260â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             meta_loss_epoch â–ˆâ–…â–ƒâ–
wandb:              meta_loss_step â–„â–…â–‚â–â–‚â–„â–‚â–ƒâ–ƒâ–ˆâ–‚â–ƒâ–…â–…â–â–ƒâ–‚â–†â–ˆâ–‚â–â–ƒâ–ˆâ–„â–‚â–â–â–…â–‚â–â–‚â–ƒâ–‚â–…â–â–â–ƒâ–‚â–‚â–‚
wandb:                    test_auc â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–†â–…â–‚â–‚â–
wandb:   test_auc/dataloader_idx_0 â–
wandb:   test_auc/dataloader_idx_1 â–
wandb:  test_auc/dataloader_idx_10 â–
wandb:  test_auc/dataloader_idx_11 â–
wandb:   test_auc/dataloader_idx_2 â–
wandb:   test_auc/dataloader_idx_3 â–
wandb:   test_auc/dataloader_idx_4 â–
wandb:   test_auc/dataloader_idx_5 â–
wandb:   test_auc/dataloader_idx_6 â–
wandb:   test_auc/dataloader_idx_7 â–
wandb:   test_auc/dataloader_idx_8 â–
wandb:   test_auc/dataloader_idx_9 â–
wandb:  test_loss/dataloader_idx_0 â–
wandb:  test_loss/dataloader_idx_1 â–
wandb: test_loss/dataloader_idx_10 â–
wandb: test_loss/dataloader_idx_11 â–
wandb:  test_loss/dataloader_idx_2 â–
wandb:  test_loss/dataloader_idx_3 â–
wandb:  test_loss/dataloader_idx_4 â–
wandb:  test_loss/dataloader_idx_5 â–
wandb:  test_loss/dataloader_idx_6 â–
wandb:  test_loss/dataloader_idx_7 â–
wandb:  test_loss/dataloader_idx_8 â–
wandb:  test_loss/dataloader_idx_9 â–
wandb:                   test_year â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:    val_auc/dataloader_idx_0 â–„â–ˆâ–â–‡
wandb:    val_auc/dataloader_idx_1 â–ƒâ–â–â–ˆ
wandb:   val_auc/dataloader_idx_10 â–â–ˆâ–…â–…
wandb:   val_auc/dataloader_idx_11 â–â–‡â–†â–ˆ
wandb:    val_auc/dataloader_idx_2 â–â–ˆâ–‚â–†
wandb:    val_auc/dataloader_idx_3 â–ˆâ–†â–â–ˆ
wandb:    val_auc/dataloader_idx_4 â–ˆâ–‡â–ƒâ–
wandb:    val_auc/dataloader_idx_5 â–ˆâ–†â–„â–
wandb:    val_auc/dataloader_idx_6 â–â–„â–ˆâ–ˆ
wandb:    val_auc/dataloader_idx_7 â–â–‚â–ˆâ–†
wandb:    val_auc/dataloader_idx_8 â–â–ˆâ–…â–…
wandb:    val_auc/dataloader_idx_9 â–â–ˆâ–…â–ˆ
wandb:   val_loss/dataloader_idx_0 â–â–„â–…â–ˆ
wandb:   val_loss/dataloader_idx_1 â–â–†â–„â–ˆ
wandb:  val_loss/dataloader_idx_10 â–â–ƒâ–…â–ˆ
wandb:  val_loss/dataloader_idx_11 â–â–„â–…â–ˆ
wandb:   val_loss/dataloader_idx_2 â–â–ƒâ–…â–ˆ
wandb:   val_loss/dataloader_idx_3 â–â–…â–…â–ˆ
wandb:   val_loss/dataloader_idx_4 â–â–ƒâ–…â–ˆ
wandb:   val_loss/dataloader_idx_5 â–â–ƒâ–…â–ˆ
wandb:   val_loss/dataloader_idx_6 â–ˆâ–†â–‚â–
wandb:   val_loss/dataloader_idx_7 â–ˆâ–ˆâ–â–‚
wandb:   val_loss/dataloader_idx_8 â–â–ƒâ–„â–ˆ
wandb:   val_loss/dataloader_idx_9 â–â–„â–…â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 4
wandb:             meta_loss_epoch 0.15221
wandb:              meta_loss_step 0.01806
wandb:                    test_auc 0.71071
wandb:   test_auc/dataloader_idx_0 0.81325
wandb:   test_auc/dataloader_idx_1 0.8294
wandb:  test_auc/dataloader_idx_10 0.73028
wandb:  test_auc/dataloader_idx_11 0.71071
wandb:   test_auc/dataloader_idx_2 0.84271
wandb:   test_auc/dataloader_idx_3 0.83889
wandb:   test_auc/dataloader_idx_4 0.83298
wandb:   test_auc/dataloader_idx_5 0.83458
wandb:   test_auc/dataloader_idx_6 0.80272
wandb:   test_auc/dataloader_idx_7 0.80826
wandb:   test_auc/dataloader_idx_8 0.78364
wandb:   test_auc/dataloader_idx_9 0.73871
wandb:  test_loss/dataloader_idx_0 0.26419
wandb:  test_loss/dataloader_idx_1 0.29422
wandb: test_loss/dataloader_idx_10 0.32616
wandb: test_loss/dataloader_idx_11 0.32912
wandb:  test_loss/dataloader_idx_2 0.2605
wandb:  test_loss/dataloader_idx_3 0.2605
wandb:  test_loss/dataloader_idx_4 0.28442
wandb:  test_loss/dataloader_idx_5 0.26039
wandb:  test_loss/dataloader_idx_6 0.29116
wandb:  test_loss/dataloader_idx_7 0.26822
wandb:  test_loss/dataloader_idx_8 0.3104
wandb:  test_loss/dataloader_idx_9 0.32037
wandb:                   test_year 2024
wandb:         trainer/global_step 46612
wandb:    val_auc/dataloader_idx_0 0.8191
wandb:    val_auc/dataloader_idx_1 0.82907
wandb:   val_auc/dataloader_idx_10 0.733
wandb:   val_auc/dataloader_idx_11 0.71719
wandb:    val_auc/dataloader_idx_2 0.84024
wandb:    val_auc/dataloader_idx_3 0.85155
wandb:    val_auc/dataloader_idx_4 0.83395
wandb:    val_auc/dataloader_idx_5 0.81982
wandb:    val_auc/dataloader_idx_6 0.82616
wandb:    val_auc/dataloader_idx_7 0.79808
wandb:    val_auc/dataloader_idx_8 0.77448
wandb:    val_auc/dataloader_idx_9 0.75098
wandb:   val_loss/dataloader_idx_0 0.29326
wandb:   val_loss/dataloader_idx_1 0.29352
wandb:  val_loss/dataloader_idx_10 0.33901
wandb:  val_loss/dataloader_idx_11 0.34726
wandb:   val_loss/dataloader_idx_2 0.26497
wandb:   val_loss/dataloader_idx_3 0.27224
wandb:   val_loss/dataloader_idx_4 0.30718
wandb:   val_loss/dataloader_idx_5 0.30597
wandb:   val_loss/dataloader_idx_6 0.2641
wandb:   val_loss/dataloader_idx_7 0.28083
wandb:   val_loss/dataloader_idx_8 0.32203
wandb:   val_loss/dataloader_idx_9 0.32815
wandb: 
wandb: ğŸš€ View run tmaml-sequential-2013-2024-2018-seed-10 at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/sn7b9wyo
wandb: â­ï¸ View project at: https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /gpfs/scratch/slj9342/wandb/wandb/run-20260126_211949-sn7b9wyo/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /gpfs/scratch/slj9342/wandb/wandb/run-20260127_050034-ep7f0xwt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmaml-sequential-2013-2024-2019-seed-10
wandb: â­ï¸ View project at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2
wandb: ğŸš€ View run at https://wandb.ai/lakej98-nyu-langone-health/la_maml_clinical_v2/runs/ep7f0xwt
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/la_maml_clinical_v2/checkpoints/la_maml_clinical_v2/tmaml-sequential-2013-2024/seed-10 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                          | Params
-----------------------------------------------------------
0 | model    | BertForSequenceClassification | 124 M 
1 | val_auc  | BinaryAUROC                   | 0     
2 | test_auc | BinaryAUROC                   | 0     
-----------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.772   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/gpfs/data/oermannlab/users/slj9342/.conda/envs/amazon_fashion_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
[2026-01-27T16:29:39.004] error: *** JOB 17655310 ON a100-4014 CANCELLED AT 2026-01-27T16:29:39 DUE TO TIME LIMIT ***
