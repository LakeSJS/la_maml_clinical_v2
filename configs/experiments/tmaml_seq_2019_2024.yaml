# TMAML sequential training on 2019-2024
# Initialized from the 2013-2018 baseline checkpoint
# Note: TMAML trains on (t, t+1) pairs, so year 2024 is only used as future data

experiment_name: "tmaml-sequential-2019-2024"

model:
  type: tmaml
  learning_rate: 1.0e-5
  inner_loop_learning_rate: 1.0e-5
  future_step: 1
  use_peft: false  # PEFT incompatible with higher library used in TMAML
  peft_method: lora
  lora_r: 8
  lora_alpha: 16
  lora_dropout: 0.1
  lora_target_modules: ["query", "value"]
  lora_bias: none

training:
  max_epochs: 40
  sequential: true  # Required for TMAML
  batch_size: 4

data:
  train_years: [2019, 2020, 2021, 2022, 2023, 2024]
  validation_years: [2019, 2020, 2021, 2022, 2023, 2024]
  test_years: [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]
  sequential_training: true
  sequential_validation: true
  sequential_test: true

initialization:
  from_checkpoint: true
  checkpoint_pattern: "{checkpoints_dir}/{project}/traditional-nonsequential-2013-2018/seed-{seed}/best-checkpoint.ckpt"
